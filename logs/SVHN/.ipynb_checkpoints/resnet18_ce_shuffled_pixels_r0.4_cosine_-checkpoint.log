Namespace(arch='resnet18', base_width=64, batch_size=128, data_root='../DATASETS/SVHN', dataset='SVHN', epochs=100, evaluate=False, loss='ce', lr=0.1, lr_gamma=0.1, lr_milestones=[40, 80], lr_schedule='cosine', momentum=0.9, noise_info=None, noise_rate=0.4, noise_type='shuffled_pixels', optimizer='sgd', print_freq=50, result_dir='results/SVHN/resnet18_ce_shuffled_pixels_r0.4_cosine_', resume='', sat_alpha=0.9, sat_es=0, save_dir='ckpts/SVHN/resnet18_ce_shuffled_pixels_r0.4_cosine_', save_freq=0, seed=5586, start_epoch=0, train_sets='trainval', turn_off_aug=False, use_refined_label=False, val_sets=['test_set'], weight_decay=0.0005, workers=4)
Using downloaded and verified file: ../DATASETS/SVHN/train_32x32.mat
data shape: (73257, 3, 32, 32)
Using downloaded and verified file: ../DATASETS/SVHN/test_32x32.mat
data shape: (26032, 3, 32, 32)
Randomizing 40.0 percent of images with `shuffled_pixels` scheme.
Noise info is saved to ckpts/SVHN/resnet18_ce_shuffled_pixels_r0.4_cosine_
Size of dataset: 73257.
Using `SGD` optimizer
Using `cosine` schedule
****************************************
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
Epoch: [0][50/573]	LR 0.100000	Time 0.269 (0.341)	Data 0.000 (0.014)	Loss 2.2711 (3.2459)	Prec@1 17.969 (16.828)
Epoch: [0][100/573]	LR 0.100000	Time 0.266 (0.303)	Data 0.000 (0.007)	Loss 2.2670 (2.7467)	Prec@1 16.406 (17.625)
Epoch: [0][150/573]	LR 0.100000	Time 0.268 (0.289)	Data 0.000 (0.005)	Loss 2.2437 (2.5778)	Prec@1 15.625 (18.245)
Epoch: [0][200/573]	LR 0.100000	Time 0.266 (0.283)	Data 0.000 (0.004)	Loss 2.2467 (2.4931)	Prec@1 18.750 (18.449)
Epoch: [0][250/573]	LR 0.100000	Time 0.266 (0.278)	Data 0.000 (0.003)	Loss 2.2064 (2.4432)	Prec@1 20.312 (18.572)
Epoch: [0][300/573]	LR 0.100000	Time 0.268 (0.275)	Data 0.000 (0.002)	Loss 2.1566 (2.4099)	Prec@1 27.344 (18.625)
Epoch: [0][350/573]	LR 0.100000	Time 0.268 (0.274)	Data 0.000 (0.002)	Loss 2.2485 (2.3852)	Prec@1 21.094 (18.681)
Epoch: [0][400/573]	LR 0.100000	Time 0.268 (0.273)	Data 0.000 (0.002)	Loss 2.2236 (2.3668)	Prec@1 18.750 (18.594)
Epoch: [0][450/573]	LR 0.100000	Time 0.269 (0.272)	Data 0.000 (0.002)	Loss 2.2554 (2.3519)	Prec@1 14.062 (18.618)
Epoch: [0][500/573]	LR 0.100000	Time 0.268 (0.271)	Data 0.000 (0.002)	Loss 2.1765 (2.3404)	Prec@1 24.219 (18.681)
Epoch: [0][550/573]	LR 0.100000	Time 0.269 (0.271)	Data 0.000 (0.001)	Loss 2.2091 (2.3317)	Prec@1 21.875 (18.636)
Epoch: [0][573/573]	LR 0.100000	Time 2.274 (0.275)	Data 0.000 (0.001)	Loss 2.2414 (2.3283)	Prec@1 21.951 (18.622)
****************************************
test_set:	 * Prec@1 19.522
****************************************
Epoch: [1][50/573]	LR 0.099975	Time 0.269 (0.273)	Data 0.000 (0.005)	Loss 2.2405 (2.2340)	Prec@1 17.969 (19.312)
Epoch: [1][100/573]	LR 0.099975	Time 0.266 (0.270)	Data 0.000 (0.003)	Loss 2.1770 (2.2358)	Prec@1 20.312 (18.805)
Epoch: [1][150/573]	LR 0.099975	Time 0.266 (0.268)	Data 0.000 (0.002)	Loss 2.2524 (2.2370)	Prec@1 17.188 (18.766)
Epoch: [1][200/573]	LR 0.099975	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 2.2904 (2.2361)	Prec@1 17.188 (18.969)
Epoch: [1][250/573]	LR 0.099975	Time 0.267 (0.266)	Data 0.000 (0.001)	Loss 2.2366 (2.2374)	Prec@1 19.531 (18.887)
Epoch: [1][300/573]	LR 0.099975	Time 0.268 (0.266)	Data 0.000 (0.001)	Loss 2.2045 (2.2372)	Prec@1 22.656 (18.870)
Epoch: [1][350/573]	LR 0.099975	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 2.1924 (2.2379)	Prec@1 25.000 (18.882)
Epoch: [1][400/573]	LR 0.099975	Time 0.268 (0.267)	Data 0.000 (0.001)	Loss 2.1951 (2.2369)	Prec@1 22.656 (18.977)
Epoch: [1][450/573]	LR 0.099975	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 2.2238 (2.2365)	Prec@1 17.969 (18.964)
Epoch: [1][500/573]	LR 0.099975	Time 0.270 (0.267)	Data 0.000 (0.001)	Loss 2.2331 (2.2366)	Prec@1 19.531 (18.877)
Epoch: [1][550/573]	LR 0.099975	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 2.2585 (2.2364)	Prec@1 21.094 (18.889)
Epoch: [1][573/573]	LR 0.099975	Time 0.122 (0.267)	Data 0.000 (0.001)	Loss 2.2213 (2.2366)	Prec@1 24.390 (18.905)
****************************************
test_set:	 * Prec@1 19.776
****************************************
Epoch: [2][50/573]	LR 0.099901	Time 0.269 (0.275)	Data 0.000 (0.006)	Loss 2.2654 (2.2367)	Prec@1 22.656 (19.484)
Epoch: [2][100/573]	LR 0.099901	Time 0.248 (0.271)	Data 0.000 (0.003)	Loss 2.2169 (2.2331)	Prec@1 19.531 (19.523)
Epoch: [2][150/573]	LR 0.099901	Time 0.268 (0.269)	Data 0.000 (0.002)	Loss 2.1972 (2.2316)	Prec@1 21.094 (19.516)
Epoch: [2][200/573]	LR 0.099901	Time 0.268 (0.268)	Data 0.000 (0.002)	Loss 2.2613 (2.2298)	Prec@1 15.625 (19.434)
Epoch: [2][250/573]	LR 0.099901	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 2.2073 (2.2217)	Prec@1 17.969 (19.969)
Epoch: [2][300/573]	LR 0.099901	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 2.0933 (2.2012)	Prec@1 28.125 (20.896)
Epoch: [2][350/573]	LR 0.099901	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 2.0169 (2.1723)	Prec@1 27.344 (22.179)
Epoch: [2][400/573]	LR 0.099901	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 1.6246 (2.1382)	Prec@1 43.750 (23.512)
Epoch: [2][450/573]	LR 0.099901	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 1.8937 (2.1051)	Prec@1 34.375 (24.832)
Epoch: [2][500/573]	LR 0.099901	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 1.7723 (2.0649)	Prec@1 37.500 (26.364)
Epoch: [2][550/573]	LR 0.099901	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 1.5228 (2.0255)	Prec@1 42.188 (27.875)
Epoch: [2][573/573]	LR 0.099901	Time 0.121 (0.267)	Data 0.000 (0.001)	Loss 1.7116 (2.0051)	Prec@1 41.463 (28.620)
****************************************
test_set:	 * Prec@1 55.101
****************************************
Epoch: [3][50/573]	LR 0.099778	Time 0.269 (0.274)	Data 0.000 (0.005)	Loss 1.2548 (1.4081)	Prec@1 60.156 (51.891)
Epoch: [3][100/573]	LR 0.099778	Time 0.266 (0.270)	Data 0.000 (0.003)	Loss 1.0741 (1.3387)	Prec@1 64.062 (54.070)
Epoch: [3][150/573]	LR 0.099778	Time 0.268 (0.268)	Data 0.000 (0.002)	Loss 0.9632 (1.2773)	Prec@1 68.750 (56.286)
Epoch: [3][200/573]	LR 0.099778	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 0.9747 (1.2268)	Prec@1 67.188 (58.016)
Epoch: [3][250/573]	LR 0.099778	Time 0.268 (0.267)	Data 0.000 (0.001)	Loss 1.1075 (1.1840)	Prec@1 65.625 (59.538)
Epoch: [3][300/573]	LR 0.099778	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.8429 (1.1517)	Prec@1 70.312 (60.727)
Epoch: [3][350/573]	LR 0.099778	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.9839 (1.1179)	Prec@1 71.094 (61.839)
Epoch: [3][400/573]	LR 0.099778	Time 0.266 (0.267)	Data 0.000 (0.001)	Loss 0.7802 (1.0877)	Prec@1 73.438 (62.896)
Epoch: [3][450/573]	LR 0.099778	Time 0.268 (0.267)	Data 0.000 (0.001)	Loss 0.9563 (1.0619)	Prec@1 68.750 (63.816)
Epoch: [3][500/573]	LR 0.099778	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.8314 (1.0417)	Prec@1 67.969 (64.578)
Epoch: [3][550/573]	LR 0.099778	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.8611 (1.0208)	Prec@1 68.750 (65.352)
Epoch: [3][573/573]	LR 0.099778	Time 0.121 (0.267)	Data 0.000 (0.001)	Loss 0.6240 (1.0125)	Prec@1 82.927 (65.643)
****************************************
test_set:	 * Prec@1 82.717
****************************************
Epoch: [4][50/573]	LR 0.099606	Time 0.269 (0.274)	Data 0.000 (0.005)	Loss 0.5936 (0.7535)	Prec@1 81.250 (74.828)
Epoch: [4][100/573]	LR 0.099606	Time 0.265 (0.270)	Data 0.000 (0.003)	Loss 0.7456 (0.7637)	Prec@1 75.781 (74.641)
Epoch: [4][150/573]	LR 0.099606	Time 0.268 (0.268)	Data 0.000 (0.002)	Loss 0.6216 (0.7474)	Prec@1 81.250 (75.396)
Epoch: [4][200/573]	LR 0.099606	Time 0.268 (0.267)	Data 0.000 (0.001)	Loss 0.7176 (0.7331)	Prec@1 74.219 (75.887)
Epoch: [4][250/573]	LR 0.099606	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 0.5960 (0.7237)	Prec@1 82.031 (76.241)
Epoch: [4][300/573]	LR 0.099606	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.8104 (0.7214)	Prec@1 75.000 (76.362)
Epoch: [4][350/573]	LR 0.099606	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.7964 (0.7151)	Prec@1 75.000 (76.585)
Epoch: [4][400/573]	LR 0.099606	Time 0.268 (0.267)	Data 0.000 (0.001)	Loss 0.6946 (0.7103)	Prec@1 78.906 (76.787)
Epoch: [4][450/573]	LR 0.099606	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.7953 (0.7042)	Prec@1 75.000 (77.033)
Epoch: [4][500/573]	LR 0.099606	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.6663 (0.6975)	Prec@1 78.125 (77.261)
Epoch: [4][550/573]	LR 0.099606	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.5627 (0.6925)	Prec@1 81.250 (77.418)
Epoch: [4][573/573]	LR 0.099606	Time 0.121 (0.267)	Data 0.000 (0.001)	Loss 0.5397 (0.6903)	Prec@1 87.805 (77.498)
****************************************
test_set:	 * Prec@1 84.692
****************************************
Epoch: [5][50/573]	LR 0.099384	Time 0.269 (0.274)	Data 0.000 (0.005)	Loss 0.6386 (0.6086)	Prec@1 78.125 (80.719)
Epoch: [5][100/573]	LR 0.099384	Time 0.265 (0.270)	Data 0.000 (0.003)	Loss 0.8057 (0.6063)	Prec@1 78.125 (80.844)
Epoch: [5][150/573]	LR 0.099384	Time 0.268 (0.268)	Data 0.000 (0.002)	Loss 0.3813 (0.6091)	Prec@1 89.844 (80.568)
Epoch: [5][200/573]	LR 0.099384	Time 0.268 (0.267)	Data 0.000 (0.002)	Loss 0.6064 (0.6066)	Prec@1 81.250 (80.551)
Epoch: [5][250/573]	LR 0.099384	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 0.6017 (0.6085)	Prec@1 80.469 (80.444)
Epoch: [5][300/573]	LR 0.099384	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.5134 (0.6020)	Prec@1 83.594 (80.669)
Epoch: [5][350/573]	LR 0.099384	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.6271 (0.6028)	Prec@1 78.125 (80.589)
Epoch: [5][400/573]	LR 0.099384	Time 0.268 (0.267)	Data 0.000 (0.001)	Loss 0.6476 (0.5984)	Prec@1 77.344 (80.760)
Epoch: [5][450/573]	LR 0.099384	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.6021 (0.5974)	Prec@1 81.250 (80.826)
Epoch: [5][500/573]	LR 0.099384	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.7396 (0.5972)	Prec@1 75.000 (80.922)
Epoch: [5][550/573]	LR 0.099384	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.5646 (0.5934)	Prec@1 82.812 (81.014)
Epoch: [5][573/573]	LR 0.099384	Time 0.122 (0.267)	Data 0.000 (0.001)	Loss 0.5571 (0.5916)	Prec@1 82.927 (81.084)
****************************************
test_set:	 * Prec@1 86.563
****************************************
Epoch: [6][50/573]	LR 0.099114	Time 0.268 (0.274)	Data 0.000 (0.005)	Loss 0.5772 (0.5653)	Prec@1 83.594 (82.062)
Epoch: [6][100/573]	LR 0.099114	Time 0.266 (0.269)	Data 0.000 (0.003)	Loss 0.7391 (0.5610)	Prec@1 78.906 (82.148)
Epoch: [6][150/573]	LR 0.099114	Time 0.267 (0.268)	Data 0.000 (0.002)	Loss 0.4562 (0.5608)	Prec@1 87.500 (82.193)
Epoch: [6][200/573]	LR 0.099114	Time 0.267 (0.267)	Data 0.000 (0.001)	Loss 0.4888 (0.5586)	Prec@1 83.594 (82.211)
Epoch: [6][250/573]	LR 0.099114	Time 0.268 (0.266)	Data 0.000 (0.001)	Loss 0.4852 (0.5527)	Prec@1 85.938 (82.425)
Epoch: [6][300/573]	LR 0.099114	Time 0.269 (0.266)	Data 0.000 (0.001)	Loss 0.4069 (0.5531)	Prec@1 85.156 (82.328)
Epoch: [6][350/573]	LR 0.099114	Time 0.224 (0.266)	Data 0.000 (0.001)	Loss 0.5981 (0.5507)	Prec@1 80.469 (82.429)
Epoch: [6][400/573]	LR 0.099114	Time 0.267 (0.266)	Data 0.000 (0.001)	Loss 0.3977 (0.5480)	Prec@1 87.500 (82.555)
Epoch: [6][450/573]	LR 0.099114	Time 0.269 (0.266)	Data 0.000 (0.001)	Loss 0.5350 (0.5468)	Prec@1 83.594 (82.585)
Epoch: [6][500/573]	LR 0.099114	Time 0.269 (0.266)	Data 0.000 (0.001)	Loss 0.4625 (0.5454)	Prec@1 85.156 (82.622)
Epoch: [6][550/573]	LR 0.099114	Time 0.269 (0.267)	Data 0.000 (0.001)	Loss 0.6013 (0.5443)	Prec@1 82.812 (82.628)
Epoch: [6][573/573]	LR 0.099114	Time 0.123 (0.266)	Data 0.000 (0.001)	Loss 0.5085 (0.5428)	Prec@1 82.927 (82.671)
****************************************
test_set:	 * Prec@1 88.706
****************************************
Epoch: [7][50/573]	LR 0.098796	Time 0.269 (0.273)	Data 0.000 (0.004)	Loss 0.6512 (0.5153)	Prec@1 76.562 (83.938)
Epoch: [7][100/573]	LR 0.098796	Time 0.265 (0.269)	Data 0.000 (0.002)	Loss 0.5605 (0.5061)	Prec@1 79.688 (83.938)
Epoch: [7][150/573]	LR 0.098796	Time 0.268 (0.267)	Data 0.000 (0.002)	Loss 0.5501 (0.5013)	Prec@1 82.031 (84.036)
Epoch: [7][200/573]	LR 0.098796	Time 0.266 (0.267)	Data 0.000 (0.001)	Loss 0.5431 (0.5091)	Prec@1 84.375 (83.793)
Epoch: [7][250/573]	LR 0.098796	Time 0.268 (0.266)	Data 0.000 (0.001)	Loss 0.4652 (0.5094)	Prec@1 84.375 (83.881)
Epoch: [7][300/573]	LR 0.098796	Time 0.269 (0.266)	Data 0.000 (0.001)	Loss 0.4168 (0.5093)	Prec@1 86.719 (83.880)
Epoch: [7][350/573]	LR 0.098796	Time 0.266 (0.267)	Data 0.000 (0.001)	Loss 0.4494 (0.5111)	Prec@1 83.594 (83.812)
Epoch: [7][400/573]	LR 0.098796	Time 0.270 (0.267)	Data 0.000 (0.001)	Loss 0.5955 (0.5082)	Prec@1 79.688 (83.891)
Epoch: [7][450/573]	LR 0.098796	Time 0.313 (0.269)	Data 0.000 (0.001)	Loss 0.4896 (0.5062)	Prec@1 82.031 (83.967)
Epoch: [7][500/573]	LR 0.098796	Time 0.314 (0.273)	Data 0.000 (0.001)	Loss 0.4938 (0.5078)	Prec@1 85.156 (83.898)
Epoch: [7][550/573]	LR 0.098796	Time 0.157 (0.276)	Data 0.003 (0.001)	Loss 0.4395 (0.5089)	Prec@1 87.500 (83.861)
Epoch: [7][573/573]	LR 0.098796	Time 0.122 (0.272)	Data 0.000 (0.001)	Loss 0.7001 (0.5086)	Prec@1 78.049 (83.873)
****************************************
test_set:	 * Prec@1 89.010
****************************************
Epoch: [8][50/573]	LR 0.098429	Time 0.311 (0.327)	Data 0.000 (0.011)	Loss 0.5391 (0.5006)	Prec@1 85.938 (84.516)
Epoch: [8][100/573]	LR 0.098429	Time 0.356 (0.326)	Data 0.000 (0.006)	Loss 0.4598 (0.4939)	Prec@1 85.938 (84.578)
Epoch: [8][150/573]	LR 0.098429	Time 0.359 (0.336)	Data 0.000 (0.004)	Loss 0.4287 (0.4891)	Prec@1 88.281 (84.573)
Epoch: [8][200/573]	LR 0.098429	Time 0.402 (0.343)	Data 0.000 (0.003)	Loss 0.4573 (0.4929)	Prec@1 84.375 (84.488)
Epoch: [8][250/573]	LR 0.098429	Time 0.400 (0.355)	Data 0.000 (0.003)	Loss 0.4593 (0.4957)	Prec@1 86.719 (84.487)
Epoch: [8][300/573]	LR 0.098429	Time 0.386 (0.362)	Data 0.000 (0.002)	Loss 0.5734 (0.4960)	Prec@1 83.594 (84.555)
Epoch: [8][350/573]	LR 0.098429	Time 0.404 (0.368)	Data 0.000 (0.002)	Loss 0.4284 (0.4938)	Prec@1 87.500 (84.616)
Epoch: [8][400/573]	LR 0.098429	Time 0.401 (0.371)	Data 0.001 (0.002)	Loss 0.4107 (0.4921)	Prec@1 90.625 (84.586)
Epoch: [8][450/573]	LR 0.098429	Time 0.404 (0.374)	Data 0.001 (0.002)	Loss 0.4692 (0.4917)	Prec@1 85.156 (84.615)
Epoch: [8][500/573]	LR 0.098429	Time 0.404 (0.377)	Data 0.000 (0.002)	Loss 0.4464 (0.4901)	Prec@1 85.156 (84.706)
Epoch: [8][550/573]	LR 0.098429	Time 0.404 (0.379)	Data 0.000 (0.001)	Loss 0.5349 (0.4901)	Prec@1 80.469 (84.702)
Epoch: [8][573/573]	LR 0.098429	Time 0.180 (0.380)	Data 0.000 (0.001)	Loss 0.6096 (0.4888)	Prec@1 75.610 (84.735)
****************************************
test_set:	 * Prec@1 89.651
****************************************
Epoch: [9][50/573]	LR 0.098015	Time 0.402 (0.402)	Data 0.000 (0.005)	Loss 0.3630 (0.4734)	Prec@1 89.062 (84.984)
Epoch: [9][100/573]	LR 0.098015	Time 0.402 (0.400)	Data 0.000 (0.003)	Loss 0.4917 (0.4721)	Prec@1 86.719 (85.117)
Epoch: [9][150/573]	LR 0.098015	Time 0.401 (0.397)	Data 0.000 (0.002)	Loss 0.3950 (0.4714)	Prec@1 86.719 (85.016)
Epoch: [9][200/573]	LR 0.098015	Time 0.369 (0.397)	Data 0.000 (0.001)	Loss 0.6791 (0.4772)	Prec@1 80.469 (84.906)
Epoch: [9][250/573]	LR 0.098015	Time 0.400 (0.397)	Data 0.000 (0.001)	Loss 0.5575 (0.4762)	Prec@1 83.594 (85.009)
Epoch: [9][300/573]	LR 0.098015	Time 0.404 (0.397)	Data 0.000 (0.001)	Loss 0.6712 (0.4748)	Prec@1 76.562 (85.086)
Epoch: [9][350/573]	LR 0.098015	Time 0.404 (0.398)	Data 0.000 (0.001)	Loss 0.4256 (0.4742)	Prec@1 87.500 (85.078)
Epoch: [9][400/573]	LR 0.098015	Time 0.401 (0.398)	Data 0.000 (0.001)	Loss 0.6434 (0.4767)	Prec@1 82.031 (84.998)
Epoch: [9][450/573]	LR 0.098015	Time 0.403 (0.398)	Data 0.000 (0.001)	Loss 0.6171 (0.4733)	Prec@1 81.250 (85.097)
Epoch: [9][500/573]	LR 0.098015	Time 0.403 (0.399)	Data 0.000 (0.001)	Loss 0.4302 (0.4734)	Prec@1 87.500 (85.119)
Epoch: [9][550/573]	LR 0.098015	Time 0.404 (0.399)	Data 0.000 (0.001)	Loss 0.5730 (0.4718)	Prec@1 83.594 (85.173)
Epoch: [9][573/573]	LR 0.098015	Time 0.183 (0.399)	Data 0.000 (0.001)	Loss 0.7667 (0.4723)	Prec@1 78.049 (85.135)
****************************************
test_set:	 * Prec@1 84.511
****************************************
Epoch: [10][50/573]	LR 0.097553	Time 0.402 (0.405)	Data 0.000 (0.005)	Loss 0.5447 (0.4707)	Prec@1 81.250 (84.984)
Epoch: [10][100/573]	LR 0.097553	Time 0.402 (0.402)	Data 0.000 (0.002)	Loss 0.3351 (0.4574)	Prec@1 89.062 (85.750)
Epoch: [10][150/573]	LR 0.097553	Time 0.401 (0.401)	Data 0.000 (0.002)	Loss 0.5471 (0.4648)	Prec@1 82.812 (85.573)
Epoch: [10][200/573]	LR 0.097553	Time 0.399 (0.401)	Data 0.000 (0.001)	Loss 0.4487 (0.4610)	Prec@1 86.719 (85.641)
Epoch: [10][250/573]	LR 0.097553	Time 0.401 (0.400)	Data 0.000 (0.001)	Loss 0.3950 (0.4606)	Prec@1 88.281 (85.650)
Epoch: [10][300/573]	LR 0.097553	Time 0.404 (0.400)	Data 0.000 (0.001)	Loss 0.4872 (0.4576)	Prec@1 85.938 (85.727)
Epoch: [10][350/573]	LR 0.097553	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.4715 (0.4550)	Prec@1 86.719 (85.859)
Epoch: [10][400/573]	LR 0.097553	Time 0.400 (0.401)	Data 0.000 (0.001)	Loss 0.4541 (0.4565)	Prec@1 85.938 (85.775)
Epoch: [10][450/573]	LR 0.097553	Time 0.404 (0.400)	Data 0.000 (0.001)	Loss 0.3771 (0.4573)	Prec@1 89.844 (85.752)
Epoch: [10][500/573]	LR 0.097553	Time 0.403 (0.401)	Data 0.000 (0.001)	Loss 0.5338 (0.4588)	Prec@1 84.375 (85.730)
Epoch: [10][550/573]	LR 0.097553	Time 0.403 (0.401)	Data 0.000 (0.001)	Loss 0.4567 (0.4584)	Prec@1 86.719 (85.716)
Epoch: [10][573/573]	LR 0.097553	Time 0.183 (0.401)	Data 0.000 (0.001)	Loss 0.4260 (0.4588)	Prec@1 90.244 (85.732)
****************************************
test_set:	 * Prec@1 88.503
****************************************
Epoch: [11][50/573]	LR 0.097044	Time 0.402 (0.407)	Data 0.000 (0.006)	Loss 0.5787 (0.4760)	Prec@1 85.938 (85.219)
Epoch: [11][100/573]	LR 0.097044	Time 0.402 (0.403)	Data 0.000 (0.003)	Loss 0.4558 (0.4604)	Prec@1 85.156 (85.828)
Epoch: [11][150/573]	LR 0.097044	Time 0.400 (0.401)	Data 0.000 (0.002)	Loss 0.3693 (0.4516)	Prec@1 86.719 (85.990)
Epoch: [11][200/573]	LR 0.097044	Time 0.400 (0.401)	Data 0.000 (0.002)	Loss 0.3400 (0.4573)	Prec@1 89.844 (85.758)
Epoch: [11][250/573]	LR 0.097044	Time 0.401 (0.400)	Data 0.000 (0.001)	Loss 0.2814 (0.4536)	Prec@1 91.406 (85.906)
Epoch: [11][300/573]	LR 0.097044	Time 0.403 (0.400)	Data 0.000 (0.001)	Loss 0.4546 (0.4507)	Prec@1 89.062 (86.003)
Epoch: [11][350/573]	LR 0.097044	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.3379 (0.4490)	Prec@1 92.969 (86.085)
Epoch: [11][400/573]	LR 0.097044	Time 0.400 (0.401)	Data 0.000 (0.001)	Loss 0.5299 (0.4493)	Prec@1 84.375 (86.066)
Epoch: [11][450/573]	LR 0.097044	Time 0.403 (0.400)	Data 0.000 (0.001)	Loss 0.6679 (0.4498)	Prec@1 81.250 (86.071)
Epoch: [11][500/573]	LR 0.097044	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.4848 (0.4494)	Prec@1 88.281 (86.088)
Epoch: [11][550/573]	LR 0.097044	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.6137 (0.4512)	Prec@1 79.688 (86.018)
Epoch: [11][573/573]	LR 0.097044	Time 0.182 (0.401)	Data 0.000 (0.001)	Loss 0.7351 (0.4518)	Prec@1 80.488 (86.008)
****************************************
test_set:	 * Prec@1 86.797
****************************************
Epoch: [12][50/573]	LR 0.096489	Time 0.403 (0.406)	Data 0.000 (0.005)	Loss 0.4348 (0.4420)	Prec@1 87.500 (85.875)
Epoch: [12][100/573]	LR 0.096489	Time 0.403 (0.403)	Data 0.000 (0.003)	Loss 0.5600 (0.4463)	Prec@1 82.031 (86.078)
Epoch: [12][150/573]	LR 0.096489	Time 0.401 (0.401)	Data 0.000 (0.002)	Loss 0.3482 (0.4438)	Prec@1 89.844 (86.255)
Epoch: [12][200/573]	LR 0.096489	Time 0.400 (0.401)	Data 0.000 (0.001)	Loss 0.4342 (0.4423)	Prec@1 89.844 (86.297)
Epoch: [12][250/573]	LR 0.096489	Time 0.400 (0.400)	Data 0.000 (0.001)	Loss 0.5957 (0.4450)	Prec@1 79.688 (86.162)
Epoch: [12][300/573]	LR 0.096489	Time 0.404 (0.400)	Data 0.000 (0.001)	Loss 0.2980 (0.4399)	Prec@1 91.406 (86.359)
Epoch: [12][350/573]	LR 0.096489	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.3668 (0.4380)	Prec@1 89.062 (86.371)
Epoch: [12][400/573]	LR 0.096489	Time 0.400 (0.401)	Data 0.000 (0.001)	Loss 0.6318 (0.4385)	Prec@1 80.469 (86.404)
Epoch: [12][450/573]	LR 0.096489	Time 0.404 (0.400)	Data 0.000 (0.001)	Loss 0.6253 (0.4383)	Prec@1 78.125 (86.406)
Epoch: [12][500/573]	LR 0.096489	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.2911 (0.4400)	Prec@1 89.062 (86.336)
Epoch: [12][550/573]	LR 0.096489	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.6199 (0.4404)	Prec@1 82.812 (86.362)
Epoch: [12][573/573]	LR 0.096489	Time 0.184 (0.401)	Data 0.000 (0.001)	Loss 0.3540 (0.4414)	Prec@1 87.805 (86.349)
****************************************
test_set:	 * Prec@1 89.144
****************************************
Epoch: [13][50/573]	LR 0.095888	Time 0.401 (0.408)	Data 0.000 (0.006)	Loss 0.5820 (0.4349)	Prec@1 84.375 (86.625)
Epoch: [13][100/573]	LR 0.095888	Time 0.402 (0.403)	Data 0.000 (0.003)	Loss 0.3573 (0.4364)	Prec@1 88.281 (86.586)
Epoch: [13][150/573]	LR 0.095888	Time 0.400 (0.401)	Data 0.000 (0.002)	Loss 0.3661 (0.4259)	Prec@1 89.062 (86.760)
Epoch: [13][200/573]	LR 0.095888	Time 0.401 (0.401)	Data 0.000 (0.002)	Loss 0.4543 (0.4296)	Prec@1 83.594 (86.648)
Epoch: [13][250/573]	LR 0.095888	Time 0.400 (0.400)	Data 0.000 (0.001)	Loss 0.4529 (0.4302)	Prec@1 86.719 (86.666)
Epoch: [13][300/573]	LR 0.095888	Time 0.404 (0.400)	Data 0.000 (0.001)	Loss 0.3633 (0.4322)	Prec@1 90.625 (86.604)
Epoch: [13][350/573]	LR 0.095888	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.4717 (0.4322)	Prec@1 85.156 (86.607)
Epoch: [13][400/573]	LR 0.095888	Time 0.399 (0.401)	Data 0.000 (0.001)	Loss 0.4649 (0.4305)	Prec@1 85.938 (86.654)
Epoch: [13][450/573]	LR 0.095888	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.4517 (0.4319)	Prec@1 85.156 (86.611)
Epoch: [13][500/573]	LR 0.095888	Time 0.403 (0.401)	Data 0.000 (0.001)	Loss 0.5342 (0.4320)	Prec@1 82.031 (86.609)
Epoch: [13][550/573]	LR 0.095888	Time 0.403 (0.401)	Data 0.000 (0.001)	Loss 0.4918 (0.4305)	Prec@1 84.375 (86.653)
Epoch: [13][573/573]	LR 0.095888	Time 0.184 (0.401)	Data 0.000 (0.001)	Loss 0.3264 (0.4300)	Prec@1 90.244 (86.672)
****************************************
test_set:	 * Prec@1 89.332
****************************************
Epoch: [14][50/573]	LR 0.095241	Time 0.402 (0.406)	Data 0.000 (0.005)	Loss 0.4057 (0.4214)	Prec@1 86.719 (86.984)
Epoch: [14][100/573]	LR 0.095241	Time 0.401 (0.403)	Data 0.000 (0.003)	Loss 0.3416 (0.4340)	Prec@1 89.844 (86.547)
Epoch: [14][150/573]	LR 0.095241	Time 0.401 (0.402)	Data 0.000 (0.002)	Loss 0.5129 (0.4294)	Prec@1 82.812 (86.755)
Epoch: [14][200/573]	LR 0.095241	Time 0.400 (0.401)	Data 0.000 (0.001)	Loss 0.4616 (0.4277)	Prec@1 84.375 (86.805)
Epoch: [14][250/573]	LR 0.095241	Time 0.400 (0.401)	Data 0.000 (0.001)	Loss 0.5034 (0.4233)	Prec@1 81.250 (87.022)
Epoch: [14][300/573]	LR 0.095241	Time 0.404 (0.400)	Data 0.000 (0.001)	Loss 0.5446 (0.4276)	Prec@1 86.719 (86.854)
Epoch: [14][350/573]	LR 0.095241	Time 0.404 (0.401)	Data 0.000 (0.001)	Loss 0.2667 (0.4256)	Prec@1 92.969 (86.940)
Epoch: [14][400/573]	LR 0.095241	Time 0.399 (0.401)	Data 0.000 (0.001)	Loss 0.2365 (0.4235)	Prec@1 93.750 (86.936)
Epoch: [14][450/573]	LR 0.095241	Time 0.403 (0.400)	Data 0.000 (0.001)	Loss 0.6201 (0.4232)	Prec@1 81.250 (86.925)
Epoch: [14][500/573]	LR 0.095241	Time 0.403 (0.401)	Data 0.000 (0.001)	Loss 0.4110 (0.4243)	Prec@1 87.500 (86.928)
Epoch: [14][550/573]	LR 0.095241	Time 0.359 (0.399)	Data 0.000 (0.001)	Loss 0.3584 (0.4240)	Prec@1 90.625 (86.930)
Epoch: [14][573/573]	LR 0.095241	Time 0.163 (0.397)	Data 0.000 (0.001)	Loss 0.3796 (0.4226)	Prec@1 82.927 (86.972)
****************************************
test_set:	 * Prec@1 90.135
****************************************
Epoch: [15][50/573]	LR 0.094550	Time 0.312 (0.315)	Data 0.000 (0.004)	Loss 0.4748 (0.4277)	Prec@1 85.156 (86.922)
Epoch: [15][100/573]	LR 0.094550	Time 0.311 (0.312)	Data 0.000 (0.002)	Loss 0.2679 (0.4257)	Prec@1 92.188 (86.953)
Epoch: [15][150/573]	LR 0.094550	Time 0.313 (0.311)	Data 0.000 (0.002)	Loss 0.4224 (0.4225)	Prec@1 85.938 (87.078)
Epoch: [15][200/573]	LR 0.094550	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.3987 (0.4214)	Prec@1 85.938 (87.137)
Epoch: [15][250/573]	LR 0.094550	Time 0.310 (0.311)	Data 0.000 (0.001)	Loss 0.3944 (0.4212)	Prec@1 85.938 (87.156)
Epoch: [15][300/573]	LR 0.094550	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.3602 (0.4164)	Prec@1 92.188 (87.258)
Epoch: [15][350/573]	LR 0.094550	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.5017 (0.4188)	Prec@1 87.500 (87.152)
Epoch: [15][400/573]	LR 0.094550	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.4448 (0.4189)	Prec@1 85.938 (87.160)
Epoch: [15][450/573]	LR 0.094550	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4468 (0.4200)	Prec@1 85.938 (87.118)
Epoch: [15][500/573]	LR 0.094550	Time 0.315 (0.312)	Data 0.000 (0.001)	Loss 0.3667 (0.4212)	Prec@1 89.062 (87.083)
Epoch: [15][550/573]	LR 0.094550	Time 0.315 (0.312)	Data 0.000 (0.001)	Loss 0.3570 (0.4210)	Prec@1 88.281 (87.121)
Epoch: [15][573/573]	LR 0.094550	Time 0.142 (0.312)	Data 0.000 (0.001)	Loss 0.2408 (0.4201)	Prec@1 95.122 (87.132)
****************************************
test_set:	 * Prec@1 89.478
****************************************
Epoch: [16][50/573]	LR 0.093815	Time 0.313 (0.317)	Data 0.000 (0.005)	Loss 0.3164 (0.4219)	Prec@1 90.625 (87.250)
Epoch: [16][100/573]	LR 0.093815	Time 0.312 (0.313)	Data 0.000 (0.003)	Loss 0.3371 (0.4218)	Prec@1 89.844 (86.898)
Epoch: [16][150/573]	LR 0.093815	Time 0.313 (0.312)	Data 0.000 (0.002)	Loss 0.2468 (0.4188)	Prec@1 92.188 (87.078)
Epoch: [16][200/573]	LR 0.093815	Time 0.312 (0.312)	Data 0.000 (0.001)	Loss 0.3584 (0.4193)	Prec@1 89.062 (87.027)
Epoch: [16][250/573]	LR 0.093815	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.4278 (0.4199)	Prec@1 85.938 (86.909)
Epoch: [16][300/573]	LR 0.093815	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.3638 (0.4189)	Prec@1 87.500 (87.000)
Epoch: [16][350/573]	LR 0.093815	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4964 (0.4135)	Prec@1 85.156 (87.185)
Epoch: [16][400/573]	LR 0.093815	Time 0.312 (0.312)	Data 0.000 (0.001)	Loss 0.4552 (0.4124)	Prec@1 88.281 (87.217)
Epoch: [16][450/573]	LR 0.093815	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4848 (0.4134)	Prec@1 85.156 (87.226)
Epoch: [16][500/573]	LR 0.093815	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.5184 (0.4155)	Prec@1 82.812 (87.125)
Epoch: [16][550/573]	LR 0.093815	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4715 (0.4169)	Prec@1 85.938 (87.075)
Epoch: [16][573/573]	LR 0.093815	Time 0.142 (0.312)	Data 0.000 (0.001)	Loss 0.5522 (0.4157)	Prec@1 82.927 (87.114)
****************************************
test_set:	 * Prec@1 87.058
****************************************
Epoch: [17][50/573]	LR 0.093037	Time 0.313 (0.315)	Data 0.000 (0.004)	Loss 0.3988 (0.4538)	Prec@1 82.812 (85.594)
Epoch: [17][100/573]	LR 0.093037	Time 0.312 (0.312)	Data 0.000 (0.002)	Loss 0.4253 (0.4206)	Prec@1 86.719 (86.719)
Epoch: [17][150/573]	LR 0.093037	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.2719 (0.4146)	Prec@1 92.969 (86.995)
Epoch: [17][200/573]	LR 0.093037	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.5134 (0.4082)	Prec@1 81.250 (87.254)
Epoch: [17][250/573]	LR 0.093037	Time 0.310 (0.311)	Data 0.000 (0.001)	Loss 0.3494 (0.4120)	Prec@1 89.062 (87.147)
Epoch: [17][300/573]	LR 0.093037	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.3961 (0.4099)	Prec@1 88.281 (87.117)
Epoch: [17][350/573]	LR 0.093037	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.5061 (0.4110)	Prec@1 83.594 (87.185)
Epoch: [17][400/573]	LR 0.093037	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.3020 (0.4080)	Prec@1 88.281 (87.248)
Epoch: [17][450/573]	LR 0.093037	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4647 (0.4079)	Prec@1 87.500 (87.233)
Epoch: [17][500/573]	LR 0.093037	Time 0.313 (0.312)	Data 0.000 (0.001)	Loss 0.4229 (0.4076)	Prec@1 86.719 (87.245)
Epoch: [17][550/573]	LR 0.093037	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.3484 (0.4097)	Prec@1 90.625 (87.173)
Epoch: [17][573/573]	LR 0.093037	Time 0.141 (0.312)	Data 0.000 (0.001)	Loss 0.2932 (0.4089)	Prec@1 87.805 (87.222)
****************************************
test_set:	 * Prec@1 91.626
****************************************
Epoch: [18][50/573]	LR 0.092216	Time 0.313 (0.316)	Data 0.000 (0.004)	Loss 0.4808 (0.3924)	Prec@1 86.719 (88.031)
Epoch: [18][100/573]	LR 0.092216	Time 0.312 (0.313)	Data 0.000 (0.002)	Loss 0.3413 (0.4032)	Prec@1 89.062 (87.422)
Epoch: [18][150/573]	LR 0.092216	Time 0.313 (0.312)	Data 0.000 (0.001)	Loss 0.3917 (0.4094)	Prec@1 87.500 (87.172)
Epoch: [18][200/573]	LR 0.092216	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.4029 (0.4135)	Prec@1 83.594 (87.008)
Epoch: [18][250/573]	LR 0.092216	Time 0.310 (0.311)	Data 0.000 (0.001)	Loss 0.5683 (0.4108)	Prec@1 84.375 (87.144)
Epoch: [18][300/573]	LR 0.092216	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.2014 (0.4091)	Prec@1 95.312 (87.224)
Epoch: [18][350/573]	LR 0.092216	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4463 (0.4078)	Prec@1 88.281 (87.277)
Epoch: [18][400/573]	LR 0.092216	Time 0.311 (0.311)	Data 0.000 (0.001)	Loss 0.3336 (0.4073)	Prec@1 87.500 (87.314)
Epoch: [18][450/573]	LR 0.092216	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4627 (0.4053)	Prec@1 87.500 (87.387)
Epoch: [18][500/573]	LR 0.092216	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.3003 (0.4041)	Prec@1 89.844 (87.427)
Epoch: [18][550/573]	LR 0.092216	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4147 (0.4038)	Prec@1 87.500 (87.477)
Epoch: [18][573/573]	LR 0.092216	Time 0.140 (0.312)	Data 0.000 (0.001)	Loss 0.3685 (0.4032)	Prec@1 90.244 (87.495)
****************************************
test_set:	 * Prec@1 88.368
****************************************
Epoch: [19][50/573]	LR 0.091354	Time 0.312 (0.316)	Data 0.000 (0.004)	Loss 0.3346 (0.4069)	Prec@1 89.062 (87.516)
Epoch: [19][100/573]	LR 0.091354	Time 0.312 (0.313)	Data 0.000 (0.002)	Loss 0.5130 (0.4025)	Prec@1 85.156 (87.750)
Epoch: [19][150/573]	LR 0.091354	Time 0.313 (0.311)	Data 0.000 (0.002)	Loss 0.3969 (0.4047)	Prec@1 88.281 (87.656)
Epoch: [19][200/573]	LR 0.091354	Time 0.311 (0.311)	Data 0.000 (0.001)	Loss 0.3576 (0.4000)	Prec@1 91.406 (87.738)
Epoch: [19][250/573]	LR 0.091354	Time 0.311 (0.311)	Data 0.000 (0.001)	Loss 0.2686 (0.3986)	Prec@1 91.406 (87.812)
Epoch: [19][300/573]	LR 0.091354	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.3667 (0.3971)	Prec@1 89.062 (87.828)
Epoch: [19][350/573]	LR 0.091354	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4324 (0.3972)	Prec@1 87.500 (87.828)
Epoch: [19][400/573]	LR 0.091354	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.5339 (0.3989)	Prec@1 82.031 (87.758)
Epoch: [19][450/573]	LR 0.091354	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4910 (0.3971)	Prec@1 85.156 (87.809)
Epoch: [19][500/573]	LR 0.091354	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4361 (0.3974)	Prec@1 85.938 (87.806)
Epoch: [19][550/573]	LR 0.091354	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4012 (0.3991)	Prec@1 90.625 (87.741)
Epoch: [19][573/573]	LR 0.091354	Time 0.141 (0.312)	Data 0.000 (0.001)	Loss 0.2172 (0.3986)	Prec@1 92.683 (87.762)
****************************************
test_set:	 * Prec@1 89.501
****************************************
Epoch: [20][50/573]	LR 0.090451	Time 0.312 (0.315)	Data 0.000 (0.004)	Loss 0.3905 (0.3688)	Prec@1 87.500 (88.703)
Epoch: [20][100/573]	LR 0.090451	Time 0.312 (0.312)	Data 0.000 (0.002)	Loss 0.6247 (0.3855)	Prec@1 79.688 (88.156)
Epoch: [20][150/573]	LR 0.090451	Time 0.311 (0.311)	Data 0.000 (0.001)	Loss 0.3432 (0.3878)	Prec@1 89.062 (88.031)
Epoch: [20][200/573]	LR 0.090451	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.4934 (0.3888)	Prec@1 82.031 (87.988)
Epoch: [20][250/573]	LR 0.090451	Time 0.310 (0.311)	Data 0.000 (0.001)	Loss 0.3160 (0.3880)	Prec@1 92.188 (88.047)
Epoch: [20][300/573]	LR 0.090451	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4820 (0.3930)	Prec@1 83.594 (87.904)
Epoch: [20][350/573]	LR 0.090451	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.3390 (0.3936)	Prec@1 92.188 (87.929)
Epoch: [20][400/573]	LR 0.090451	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.4034 (0.3935)	Prec@1 89.062 (87.990)
Epoch: [20][450/573]	LR 0.090451	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.5394 (0.3946)	Prec@1 84.375 (87.958)
Epoch: [20][500/573]	LR 0.090451	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.3982 (0.3974)	Prec@1 86.719 (87.872)
Epoch: [20][550/573]	LR 0.090451	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.2858 (0.3956)	Prec@1 91.406 (87.911)
Epoch: [20][573/573]	LR 0.090451	Time 0.140 (0.312)	Data 0.000 (0.001)	Loss 0.7070 (0.3954)	Prec@1 73.171 (87.906)
****************************************
test_set:	 * Prec@1 88.871
****************************************
Epoch: [21][50/573]	LR 0.089508	Time 0.312 (0.316)	Data 0.000 (0.004)	Loss 0.3990 (0.4161)	Prec@1 87.500 (87.109)
Epoch: [21][100/573]	LR 0.089508	Time 0.311 (0.313)	Data 0.000 (0.002)	Loss 0.4029 (0.4043)	Prec@1 88.281 (87.531)
Epoch: [21][150/573]	LR 0.089508	Time 0.312 (0.311)	Data 0.000 (0.002)	Loss 0.3333 (0.3954)	Prec@1 89.844 (87.901)
Epoch: [21][200/573]	LR 0.089508	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.3367 (0.3987)	Prec@1 90.625 (87.719)
Epoch: [21][250/573]	LR 0.089508	Time 0.310 (0.311)	Data 0.000 (0.001)	Loss 0.3446 (0.3988)	Prec@1 89.062 (87.719)
Epoch: [21][300/573]	LR 0.089508	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4070 (0.3976)	Prec@1 88.281 (87.807)
Epoch: [21][350/573]	LR 0.089508	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.4087 (0.3968)	Prec@1 88.281 (87.783)
Epoch: [21][400/573]	LR 0.089508	Time 0.313 (0.312)	Data 0.000 (0.001)	Loss 0.3383 (0.3926)	Prec@1 88.281 (87.971)
Epoch: [21][450/573]	LR 0.089508	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.5138 (0.3899)	Prec@1 85.156 (88.068)
Epoch: [21][500/573]	LR 0.089508	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.3531 (0.3918)	Prec@1 92.188 (88.022)
Epoch: [21][550/573]	LR 0.089508	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4036 (0.3916)	Prec@1 88.281 (88.024)
Epoch: [21][573/573]	LR 0.089508	Time 0.140 (0.312)	Data 0.000 (0.001)	Loss 0.5198 (0.3921)	Prec@1 87.805 (87.994)
****************************************
test_set:	 * Prec@1 91.007
****************************************
Epoch: [22][50/573]	LR 0.088526	Time 0.313 (0.316)	Data 0.001 (0.004)	Loss 0.4379 (0.3922)	Prec@1 88.281 (87.781)
Epoch: [22][100/573]	LR 0.088526	Time 0.312 (0.313)	Data 0.000 (0.002)	Loss 0.4654 (0.3876)	Prec@1 85.156 (88.023)
Epoch: [22][150/573]	LR 0.088526	Time 0.312 (0.312)	Data 0.000 (0.002)	Loss 0.3870 (0.3895)	Prec@1 87.500 (87.979)
Epoch: [22][200/573]	LR 0.088526	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.2275 (0.3884)	Prec@1 92.969 (88.004)
Epoch: [22][250/573]	LR 0.088526	Time 0.311 (0.311)	Data 0.000 (0.001)	Loss 0.3125 (0.3912)	Prec@1 88.281 (87.953)
Epoch: [22][300/573]	LR 0.088526	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.3463 (0.3907)	Prec@1 92.969 (88.049)
Epoch: [22][350/573]	LR 0.088526	Time 0.313 (0.311)	Data 0.000 (0.001)	Loss 0.4154 (0.3901)	Prec@1 85.156 (88.020)
Epoch: [22][400/573]	LR 0.088526	Time 0.312 (0.311)	Data 0.000 (0.001)	Loss 0.3389 (0.3899)	Prec@1 89.844 (88.023)
Epoch: [22][450/573]	LR 0.088526	Time 0.314 (0.311)	Data 0.000 (0.001)	Loss 0.4091 (0.3901)	Prec@1 85.156 (88.002)
Epoch: [22][500/573]	LR 0.088526	Time 0.313 (0.312)	Data 0.000 (0.001)	Loss 0.3043 (0.3910)	Prec@1 92.188 (87.981)
Epoch: [22][550/573]	LR 0.088526	Time 0.314 (0.312)	Data 0.000 (0.001)	Loss 0.4349 (0.3915)	Prec@1 87.500 (87.993)
Epoch: [22][573/573]	LR 0.088526	Time 0.141 (0.312)	Data 0.000 (0.001)	Loss 0.2881 (0.3913)	Prec@1 92.683 (88.019)
****************************************
test_set:	 * Prec@1 91.530
****************************************
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main()
  File "main.py", line 160, in main
    train(train_loader, model, criterion, optimizer, epoch)
  File "main.py", line 238, in train
    losses.update(loss.item(), input.size(0))
KeyboardInterrupt
Namespace(arch='resnet18', base_width=64, batch_size=128, data_root='../DATASETS/SVHN', dataset='SVHN', epochs=100, evaluate=False, loss='ce', lr=0.1, lr_gamma=0.1, lr_milestones=[40, 80], lr_schedule='cosine', momentum=0.9, noise_info=None, noise_rate=0.4, noise_type='shuffled_pixels', optimizer='sgd', print_freq=50, result_dir='results/SVHN/resnet18_ce_shuffled_pixels_r0.4_cosine_', resume='', sat_alpha=0.9, sat_es=0, save_dir='ckpts/SVHN/resnet18_ce_shuffled_pixels_r0.4_cosine_', save_freq=0, seed=4773, start_epoch=0, train_sets='trainval', turn_off_aug=False, use_refined_label=False, val_sets=['test_set'], weight_decay=0.0005, workers=4)
Using downloaded and verified file: ../DATASETS/SVHN/train_32x32.mat
Traceback (most recent call last):
  File "main.py", line 310, in <module>
    main()
  File "main.py", line 124, in main
    train_loader, val_loaders, test_loader, num_classes, targets = get_loader(args)
  File "/home/jovyan/work/Mitigating-overfitting-via-self-adaptive-training/datasets/loaders.py", line 43, in get_loader
    clean_train_set = SVHN(root=args.data_root, split='train', download=True, transform=tform_train)
  File "/home/jovyan/work/Mitigating-overfitting-via-self-adaptive-training/datasets/datasets.py", line 76, in __init__
    target_transform=target_transform, download=download)
  File "/opt/conda/lib/python3.6/site-packages/torchvision/datasets/svhn.py", line 70, in __init__
    loaded_mat = sio.loadmat(os.path.join(self.root, self.filename))
  File "/opt/conda/lib/python3.6/site-packages/scipy/io/matlab/mio.py", line 218, in loadmat
    matfile_dict = MR.get_variables(variable_names)
  File "/opt/conda/lib/python3.6/site-packages/scipy/io/matlab/mio5.py", line 292, in get_variables
    res = self.read_var_array(hdr, process)
  File "/opt/conda/lib/python3.6/site-packages/scipy/io/matlab/mio5.py", line 252, in read_var_array
    return self._matrix_reader.array_from_header(header, process)
KeyboardInterrupt
