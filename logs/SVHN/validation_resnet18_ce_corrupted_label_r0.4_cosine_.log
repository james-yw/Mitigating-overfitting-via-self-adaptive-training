Namespace(arch='resnet18', base_width=64, batch_size=128, data_root='../DATASETS/SVHN', dataset='SVHN', epochs=100, evaluate=False, loss='ce', lr=0.1, lr_gamma=0.1, lr_milestones=[40, 80], lr_schedule='cosine', momentum=0.9, noise_info=None, noise_rate=0.4, noise_type='corrupted_label', optimizer='sgd', print_freq=50, result_dir='./result/SVHN', resume='', sat_alpha=0.9, sat_es=0, save_dir='ckpts/SVHN/validation_resnet18_ce_corrupted_label_r0.4_cosine_', save_freq=0, seed=2973, start_epoch=0, train_sets='train', turn_off_aug=False, use_refined_label=False, val_sets=['clean_train', 'noisy_train', 'clean_val', 'noisy_val'], weight_decay=0.0005, workers=4)
Using downloaded and verified file: ../DATASETS/SVHN/train_32x32.mat
data shape: (73257, 3, 32, 32)
Using downloaded and verified file: ../DATASETS/SVHN/test_32x32.mat
data shape: (26032, 3, 32, 32)
Randomizing 40.0 percent of labels 
Noisy labels saved to ckpts/SVHN/validation_resnet18_ce_corrupted_label_r0.4_cosine_/noisy_idx_labels.npy
Size of dataset: 73257.
Label error rate: 0.36.
Using `SGD` optimizer
Using `cosine` schedule
****************************************
Epoch: [0][50/516]	LR 0.100000	Time 0.040 (0.074)	Data 0.000 (0.013)	Loss 2.3019 (3.1846)	Prec@1 15.625 (13.234)
Epoch: [0][100/516]	LR 0.100000	Time 0.040 (0.057)	Data 0.000 (0.007)	Loss 2.3375 (2.7394)	Prec@1 14.062 (14.336)
Epoch: [0][150/516]	LR 0.100000	Time 0.040 (0.052)	Data 0.000 (0.004)	Loss 2.2813 (2.5851)	Prec@1 12.500 (14.891)
Epoch: [0][200/516]	LR 0.100000	Time 0.040 (0.049)	Data 0.000 (0.003)	Loss 2.2571 (2.5092)	Prec@1 17.969 (14.941)
Epoch: [0][250/516]	LR 0.100000	Time 0.045 (0.047)	Data 0.000 (0.003)	Loss 2.2552 (2.4645)	Prec@1 17.188 (14.791)
Epoch: [0][300/516]	LR 0.100000	Time 0.040 (0.046)	Data 0.000 (0.002)	Loss 2.2610 (2.4326)	Prec@1 17.188 (14.966)
Epoch: [0][350/516]	LR 0.100000	Time 0.040 (0.045)	Data 0.000 (0.002)	Loss 2.2637 (2.4111)	Prec@1 20.312 (14.953)
Epoch: [0][400/516]	LR 0.100000	Time 0.040 (0.045)	Data 0.000 (0.002)	Loss 2.3006 (2.3940)	Prec@1 11.719 (15.057)
Epoch: [0][450/516]	LR 0.100000	Time 0.040 (0.044)	Data 0.000 (0.002)	Loss 2.2678 (2.3816)	Prec@1 18.750 (15.115)
Epoch: [0][500/516]	LR 0.100000	Time 0.040 (0.044)	Data 0.000 (0.001)	Loss 2.3432 (2.3706)	Prec@1 10.938 (15.211)
Epoch: [0][516/516]	LR 0.100000	Time 0.152 (0.044)	Data 0.000 (0.001)	Loss 2.4517 (2.3677)	Prec@1 9.091 (15.211)
****************************************
clean_train:	 * Prec@1 18.947
noisy_train:	 * Prec@1 15.598
clean_val:	 * Prec@1 18.905
noisy_val:	 * Prec@1 15.220
****************************************
Epoch: [1][50/516]	LR 0.099975	Time 0.040 (0.046)	Data 0.000 (0.006)	Loss 2.2884 (2.2822)	Prec@1 13.281 (15.062)
Epoch: [1][100/516]	LR 0.099975	Time 0.040 (0.044)	Data 0.000 (0.003)	Loss 2.2763 (2.2788)	Prec@1 13.281 (15.523)
Epoch: [1][150/516]	LR 0.099975	Time 0.040 (0.043)	Data 0.000 (0.002)	Loss 2.3065 (2.2782)	Prec@1 17.188 (15.526)
Epoch: [1][200/516]	LR 0.099975	Time 0.041 (0.042)	Data 0.000 (0.002)	Loss 2.2401 (2.2780)	Prec@1 15.625 (15.531)
Epoch: [1][250/516]	LR 0.099975	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.3185 (2.2775)	Prec@1 13.281 (15.537)
Epoch: [1][300/516]	LR 0.099975	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.2648 (2.2772)	Prec@1 17.969 (15.625)
Epoch: [1][350/516]	LR 0.099975	Time 0.042 (0.042)	Data 0.000 (0.001)	Loss 2.2625 (2.2774)	Prec@1 16.406 (15.594)
Epoch: [1][400/516]	LR 0.099975	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.2792 (2.2776)	Prec@1 13.281 (15.592)
Epoch: [1][450/516]	LR 0.099975	Time 0.040 (0.041)	Data 0.000 (0.001)	Loss 2.2924 (2.2769)	Prec@1 11.719 (15.630)
Epoch: [1][500/516]	LR 0.099975	Time 0.040 (0.041)	Data 0.000 (0.001)	Loss 2.2565 (2.2774)	Prec@1 15.625 (15.567)
Epoch: [1][516/516]	LR 0.099975	Time 0.016 (0.041)	Data 0.000 (0.001)	Loss 2.3526 (2.2774)	Prec@1 9.091 (15.557)
****************************************
clean_train:	 * Prec@1 18.932
noisy_train:	 * Prec@1 15.589
clean_val:	 * Prec@1 18.796
noisy_val:	 * Prec@1 15.124
****************************************
Epoch: [2][50/516]	LR 0.099901	Time 0.040 (0.047)	Data 0.000 (0.006)	Loss 2.2713 (2.2779)	Prec@1 16.406 (15.641)
Epoch: [2][100/516]	LR 0.099901	Time 0.041 (0.044)	Data 0.000 (0.003)	Loss 2.2485 (2.2767)	Prec@1 19.531 (15.797)
Epoch: [2][150/516]	LR 0.099901	Time 0.041 (0.043)	Data 0.000 (0.002)	Loss 2.2901 (2.2771)	Prec@1 15.625 (15.802)
Epoch: [2][200/516]	LR 0.099901	Time 0.043 (0.042)	Data 0.000 (0.002)	Loss 2.2839 (2.2770)	Prec@1 12.500 (15.641)
Epoch: [2][250/516]	LR 0.099901	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.2958 (2.2771)	Prec@1 15.625 (15.628)
Epoch: [2][300/516]	LR 0.099901	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.2582 (2.2777)	Prec@1 17.188 (15.516)
Epoch: [2][350/516]	LR 0.099901	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.2752 (2.2775)	Prec@1 15.625 (15.464)
Epoch: [2][400/516]	LR 0.099901	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 2.2721 (2.2776)	Prec@1 14.844 (15.436)
Epoch: [2][450/516]	LR 0.099901	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 2.2602 (2.2772)	Prec@1 17.969 (15.432)
Epoch: [2][500/516]	LR 0.099901	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 2.2776 (2.2769)	Prec@1 17.969 (15.536)
Epoch: [2][516/516]	LR 0.099901	Time 0.017 (0.042)	Data 0.000 (0.001)	Loss 2.2548 (2.2766)	Prec@1 18.182 (15.547)
****************************************
clean_train:	 * Prec@1 18.927
noisy_train:	 * Prec@1 15.578
clean_val:	 * Prec@1 18.851
noisy_val:	 * Prec@1 15.165
****************************************
Epoch: [3][50/516]	LR 0.099778	Time 0.041 (0.047)	Data 0.000 (0.006)	Loss 2.2593 (2.2817)	Prec@1 17.188 (13.781)
Epoch: [3][100/516]	LR 0.099778	Time 0.041 (0.044)	Data 0.000 (0.003)	Loss 2.3239 (2.2742)	Prec@1 10.156 (14.969)
Epoch: [3][150/516]	LR 0.099778	Time 0.043 (0.043)	Data 0.000 (0.002)	Loss 2.2756 (2.2738)	Prec@1 19.531 (15.375)
Epoch: [3][200/516]	LR 0.099778	Time 0.041 (0.043)	Data 0.000 (0.002)	Loss 2.2430 (2.2758)	Prec@1 18.750 (15.328)
Epoch: [3][250/516]	LR 0.099778	Time 0.041 (0.043)	Data 0.000 (0.001)	Loss 2.2454 (2.2747)	Prec@1 20.312 (15.506)
Epoch: [3][300/516]	LR 0.099778	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 2.2700 (2.2722)	Prec@1 17.188 (15.862)
Epoch: [3][350/516]	LR 0.099778	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 2.2106 (2.2670)	Prec@1 21.094 (16.324)
Epoch: [3][400/516]	LR 0.099778	Time 0.045 (0.042)	Data 0.000 (0.001)	Loss 2.1894 (2.2601)	Prec@1 21.094 (16.824)
Epoch: [3][450/516]	LR 0.099778	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 2.1464 (2.2520)	Prec@1 24.219 (17.335)
Epoch: [3][500/516]	LR 0.099778	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 2.2165 (2.2416)	Prec@1 18.750 (18.073)
Epoch: [3][516/516]	LR 0.099778	Time 0.014 (0.042)	Data 0.000 (0.001)	Loss 1.9102 (2.2379)	Prec@1 63.636 (18.339)
****************************************
clean_train:	 * Prec@1 32.419
noisy_train:	 * Prec@1 23.520
clean_val:	 * Prec@1 32.364
noisy_val:	 * Prec@1 23.055
****************************************
Epoch: [4][50/516]	LR 0.099606	Time 0.041 (0.046)	Data 0.000 (0.005)	Loss 2.2045 (2.1334)	Prec@1 25.000 (24.750)
Epoch: [4][100/516]	LR 0.099606	Time 0.041 (0.044)	Data 0.000 (0.003)	Loss 2.0663 (2.1316)	Prec@1 28.125 (25.336)
Epoch: [4][150/516]	LR 0.099606	Time 0.041 (0.043)	Data 0.000 (0.002)	Loss 2.0641 (2.1200)	Prec@1 26.562 (26.198)
Epoch: [4][200/516]	LR 0.099606	Time 0.042 (0.042)	Data 0.000 (0.002)	Loss 1.9820 (2.1102)	Prec@1 33.594 (26.715)
Epoch: [4][250/516]	LR 0.099606	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.9486 (2.0968)	Prec@1 36.719 (27.609)
Epoch: [4][300/516]	LR 0.099606	Time 0.040 (0.042)	Data 0.000 (0.001)	Loss 1.9178 (2.0830)	Prec@1 36.719 (28.505)
Epoch: [4][350/516]	LR 0.099606	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.7987 (2.0666)	Prec@1 42.188 (29.643)
Epoch: [4][400/516]	LR 0.099606	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.8059 (2.0476)	Prec@1 36.719 (30.889)
Epoch: [4][450/516]	LR 0.099606	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.7778 (2.0321)	Prec@1 47.656 (31.927)
Epoch: [4][500/516]	LR 0.099606	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.8163 (2.0145)	Prec@1 44.531 (33.017)
Epoch: [4][516/516]	LR 0.099606	Time 0.015 (0.042)	Data 0.000 (0.001)	Loss 1.7065 (2.0084)	Prec@1 54.545 (33.380)
****************************************
clean_train:	 * Prec@1 59.195
noisy_train:	 * Prec@1 39.452
clean_val:	 * Prec@1 58.668
noisy_val:	 * Prec@1 39.203
****************************************
Epoch: [5][50/516]	LR 0.099384	Time 0.040 (0.046)	Data 0.000 (0.005)	Loss 1.8605 (1.8440)	Prec@1 43.750 (44.703)
Epoch: [5][100/516]	LR 0.099384	Time 0.040 (0.044)	Data 0.000 (0.003)	Loss 1.8376 (1.8322)	Prec@1 46.094 (45.242)
Epoch: [5][150/516]	LR 0.099384	Time 0.041 (0.043)	Data 0.000 (0.002)	Loss 1.8153 (1.8117)	Prec@1 46.094 (46.406)
Epoch: [5][200/516]	LR 0.099384	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.8411 (1.7900)	Prec@1 50.000 (47.590)
Epoch: [5][250/516]	LR 0.099384	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.6837 (1.7786)	Prec@1 52.344 (48.122)
Epoch: [5][300/516]	LR 0.099384	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.8201 (1.7675)	Prec@1 46.094 (48.643)
Epoch: [5][350/516]	LR 0.099384	Time 0.045 (0.042)	Data 0.001 (0.001)	Loss 1.5714 (1.7593)	Prec@1 57.031 (49.036)
Epoch: [5][400/516]	LR 0.099384	Time 0.044 (0.042)	Data 0.000 (0.001)	Loss 1.6150 (1.7530)	Prec@1 52.344 (49.430)
Epoch: [5][450/516]	LR 0.099384	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.7421 (1.7496)	Prec@1 49.219 (49.665)
Epoch: [5][500/516]	LR 0.099384	Time 0.041 (0.042)	Data 0.000 (0.001)	Loss 1.8593 (1.7455)	Prec@1 48.438 (49.869)
Epoch: [5][516/516]	LR 0.099384	Time 0.015 (0.042)	Data 0.000 (0.001)	Loss 2.2764 (1.7440)	Prec@1 36.364 (49.919)
****************************************
clean_train:	 * Prec@1 72.081
noisy_train:	 * Prec@1 47.419
clean_val:	 * Prec@1 71.895
noisy_val:	 * Prec@1 46.901
****************************************
Epoch: [6][50/516]	LR 0.099114	Time 0.040 (0.056)	Data 0.000 (0.008)	Loss 1.7443 (1.6873)	Prec@1 50.000 (53.281)
Epoch: [6][100/516]	LR 0.099114	Time 0.041 (0.049)	Data 0.000 (0.004)	Loss 1.9090 (1.6926)	Prec@1 47.656 (52.750)
Epoch: [6][150/516]	LR 0.099114	Time 0.041 (0.046)	Data 0.000 (0.003)	Loss 1.8538 (1.6903)	Prec@1 49.219 (53.031)
Epoch: [6][200/516]	LR 0.099114	Time 0.044 (0.045)	Data 0.000 (0.002)	Loss 1.6042 (1.6853)	Prec@1 55.469 (53.238)
Epoch: [6][250/516]	LR 0.099114	Time 0.041 (0.045)	Data 0.000 (0.002)	Loss 1.7035 (1.6834)	Prec@1 53.125 (53.319)
Epoch: [6][300/516]	LR 0.099114	Time 0.042 (0.044)	Data 0.000 (0.002)	Loss 1.8439 (1.6782)	Prec@1 43.750 (53.539)
Epoch: [6][350/516]	LR 0.099114	Time 0.046 (0.044)	Data 0.000 (0.001)	Loss 1.8128 (1.6759)	Prec@1 49.219 (53.679)
Epoch: [6][400/516]	LR 0.099114	Time 0.042 (0.044)	Data 0.000 (0.001)	Loss 1.6851 (1.6758)	Prec@1 53.125 (53.711)
Epoch: [6][450/516]	LR 0.099114	Time 0.042 (0.045)	Data 0.000 (0.002)	Loss 1.7745 (1.6682)	Prec@1 49.219 (53.970)
Epoch: [6][500/516]	LR 0.099114	Time 0.041 (0.048)	Data 0.000 (0.005)	Loss 1.8248 (1.6672)	Prec@1 49.219 (53.994)
Epoch: [6][516/516]	LR 0.099114	Time 0.165 (0.048)	Data 0.000 (0.006)	Loss 1.2417 (1.6676)	Prec@1 72.727 (53.990)
****************************************
clean_train:	 * Prec@1 66.374
noisy_train:	 * Prec@1 43.940
clean_val:	 * Prec@1 66.230
noisy_val:	 * Prec@1 43.434
****************************************
Epoch: [7][50/516]	LR 0.098796	Time 0.082 (0.097)	Data 0.000 (0.009)	Loss 1.8254 (1.6363)	Prec@1 45.312 (55.094)
Epoch: [7][100/516]	LR 0.098796	Time 0.083 (0.090)	Data 0.000 (0.005)	Loss 1.7824 (1.6436)	Prec@1 50.781 (54.852)
Epoch: [7][150/516]	LR 0.098796	Time 0.083 (0.087)	Data 0.000 (0.003)	Loss 1.5248 (1.6453)	Prec@1 59.375 (54.698)
Epoch: [7][200/516]	LR 0.098796	Time 0.085 (0.086)	Data 0.000 (0.003)	Loss 1.6684 (1.6424)	Prec@1 54.688 (54.992)
Epoch: [7][250/516]	LR 0.098796	Time 0.088 (0.086)	Data 0.000 (0.002)	Loss 1.6638 (1.6455)	Prec@1 51.562 (54.850)
Epoch: [7][300/516]	LR 0.098796	Time 0.082 (0.085)	Data 0.000 (0.002)	Loss 1.6984 (1.6434)	Prec@1 52.344 (54.990)
Epoch: [7][350/516]	LR 0.098796	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.6797 (1.6465)	Prec@1 54.688 (54.924)
Epoch: [7][400/516]	LR 0.098796	Time 0.078 (0.085)	Data 0.000 (0.001)	Loss 1.6729 (1.6441)	Prec@1 54.688 (55.031)
Epoch: [7][450/516]	LR 0.098796	Time 0.080 (0.085)	Data 0.000 (0.001)	Loss 1.5723 (1.6428)	Prec@1 59.375 (55.056)
Epoch: [7][500/516]	LR 0.098796	Time 0.079 (0.084)	Data 0.000 (0.001)	Loss 1.6734 (1.6420)	Prec@1 52.344 (55.062)
Epoch: [7][516/516]	LR 0.098796	Time 0.045 (0.084)	Data 0.000 (0.001)	Loss 1.4185 (1.6411)	Prec@1 63.636 (55.091)
****************************************
clean_train:	 * Prec@1 83.457
noisy_train:	 * Prec@1 54.260
clean_val:	 * Prec@1 83.443
noisy_val:	 * Prec@1 53.822
****************************************
Epoch: [8][50/516]	LR 0.098429	Time 0.083 (0.075)	Data 0.000 (0.008)	Loss 1.7235 (1.6491)	Prec@1 50.781 (55.125)
Epoch: [8][100/516]	LR 0.098429	Time 0.081 (0.079)	Data 0.000 (0.004)	Loss 1.6551 (1.6507)	Prec@1 51.562 (54.945)
Epoch: [8][150/516]	LR 0.098429	Time 0.081 (0.080)	Data 0.000 (0.003)	Loss 1.5811 (1.6405)	Prec@1 59.375 (55.333)
Epoch: [8][200/516]	LR 0.098429	Time 0.089 (0.081)	Data 0.000 (0.002)	Loss 1.6452 (1.6402)	Prec@1 54.688 (55.438)
Epoch: [8][250/516]	LR 0.098429	Time 0.089 (0.081)	Data 0.000 (0.002)	Loss 1.6222 (1.6388)	Prec@1 54.688 (55.372)
Epoch: [8][300/516]	LR 0.098429	Time 0.081 (0.081)	Data 0.000 (0.002)	Loss 1.6195 (1.6335)	Prec@1 55.469 (55.609)
Epoch: [8][350/516]	LR 0.098429	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 1.5993 (1.6334)	Prec@1 57.031 (55.592)
Epoch: [8][400/516]	LR 0.098429	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.7317 (1.6334)	Prec@1 53.906 (55.605)
Epoch: [8][450/516]	LR 0.098429	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 1.6081 (1.6333)	Prec@1 57.031 (55.597)
Epoch: [8][500/516]	LR 0.098429	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 1.5018 (1.6307)	Prec@1 61.719 (55.684)
Epoch: [8][516/516]	LR 0.098429	Time 0.027 (0.082)	Data 0.000 (0.001)	Loss 1.4515 (1.6295)	Prec@1 72.727 (55.734)
****************************************
clean_train:	 * Prec@1 84.188
noisy_train:	 * Prec@1 54.704
clean_val:	 * Prec@1 84.562
noisy_val:	 * Prec@1 54.450
****************************************
Epoch: [9][50/516]	LR 0.098015	Time 0.092 (0.092)	Data 0.000 (0.005)	Loss 1.5291 (1.6127)	Prec@1 58.594 (56.516)
Epoch: [9][100/516]	LR 0.098015	Time 0.087 (0.086)	Data 0.000 (0.003)	Loss 1.6350 (1.5959)	Prec@1 56.250 (57.242)
Epoch: [9][150/516]	LR 0.098015	Time 0.080 (0.078)	Data 0.000 (0.002)	Loss 1.5611 (1.6027)	Prec@1 57.812 (56.958)
Epoch: [9][200/516]	LR 0.098015	Time 0.082 (0.079)	Data 0.000 (0.001)	Loss 1.8087 (1.6093)	Prec@1 50.000 (56.512)
Epoch: [9][250/516]	LR 0.098015	Time 0.087 (0.080)	Data 0.000 (0.001)	Loss 1.7142 (1.6143)	Prec@1 53.125 (56.306)
Epoch: [9][300/516]	LR 0.098015	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 1.7353 (1.6126)	Prec@1 51.562 (56.424)
Epoch: [9][350/516]	LR 0.098015	Time 0.079 (0.081)	Data 0.000 (0.001)	Loss 1.4808 (1.6126)	Prec@1 59.375 (56.406)
Epoch: [9][400/516]	LR 0.098015	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.7574 (1.6166)	Prec@1 50.000 (56.217)
Epoch: [9][450/516]	LR 0.098015	Time 0.082 (0.081)	Data 0.000 (0.001)	Loss 1.6846 (1.6167)	Prec@1 52.344 (56.189)
Epoch: [9][500/516]	LR 0.098015	Time 0.081 (0.081)	Data 0.001 (0.001)	Loss 1.5031 (1.6157)	Prec@1 63.281 (56.241)
Epoch: [9][516/516]	LR 0.098015	Time 0.021 (0.081)	Data 0.000 (0.001)	Loss 1.7419 (1.6159)	Prec@1 45.455 (56.236)
****************************************
clean_train:	 * Prec@1 84.230
noisy_train:	 * Prec@1 54.710
clean_val:	 * Prec@1 84.384
noisy_val:	 * Prec@1 54.436
****************************************
Epoch: [10][50/516]	LR 0.097553	Time 0.088 (0.084)	Data 0.000 (0.005)	Loss 1.5959 (1.6216)	Prec@1 57.031 (55.891)
Epoch: [10][100/516]	LR 0.097553	Time 0.088 (0.086)	Data 0.000 (0.002)	Loss 1.5068 (1.6320)	Prec@1 60.156 (55.656)
Epoch: [10][150/516]	LR 0.097553	Time 0.084 (0.086)	Data 0.000 (0.002)	Loss 1.5462 (1.6292)	Prec@1 60.156 (55.750)
Epoch: [10][200/516]	LR 0.097553	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.5808 (1.6243)	Prec@1 58.594 (56.066)
Epoch: [10][250/516]	LR 0.097553	Time 0.041 (0.082)	Data 0.000 (0.001)	Loss 1.3826 (1.6188)	Prec@1 64.844 (56.275)
Epoch: [10][300/516]	LR 0.097553	Time 0.083 (0.080)	Data 0.000 (0.001)	Loss 1.5226 (1.6152)	Prec@1 60.156 (56.370)
Epoch: [10][350/516]	LR 0.097553	Time 0.078 (0.081)	Data 0.000 (0.001)	Loss 1.5713 (1.6128)	Prec@1 59.375 (56.455)
Epoch: [10][400/516]	LR 0.097553	Time 0.081 (0.081)	Data 0.000 (0.001)	Loss 1.5997 (1.6138)	Prec@1 54.688 (56.424)
Epoch: [10][450/516]	LR 0.097553	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 1.6821 (1.6146)	Prec@1 53.125 (56.384)
Epoch: [10][500/516]	LR 0.097553	Time 0.078 (0.081)	Data 0.000 (0.001)	Loss 1.6308 (1.6161)	Prec@1 55.469 (56.342)
Epoch: [10][516/516]	LR 0.097553	Time 0.022 (0.081)	Data 0.000 (0.001)	Loss 2.0761 (1.6167)	Prec@1 36.364 (56.304)
****************************************
clean_train:	 * Prec@1 86.122
noisy_train:	 * Prec@1 55.910
clean_val:	 * Prec@1 85.572
noisy_val:	 * Prec@1 55.119
****************************************
Epoch: [11][50/516]	LR 0.097044	Time 0.088 (0.092)	Data 0.000 (0.005)	Loss 1.4728 (1.6455)	Prec@1 63.281 (54.938)
Epoch: [11][100/516]	LR 0.097044	Time 0.086 (0.090)	Data 0.000 (0.002)	Loss 1.5803 (1.6329)	Prec@1 56.250 (55.727)
Epoch: [11][150/516]	LR 0.097044	Time 0.087 (0.086)	Data 0.000 (0.002)	Loss 1.4521 (1.6251)	Prec@1 60.938 (56.109)
Epoch: [11][200/516]	LR 0.097044	Time 0.087 (0.087)	Data 0.000 (0.001)	Loss 1.4654 (1.6247)	Prec@1 60.938 (56.156)
Epoch: [11][250/516]	LR 0.097044	Time 0.088 (0.087)	Data 0.000 (0.001)	Loss 1.7975 (1.6201)	Prec@1 49.219 (56.356)
Epoch: [11][300/516]	LR 0.097044	Time 0.089 (0.087)	Data 0.000 (0.001)	Loss 1.5130 (1.6194)	Prec@1 60.938 (56.383)
Epoch: [11][350/516]	LR 0.097044	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.5768 (1.6188)	Prec@1 58.594 (56.350)
Epoch: [11][400/516]	LR 0.097044	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 1.5057 (1.6144)	Prec@1 61.719 (56.514)
Epoch: [11][450/516]	LR 0.097044	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 1.5257 (1.6102)	Prec@1 59.375 (56.672)
Epoch: [11][500/516]	LR 0.097044	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.5554 (1.6098)	Prec@1 57.031 (56.648)
Epoch: [11][516/516]	LR 0.097044	Time 0.015 (0.082)	Data 0.000 (0.001)	Loss 1.7154 (1.6089)	Prec@1 45.455 (56.677)
****************************************
clean_train:	 * Prec@1 82.820
noisy_train:	 * Prec@1 53.920
clean_val:	 * Prec@1 82.856
noisy_val:	 * Prec@1 54.027
****************************************
Epoch: [12][50/516]	LR 0.096489	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 1.8309 (1.6057)	Prec@1 48.438 (56.391)
Epoch: [12][100/516]	LR 0.096489	Time 0.087 (0.082)	Data 0.000 (0.002)	Loss 1.7397 (1.6070)	Prec@1 51.562 (56.492)
Epoch: [12][150/516]	LR 0.096489	Time 0.090 (0.084)	Data 0.000 (0.002)	Loss 1.4560 (1.5975)	Prec@1 61.719 (57.021)
Epoch: [12][200/516]	LR 0.096489	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.7873 (1.6033)	Prec@1 53.906 (56.871)
Epoch: [12][250/516]	LR 0.096489	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.6879 (1.6039)	Prec@1 56.250 (56.888)
Epoch: [12][300/516]	LR 0.096489	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 1.6464 (1.6031)	Prec@1 57.812 (56.901)
Epoch: [12][350/516]	LR 0.096489	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.6160 (1.6075)	Prec@1 55.469 (56.685)
Epoch: [12][400/516]	LR 0.096489	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.6566 (1.6053)	Prec@1 53.906 (56.766)
Epoch: [12][450/516]	LR 0.096489	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.7153 (1.6062)	Prec@1 53.125 (56.741)
Epoch: [12][500/516]	LR 0.096489	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.6206 (1.6069)	Prec@1 57.031 (56.716)
Epoch: [12][516/516]	LR 0.096489	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 1.5204 (1.6075)	Prec@1 63.636 (56.690)
****************************************
clean_train:	 * Prec@1 86.938
noisy_train:	 * Prec@1 56.379
clean_val:	 * Prec@1 87.032
noisy_val:	 * Prec@1 56.047
****************************************
Epoch: [13][50/516]	LR 0.095888	Time 0.085 (0.088)	Data 0.000 (0.005)	Loss 1.5895 (1.6049)	Prec@1 57.812 (56.938)
Epoch: [13][100/516]	LR 0.095888	Time 0.085 (0.085)	Data 0.000 (0.003)	Loss 1.5709 (1.6065)	Prec@1 57.812 (56.836)
Epoch: [13][150/516]	LR 0.095888	Time 0.083 (0.084)	Data 0.000 (0.002)	Loss 1.5747 (1.6065)	Prec@1 57.031 (56.917)
Epoch: [13][200/516]	LR 0.095888	Time 0.041 (0.083)	Data 0.000 (0.001)	Loss 1.6315 (1.6045)	Prec@1 54.688 (56.957)
Epoch: [13][250/516]	LR 0.095888	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.4237 (1.6044)	Prec@1 64.844 (56.956)
Epoch: [13][300/516]	LR 0.095888	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.7577 (1.6018)	Prec@1 52.344 (57.039)
Epoch: [13][350/516]	LR 0.095888	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.8113 (1.6011)	Prec@1 48.438 (57.045)
Epoch: [13][400/516]	LR 0.095888	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 1.4652 (1.6011)	Prec@1 63.281 (57.041)
Epoch: [13][450/516]	LR 0.095888	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.7435 (1.6015)	Prec@1 53.125 (57.007)
Epoch: [13][500/516]	LR 0.095888	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.8586 (1.6020)	Prec@1 47.656 (56.994)
Epoch: [13][516/516]	LR 0.095888	Time 0.020 (0.084)	Data 0.000 (0.001)	Loss 1.6127 (1.6013)	Prec@1 45.455 (57.014)
****************************************
clean_train:	 * Prec@1 87.895
noisy_train:	 * Prec@1 56.990
clean_val:	 * Prec@1 87.046
noisy_val:	 * Prec@1 56.074
****************************************
Epoch: [14][50/516]	LR 0.095241	Time 0.083 (0.089)	Data 0.000 (0.006)	Loss 1.6303 (1.6453)	Prec@1 55.469 (54.625)
Epoch: [14][100/516]	LR 0.095241	Time 0.078 (0.085)	Data 0.000 (0.003)	Loss 1.7231 (1.6268)	Prec@1 53.125 (55.617)
Epoch: [14][150/516]	LR 0.095241	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.5438 (1.6219)	Prec@1 60.156 (55.938)
Epoch: [14][200/516]	LR 0.095241	Time 0.080 (0.084)	Data 0.000 (0.002)	Loss 1.4703 (1.6138)	Prec@1 62.500 (56.328)
Epoch: [14][250/516]	LR 0.095241	Time 0.085 (0.084)	Data 0.000 (0.001)	Loss 1.5819 (1.6065)	Prec@1 59.375 (56.663)
Epoch: [14][300/516]	LR 0.095241	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.5675 (1.6060)	Prec@1 57.812 (56.698)
Epoch: [14][350/516]	LR 0.095241	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 1.4593 (1.6043)	Prec@1 63.281 (56.781)
Epoch: [14][400/516]	LR 0.095241	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 1.5096 (1.6016)	Prec@1 58.594 (56.859)
Epoch: [14][450/516]	LR 0.095241	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6168 (1.5999)	Prec@1 56.250 (56.938)
Epoch: [14][500/516]	LR 0.095241	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.5988 (1.6013)	Prec@1 56.250 (56.903)
Epoch: [14][516/516]	LR 0.095241	Time 0.020 (0.084)	Data 0.000 (0.001)	Loss 2.0209 (1.6012)	Prec@1 36.364 (56.908)
****************************************
clean_train:	 * Prec@1 86.701
noisy_train:	 * Prec@1 56.259
clean_val:	 * Prec@1 86.432
noisy_val:	 * Prec@1 55.747
****************************************
Epoch: [15][50/516]	LR 0.094550	Time 0.083 (0.089)	Data 0.000 (0.004)	Loss 1.5675 (1.5873)	Prec@1 60.156 (57.703)
Epoch: [15][100/516]	LR 0.094550	Time 0.080 (0.086)	Data 0.000 (0.002)	Loss 1.7531 (1.5861)	Prec@1 53.125 (57.891)
Epoch: [15][150/516]	LR 0.094550	Time 0.082 (0.085)	Data 0.000 (0.002)	Loss 1.4886 (1.5905)	Prec@1 61.719 (57.536)
Epoch: [15][200/516]	LR 0.094550	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5812 (1.5945)	Prec@1 56.250 (57.328)
Epoch: [15][250/516]	LR 0.094550	Time 0.081 (0.085)	Data 0.000 (0.001)	Loss 1.8354 (1.5931)	Prec@1 50.000 (57.428)
Epoch: [15][300/516]	LR 0.094550	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.6937 (1.5969)	Prec@1 51.562 (57.247)
Epoch: [15][350/516]	LR 0.094550	Time 0.089 (0.084)	Data 0.000 (0.001)	Loss 1.6115 (1.5968)	Prec@1 57.031 (57.243)
Epoch: [15][400/516]	LR 0.094550	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.6632 (1.5976)	Prec@1 53.125 (57.234)
Epoch: [15][450/516]	LR 0.094550	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.4932 (1.5959)	Prec@1 62.500 (57.344)
Epoch: [15][500/516]	LR 0.094550	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6493 (1.5979)	Prec@1 55.469 (57.244)
Epoch: [15][516/516]	LR 0.094550	Time 0.020 (0.084)	Data 0.000 (0.001)	Loss 1.3534 (1.5979)	Prec@1 63.636 (57.223)
****************************************
clean_train:	 * Prec@1 86.635
noisy_train:	 * Prec@1 56.332
clean_val:	 * Prec@1 85.763
noisy_val:	 * Prec@1 55.283
****************************************
Epoch: [16][50/516]	LR 0.093815	Time 0.089 (0.087)	Data 0.000 (0.004)	Loss 1.7803 (1.6096)	Prec@1 51.562 (56.625)
Epoch: [16][100/516]	LR 0.093815	Time 0.089 (0.085)	Data 0.000 (0.002)	Loss 1.4121 (1.5957)	Prec@1 64.062 (57.383)
Epoch: [16][150/516]	LR 0.093815	Time 0.082 (0.085)	Data 0.000 (0.002)	Loss 1.5175 (1.5946)	Prec@1 59.375 (57.365)
Epoch: [16][200/516]	LR 0.093815	Time 0.080 (0.084)	Data 0.000 (0.001)	Loss 1.5444 (1.5916)	Prec@1 60.156 (57.453)
Epoch: [16][250/516]	LR 0.093815	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.6573 (1.5943)	Prec@1 53.906 (57.316)
Epoch: [16][300/516]	LR 0.093815	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.8221 (1.5961)	Prec@1 49.219 (57.268)
Epoch: [16][350/516]	LR 0.093815	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.5145 (1.5955)	Prec@1 61.719 (57.330)
Epoch: [16][400/516]	LR 0.093815	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 1.6558 (1.5955)	Prec@1 54.688 (57.332)
Epoch: [16][450/516]	LR 0.093815	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.6195 (1.5953)	Prec@1 57.031 (57.314)
Epoch: [16][500/516]	LR 0.093815	Time 0.085 (0.084)	Data 0.000 (0.001)	Loss 1.5128 (1.5930)	Prec@1 61.719 (57.398)
Epoch: [16][516/516]	LR 0.093815	Time 0.015 (0.083)	Data 0.000 (0.001)	Loss 1.4825 (1.5927)	Prec@1 63.636 (57.398)
****************************************
clean_train:	 * Prec@1 86.287
noisy_train:	 * Prec@1 56.103
clean_val:	 * Prec@1 85.708
noisy_val:	 * Prec@1 55.187
****************************************
Epoch: [17][50/516]	LR 0.093037	Time 0.083 (0.073)	Data 0.000 (0.004)	Loss 1.4040 (1.5852)	Prec@1 64.062 (57.641)
Epoch: [17][100/516]	LR 0.093037	Time 0.079 (0.078)	Data 0.000 (0.002)	Loss 1.6322 (1.5841)	Prec@1 56.250 (57.727)
Epoch: [17][150/516]	LR 0.093037	Time 0.085 (0.080)	Data 0.000 (0.002)	Loss 1.6181 (1.5955)	Prec@1 58.594 (57.240)
Epoch: [17][200/516]	LR 0.093037	Time 0.081 (0.081)	Data 0.000 (0.001)	Loss 1.4554 (1.5936)	Prec@1 60.938 (57.355)
Epoch: [17][250/516]	LR 0.093037	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 1.3713 (1.5919)	Prec@1 64.844 (57.472)
Epoch: [17][300/516]	LR 0.093037	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.6617 (1.5911)	Prec@1 57.031 (57.417)
Epoch: [17][350/516]	LR 0.093037	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 1.5815 (1.5927)	Prec@1 57.031 (57.411)
Epoch: [17][400/516]	LR 0.093037	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.5737 (1.5904)	Prec@1 57.812 (57.475)
Epoch: [17][450/516]	LR 0.093037	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 1.7790 (1.5892)	Prec@1 50.000 (57.503)
Epoch: [17][500/516]	LR 0.093037	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 1.5204 (1.5895)	Prec@1 60.156 (57.519)
Epoch: [17][516/516]	LR 0.093037	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 0.6582 (1.5893)	Prec@1 100.000 (57.518)
****************************************
clean_train:	 * Prec@1 89.119
noisy_train:	 * Prec@1 57.894
clean_val:	 * Prec@1 88.684
noisy_val:	 * Prec@1 57.125
****************************************
Epoch: [18][50/516]	LR 0.092216	Time 0.088 (0.091)	Data 0.000 (0.005)	Loss 1.6356 (1.5726)	Prec@1 54.688 (58.000)
Epoch: [18][100/516]	LR 0.092216	Time 0.090 (0.080)	Data 0.000 (0.002)	Loss 1.6757 (1.5734)	Prec@1 55.469 (58.047)
Epoch: [18][150/516]	LR 0.092216	Time 0.083 (0.076)	Data 0.000 (0.002)	Loss 1.4649 (1.5776)	Prec@1 58.594 (57.984)
Epoch: [18][200/516]	LR 0.092216	Time 0.081 (0.077)	Data 0.000 (0.001)	Loss 1.5057 (1.5819)	Prec@1 61.719 (57.895)
Epoch: [18][250/516]	LR 0.092216	Time 0.081 (0.079)	Data 0.000 (0.001)	Loss 1.4685 (1.5860)	Prec@1 61.719 (57.669)
Epoch: [18][300/516]	LR 0.092216	Time 0.084 (0.079)	Data 0.000 (0.001)	Loss 1.6686 (1.5877)	Prec@1 54.688 (57.544)
Epoch: [18][350/516]	LR 0.092216	Time 0.080 (0.080)	Data 0.000 (0.001)	Loss 1.6372 (1.5895)	Prec@1 53.906 (57.478)
Epoch: [18][400/516]	LR 0.092216	Time 0.083 (0.080)	Data 0.000 (0.001)	Loss 1.4426 (1.5892)	Prec@1 61.719 (57.520)
Epoch: [18][450/516]	LR 0.092216	Time 0.090 (0.081)	Data 0.000 (0.001)	Loss 1.5522 (1.5890)	Prec@1 59.375 (57.523)
Epoch: [18][500/516]	LR 0.092216	Time 0.078 (0.081)	Data 0.000 (0.001)	Loss 1.6605 (1.5867)	Prec@1 55.469 (57.648)
Epoch: [18][516/516]	LR 0.092216	Time 0.021 (0.081)	Data 0.000 (0.001)	Loss 1.3772 (1.5864)	Prec@1 63.636 (57.672)
****************************************
clean_train:	 * Prec@1 85.970
noisy_train:	 * Prec@1 55.874
clean_val:	 * Prec@1 85.326
noisy_val:	 * Prec@1 54.982
****************************************
Epoch: [19][50/516]	LR 0.091354	Time 0.091 (0.083)	Data 0.000 (0.005)	Loss 1.4814 (1.6114)	Prec@1 63.281 (56.219)
Epoch: [19][100/516]	LR 0.091354	Time 0.088 (0.085)	Data 0.000 (0.002)	Loss 1.6259 (1.5953)	Prec@1 56.250 (57.148)
Epoch: [19][150/516]	LR 0.091354	Time 0.085 (0.085)	Data 0.000 (0.002)	Loss 1.5065 (1.5922)	Prec@1 57.812 (57.307)
Epoch: [19][200/516]	LR 0.091354	Time 0.048 (0.083)	Data 0.000 (0.001)	Loss 1.5976 (1.5869)	Prec@1 57.031 (57.543)
Epoch: [19][250/516]	LR 0.091354	Time 0.067 (0.080)	Data 0.000 (0.001)	Loss 1.4262 (1.5882)	Prec@1 64.844 (57.534)
Epoch: [19][300/516]	LR 0.091354	Time 0.081 (0.080)	Data 0.000 (0.001)	Loss 1.7672 (1.5870)	Prec@1 50.781 (57.604)
Epoch: [19][350/516]	LR 0.091354	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 1.5317 (1.5910)	Prec@1 58.594 (57.469)
Epoch: [19][400/516]	LR 0.091354	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 1.5069 (1.5925)	Prec@1 60.938 (57.408)
Epoch: [19][450/516]	LR 0.091354	Time 0.068 (0.081)	Data 0.000 (0.001)	Loss 1.5770 (1.5898)	Prec@1 56.250 (57.519)
Epoch: [19][500/516]	LR 0.091354	Time 0.081 (0.081)	Data 0.000 (0.001)	Loss 1.6094 (1.5906)	Prec@1 57.812 (57.494)
Epoch: [19][516/516]	LR 0.091354	Time 0.020 (0.081)	Data 0.000 (0.001)	Loss 1.3488 (1.5899)	Prec@1 72.727 (57.510)
****************************************
clean_train:	 * Prec@1 88.285
noisy_train:	 * Prec@1 57.240
clean_val:	 * Prec@1 87.756
noisy_val:	 * Prec@1 56.511
****************************************
Epoch: [20][50/516]	LR 0.090451	Time 0.087 (0.092)	Data 0.000 (0.004)	Loss 1.6395 (1.6054)	Prec@1 55.469 (56.672)
Epoch: [20][100/516]	LR 0.090451	Time 0.088 (0.090)	Data 0.000 (0.002)	Loss 1.6282 (1.5860)	Prec@1 57.812 (57.398)
Epoch: [20][150/516]	LR 0.090451	Time 0.087 (0.086)	Data 0.000 (0.002)	Loss 1.7092 (1.5861)	Prec@1 52.344 (57.542)
Epoch: [20][200/516]	LR 0.090451	Time 0.089 (0.086)	Data 0.000 (0.001)	Loss 1.2752 (1.5817)	Prec@1 68.750 (57.766)
Epoch: [20][250/516]	LR 0.090451	Time 0.088 (0.086)	Data 0.000 (0.001)	Loss 1.5756 (1.5822)	Prec@1 57.812 (57.784)
Epoch: [20][300/516]	LR 0.090451	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5993 (1.5831)	Prec@1 57.812 (57.755)
Epoch: [20][350/516]	LR 0.090451	Time 0.041 (0.083)	Data 0.000 (0.001)	Loss 1.4789 (1.5841)	Prec@1 62.500 (57.743)
Epoch: [20][400/516]	LR 0.090451	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 1.5204 (1.5827)	Prec@1 57.812 (57.801)
Epoch: [20][450/516]	LR 0.090451	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.5774 (1.5852)	Prec@1 60.156 (57.705)
Epoch: [20][500/516]	LR 0.090451	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 1.6666 (1.5832)	Prec@1 55.469 (57.808)
Epoch: [20][516/516]	LR 0.090451	Time 0.020 (0.082)	Data 0.000 (0.001)	Loss 1.9472 (1.5840)	Prec@1 45.455 (57.788)
****************************************
clean_train:	 * Prec@1 83.613
noisy_train:	 * Prec@1 54.493
clean_val:	 * Prec@1 83.292
noisy_val:	 * Prec@1 53.877
****************************************
Epoch: [21][50/516]	LR 0.089508	Time 0.083 (0.088)	Data 0.000 (0.006)	Loss 1.6211 (1.6069)	Prec@1 54.688 (56.547)
Epoch: [21][100/516]	LR 0.089508	Time 0.088 (0.083)	Data 0.000 (0.003)	Loss 1.5165 (1.6020)	Prec@1 61.719 (56.781)
Epoch: [21][150/516]	LR 0.089508	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 1.5545 (1.5917)	Prec@1 63.281 (57.349)
Epoch: [21][200/516]	LR 0.089508	Time 0.088 (0.085)	Data 0.000 (0.002)	Loss 1.5084 (1.5878)	Prec@1 58.594 (57.430)
Epoch: [21][250/516]	LR 0.089508	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 1.5326 (1.5896)	Prec@1 60.938 (57.413)
Epoch: [21][300/516]	LR 0.089508	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4415 (1.5909)	Prec@1 64.062 (57.375)
Epoch: [21][350/516]	LR 0.089508	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5732 (1.5883)	Prec@1 56.250 (57.484)
Epoch: [21][400/516]	LR 0.089508	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.7897 (1.5872)	Prec@1 49.219 (57.543)
Epoch: [21][450/516]	LR 0.089508	Time 0.052 (0.083)	Data 0.000 (0.001)	Loss 1.5979 (1.5849)	Prec@1 56.250 (57.655)
Epoch: [21][500/516]	LR 0.089508	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 1.5326 (1.5862)	Prec@1 59.375 (57.600)
Epoch: [21][516/516]	LR 0.089508	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 1.1588 (1.5849)	Prec@1 72.727 (57.636)
****************************************
clean_train:	 * Prec@1 86.692
noisy_train:	 * Prec@1 56.307
clean_val:	 * Prec@1 86.486
noisy_val:	 * Prec@1 55.747
****************************************
Epoch: [22][50/516]	LR 0.088526	Time 0.083 (0.089)	Data 0.000 (0.005)	Loss 1.7912 (1.5883)	Prec@1 48.438 (57.703)
Epoch: [22][100/516]	LR 0.088526	Time 0.084 (0.086)	Data 0.000 (0.003)	Loss 1.6301 (1.5851)	Prec@1 54.688 (57.781)
Epoch: [22][150/516]	LR 0.088526	Time 0.080 (0.085)	Data 0.000 (0.002)	Loss 1.6555 (1.5782)	Prec@1 56.250 (57.948)
Epoch: [22][200/516]	LR 0.088526	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 1.5745 (1.5769)	Prec@1 56.250 (57.988)
Epoch: [22][250/516]	LR 0.088526	Time 0.090 (0.084)	Data 0.000 (0.001)	Loss 1.7502 (1.5795)	Prec@1 52.344 (57.913)
Epoch: [22][300/516]	LR 0.088526	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.6126 (1.5773)	Prec@1 55.469 (58.013)
Epoch: [22][350/516]	LR 0.088526	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5582 (1.5803)	Prec@1 57.812 (57.864)
Epoch: [22][400/516]	LR 0.088526	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4541 (1.5782)	Prec@1 62.500 (57.957)
Epoch: [22][450/516]	LR 0.088526	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6137 (1.5791)	Prec@1 56.250 (57.936)
Epoch: [22][500/516]	LR 0.088526	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5843 (1.5817)	Prec@1 56.250 (57.845)
Epoch: [22][516/516]	LR 0.088526	Time 0.020 (0.084)	Data 0.000 (0.001)	Loss 1.7650 (1.5809)	Prec@1 45.455 (57.868)
****************************************
clean_train:	 * Prec@1 88.409
noisy_train:	 * Prec@1 57.290
clean_val:	 * Prec@1 88.152
noisy_val:	 * Prec@1 56.934
****************************************
Epoch: [23][50/516]	LR 0.087506	Time 0.083 (0.087)	Data 0.000 (0.004)	Loss 1.6197 (1.5953)	Prec@1 56.250 (57.359)
Epoch: [23][100/516]	LR 0.087506	Time 0.080 (0.085)	Data 0.000 (0.002)	Loss 1.5425 (1.5911)	Prec@1 56.250 (57.422)
Epoch: [23][150/516]	LR 0.087506	Time 0.081 (0.084)	Data 0.000 (0.002)	Loss 1.4893 (1.5832)	Prec@1 62.500 (57.719)
Epoch: [23][200/516]	LR 0.087506	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.5396 (1.5854)	Prec@1 60.156 (57.516)
Epoch: [23][250/516]	LR 0.087506	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.6322 (1.5878)	Prec@1 56.250 (57.516)
Epoch: [23][300/516]	LR 0.087506	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 1.4964 (1.5847)	Prec@1 62.500 (57.669)
Epoch: [23][350/516]	LR 0.087506	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.4726 (1.5857)	Prec@1 61.719 (57.627)
Epoch: [23][400/516]	LR 0.087506	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.6704 (1.5825)	Prec@1 52.344 (57.770)
Epoch: [23][450/516]	LR 0.087506	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5116 (1.5816)	Prec@1 61.719 (57.821)
Epoch: [23][500/516]	LR 0.087506	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4607 (1.5809)	Prec@1 60.938 (57.837)
Epoch: [23][516/516]	LR 0.087506	Time 0.021 (0.084)	Data 0.000 (0.001)	Loss 1.6922 (1.5807)	Prec@1 45.455 (57.848)
****************************************
clean_train:	 * Prec@1 88.488
noisy_train:	 * Prec@1 57.481
clean_val:	 * Prec@1 88.397
noisy_val:	 * Prec@1 56.975
****************************************
Epoch: [24][50/516]	LR 0.086448	Time 0.088 (0.087)	Data 0.000 (0.005)	Loss 1.5849 (1.5937)	Prec@1 58.594 (57.359)
Epoch: [24][100/516]	LR 0.086448	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 1.4909 (1.5889)	Prec@1 59.375 (57.633)
Epoch: [24][150/516]	LR 0.086448	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 1.7728 (1.5793)	Prec@1 51.562 (58.099)
Epoch: [24][200/516]	LR 0.086448	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.6129 (1.5709)	Prec@1 56.250 (58.359)
Epoch: [24][250/516]	LR 0.086448	Time 0.071 (0.084)	Data 0.000 (0.001)	Loss 1.5108 (1.5733)	Prec@1 58.594 (58.247)
Epoch: [24][300/516]	LR 0.086448	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.5611 (1.5715)	Prec@1 59.375 (58.333)
Epoch: [24][350/516]	LR 0.086448	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.5489 (1.5739)	Prec@1 56.250 (58.248)
Epoch: [24][400/516]	LR 0.086448	Time 0.040 (0.083)	Data 0.000 (0.001)	Loss 1.6173 (1.5729)	Prec@1 57.031 (58.283)
Epoch: [24][450/516]	LR 0.086448	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.4605 (1.5766)	Prec@1 60.938 (58.163)
Epoch: [24][500/516]	LR 0.086448	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.4462 (1.5774)	Prec@1 60.938 (58.155)
Epoch: [24][516/516]	LR 0.086448	Time 0.023 (0.083)	Data 0.000 (0.001)	Loss 1.2279 (1.5776)	Prec@1 63.636 (58.143)
****************************************
clean_train:	 * Prec@1 89.075
noisy_train:	 * Prec@1 57.754
clean_val:	 * Prec@1 88.357
noisy_val:	 * Prec@1 56.962
****************************************
Epoch: [25][50/516]	LR 0.085355	Time 0.081 (0.088)	Data 0.000 (0.005)	Loss 1.4542 (1.5855)	Prec@1 63.281 (57.281)
Epoch: [25][100/516]	LR 0.085355	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.4396 (1.5797)	Prec@1 62.500 (57.656)
Epoch: [25][150/516]	LR 0.085355	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.4811 (1.5791)	Prec@1 61.719 (57.792)
Epoch: [25][200/516]	LR 0.085355	Time 0.083 (0.085)	Data 0.000 (0.001)	Loss 1.8707 (1.5833)	Prec@1 47.656 (57.672)
Epoch: [25][250/516]	LR 0.085355	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.4380 (1.5767)	Prec@1 65.625 (57.962)
Epoch: [25][300/516]	LR 0.085355	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6667 (1.5802)	Prec@1 51.562 (57.826)
Epoch: [25][350/516]	LR 0.085355	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.3235 (1.5763)	Prec@1 67.969 (57.980)
Epoch: [25][400/516]	LR 0.085355	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.5251 (1.5749)	Prec@1 59.375 (58.035)
Epoch: [25][450/516]	LR 0.085355	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.4457 (1.5749)	Prec@1 63.281 (58.030)
Epoch: [25][500/516]	LR 0.085355	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 1.5585 (1.5761)	Prec@1 60.938 (57.992)
Epoch: [25][516/516]	LR 0.085355	Time 0.020 (0.083)	Data 0.000 (0.001)	Loss 1.1624 (1.5755)	Prec@1 72.727 (58.009)
****************************************
clean_train:	 * Prec@1 87.778
noisy_train:	 * Prec@1 57.048
clean_val:	 * Prec@1 86.964
noisy_val:	 * Prec@1 56.129
****************************************
Epoch: [26][50/516]	LR 0.084227	Time 0.083 (0.080)	Data 0.000 (0.004)	Loss 1.4335 (1.5834)	Prec@1 61.719 (57.547)
Epoch: [26][100/516]	LR 0.084227	Time 0.084 (0.082)	Data 0.000 (0.002)	Loss 1.7108 (1.5917)	Prec@1 50.000 (57.219)
Epoch: [26][150/516]	LR 0.084227	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 1.4787 (1.5768)	Prec@1 62.500 (57.885)
Epoch: [26][200/516]	LR 0.084227	Time 0.068 (0.083)	Data 0.000 (0.001)	Loss 1.4036 (1.5764)	Prec@1 64.062 (57.902)
Epoch: [26][250/516]	LR 0.084227	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.5333 (1.5794)	Prec@1 58.594 (57.809)
Epoch: [26][300/516]	LR 0.084227	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 1.4908 (1.5755)	Prec@1 60.156 (57.979)
Epoch: [26][350/516]	LR 0.084227	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 1.6042 (1.5775)	Prec@1 56.250 (57.951)
Epoch: [26][400/516]	LR 0.084227	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.5049 (1.5798)	Prec@1 62.500 (57.869)
Epoch: [26][450/516]	LR 0.084227	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 1.8042 (1.5768)	Prec@1 53.125 (58.000)
Epoch: [26][500/516]	LR 0.084227	Time 0.077 (0.083)	Data 0.000 (0.001)	Loss 1.7139 (1.5751)	Prec@1 53.125 (58.064)
Epoch: [26][516/516]	LR 0.084227	Time 0.021 (0.083)	Data 0.000 (0.001)	Loss 1.2978 (1.5753)	Prec@1 72.727 (58.050)
****************************************
clean_train:	 * Prec@1 85.957
noisy_train:	 * Prec@1 55.933
clean_val:	 * Prec@1 85.599
noisy_val:	 * Prec@1 55.010
****************************************
Epoch: [27][50/516]	LR 0.083066	Time 0.088 (0.091)	Data 0.000 (0.003)	Loss 1.5034 (1.5517)	Prec@1 60.938 (59.031)
Epoch: [27][100/516]	LR 0.083066	Time 0.088 (0.081)	Data 0.000 (0.002)	Loss 1.7344 (1.5760)	Prec@1 50.781 (58.297)
Epoch: [27][150/516]	LR 0.083066	Time 0.081 (0.078)	Data 0.000 (0.001)	Loss 1.5897 (1.5697)	Prec@1 57.031 (58.281)
Epoch: [27][200/516]	LR 0.083066	Time 0.089 (0.079)	Data 0.000 (0.001)	Loss 1.7111 (1.5768)	Prec@1 53.906 (58.020)
Epoch: [27][250/516]	LR 0.083066	Time 0.083 (0.080)	Data 0.000 (0.001)	Loss 1.2991 (1.5774)	Prec@1 67.969 (58.013)
Epoch: [27][300/516]	LR 0.083066	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.4203 (1.5765)	Prec@1 66.406 (58.036)
Epoch: [27][350/516]	LR 0.083066	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 1.7694 (1.5773)	Prec@1 48.438 (58.027)
Epoch: [27][400/516]	LR 0.083066	Time 0.085 (0.081)	Data 0.000 (0.001)	Loss 1.4303 (1.5773)	Prec@1 63.281 (58.020)
Epoch: [27][450/516]	LR 0.083066	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.5148 (1.5761)	Prec@1 60.938 (58.056)
Epoch: [27][500/516]	LR 0.083066	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.7016 (1.5756)	Prec@1 50.781 (58.086)
Epoch: [27][516/516]	LR 0.083066	Time 0.021 (0.081)	Data 0.000 (0.001)	Loss 1.1003 (1.5743)	Prec@1 81.818 (58.130)
****************************************
clean_train:	 * Prec@1 88.148
noisy_train:	 * Prec@1 57.292
clean_val:	 * Prec@1 87.633
noisy_val:	 * Prec@1 56.429
****************************************
Epoch: [28][50/516]	LR 0.081871	Time 0.088 (0.088)	Data 0.000 (0.005)	Loss 1.6468 (1.5702)	Prec@1 57.812 (58.625)
Epoch: [28][100/516]	LR 0.081871	Time 0.087 (0.088)	Data 0.000 (0.002)	Loss 1.6797 (1.5660)	Prec@1 55.469 (58.422)
Epoch: [28][150/516]	LR 0.081871	Time 0.088 (0.088)	Data 0.000 (0.002)	Loss 1.4804 (1.5694)	Prec@1 61.719 (58.302)
Epoch: [28][200/516]	LR 0.081871	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6349 (1.5694)	Prec@1 56.250 (58.398)
Epoch: [28][250/516]	LR 0.081871	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.4458 (1.5728)	Prec@1 64.062 (58.275)
Epoch: [28][300/516]	LR 0.081871	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.5318 (1.5737)	Prec@1 59.375 (58.260)
Epoch: [28][350/516]	LR 0.081871	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.5791 (1.5742)	Prec@1 58.594 (58.208)
Epoch: [28][400/516]	LR 0.081871	Time 0.080 (0.082)	Data 0.000 (0.001)	Loss 1.6404 (1.5733)	Prec@1 54.688 (58.240)
Epoch: [28][450/516]	LR 0.081871	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.6548 (1.5723)	Prec@1 53.125 (58.276)
Epoch: [28][500/516]	LR 0.081871	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 1.6848 (1.5710)	Prec@1 53.906 (58.333)
Epoch: [28][516/516]	LR 0.081871	Time 0.018 (0.082)	Data 0.000 (0.001)	Loss 1.5368 (1.5705)	Prec@1 63.636 (58.359)
****************************************
clean_train:	 * Prec@1 90.081
noisy_train:	 * Prec@1 58.394
clean_val:	 * Prec@1 89.885
noisy_val:	 * Prec@1 57.589
****************************************
Epoch: [29][50/516]	LR 0.080645	Time 0.081 (0.092)	Data 0.000 (0.005)	Loss 1.5784 (1.5350)	Prec@1 57.812 (59.594)
Epoch: [29][100/516]	LR 0.080645	Time 0.041 (0.089)	Data 0.000 (0.003)	Loss 1.3438 (1.5513)	Prec@1 67.969 (59.008)
Epoch: [29][150/516]	LR 0.080645	Time 0.080 (0.086)	Data 0.000 (0.002)	Loss 1.5563 (1.5614)	Prec@1 58.594 (58.651)
Epoch: [29][200/516]	LR 0.080645	Time 0.083 (0.086)	Data 0.000 (0.001)	Loss 1.5897 (1.5639)	Prec@1 58.594 (58.543)
Epoch: [29][250/516]	LR 0.080645	Time 0.088 (0.087)	Data 0.000 (0.001)	Loss 1.5860 (1.5653)	Prec@1 56.250 (58.459)
Epoch: [29][300/516]	LR 0.080645	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.4423 (1.5683)	Prec@1 64.062 (58.339)
Epoch: [29][350/516]	LR 0.080645	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 1.7661 (1.5645)	Prec@1 51.562 (58.496)
Epoch: [29][400/516]	LR 0.080645	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.5794 (1.5676)	Prec@1 58.594 (58.395)
Epoch: [29][450/516]	LR 0.080645	Time 0.078 (0.083)	Data 0.000 (0.001)	Loss 1.4584 (1.5681)	Prec@1 63.281 (58.417)
Epoch: [29][500/516]	LR 0.080645	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.5196 (1.5692)	Prec@1 59.375 (58.402)
Epoch: [29][516/516]	LR 0.080645	Time 0.023 (0.083)	Data 0.000 (0.001)	Loss 1.4752 (1.5697)	Prec@1 54.545 (58.397)
****************************************
clean_train:	 * Prec@1 88.128
noisy_train:	 * Prec@1 57.308
clean_val:	 * Prec@1 87.415
noisy_val:	 * Prec@1 56.265
****************************************
Epoch: [30][50/516]	LR 0.079389	Time 0.088 (0.081)	Data 0.000 (0.004)	Loss 1.7360 (1.5929)	Prec@1 51.562 (57.031)
Epoch: [30][100/516]	LR 0.079389	Time 0.088 (0.084)	Data 0.000 (0.002)	Loss 1.5290 (1.5610)	Prec@1 59.375 (58.258)
Epoch: [30][150/516]	LR 0.079389	Time 0.087 (0.086)	Data 0.000 (0.002)	Loss 1.5236 (1.5682)	Prec@1 60.938 (57.938)
Epoch: [30][200/516]	LR 0.079389	Time 0.087 (0.086)	Data 0.000 (0.001)	Loss 1.6787 (1.5692)	Prec@1 53.906 (57.906)
Epoch: [30][250/516]	LR 0.079389	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.8116 (1.5709)	Prec@1 48.438 (57.922)
Epoch: [30][300/516]	LR 0.079389	Time 0.085 (0.085)	Data 0.000 (0.001)	Loss 1.5882 (1.5688)	Prec@1 57.031 (58.089)
Epoch: [30][350/516]	LR 0.079389	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.6339 (1.5680)	Prec@1 59.375 (58.203)
Epoch: [30][400/516]	LR 0.079389	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.3030 (1.5675)	Prec@1 67.969 (58.262)
Epoch: [30][450/516]	LR 0.079389	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 1.7104 (1.5677)	Prec@1 56.250 (58.285)
Epoch: [30][500/516]	LR 0.079389	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.6366 (1.5691)	Prec@1 57.031 (58.244)
Epoch: [30][516/516]	LR 0.079389	Time 0.019 (0.083)	Data 0.000 (0.001)	Loss 1.7806 (1.5691)	Prec@1 45.455 (58.262)
****************************************
clean_train:	 * Prec@1 91.133
noisy_train:	 * Prec@1 59.080
clean_val:	 * Prec@1 90.718
noisy_val:	 * Prec@1 58.108
****************************************
Epoch: [31][50/516]	LR 0.078104	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 1.7167 (1.5691)	Prec@1 52.344 (58.500)
Epoch: [31][100/516]	LR 0.078104	Time 0.084 (0.086)	Data 0.000 (0.003)	Loss 1.3430 (1.5652)	Prec@1 67.969 (58.594)
Epoch: [31][150/516]	LR 0.078104	Time 0.080 (0.082)	Data 0.000 (0.002)	Loss 1.6806 (1.5614)	Prec@1 52.344 (58.677)
Epoch: [31][200/516]	LR 0.078104	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6151 (1.5649)	Prec@1 56.250 (58.551)
Epoch: [31][250/516]	LR 0.078104	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.3812 (1.5687)	Prec@1 63.281 (58.394)
Epoch: [31][300/516]	LR 0.078104	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.6707 (1.5705)	Prec@1 55.469 (58.292)
Epoch: [31][350/516]	LR 0.078104	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.5733 (1.5680)	Prec@1 57.812 (58.371)
Epoch: [31][400/516]	LR 0.078104	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.7629 (1.5699)	Prec@1 51.562 (58.291)
Epoch: [31][450/516]	LR 0.078104	Time 0.085 (0.085)	Data 0.000 (0.001)	Loss 1.4566 (1.5691)	Prec@1 62.500 (58.366)
Epoch: [31][500/516]	LR 0.078104	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.3971 (1.5664)	Prec@1 64.062 (58.513)
Epoch: [31][516/516]	LR 0.078104	Time 0.021 (0.084)	Data 0.000 (0.001)	Loss 1.5042 (1.5661)	Prec@1 54.545 (58.517)
****************************************
clean_train:	 * Prec@1 87.563
noisy_train:	 * Prec@1 56.960
clean_val:	 * Prec@1 86.800
noisy_val:	 * Prec@1 56.020
****************************************
Epoch: [32][50/516]	LR 0.076791	Time 0.088 (0.087)	Data 0.000 (0.004)	Loss 1.2956 (1.5765)	Prec@1 67.188 (58.125)
Epoch: [32][100/516]	LR 0.076791	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.4672 (1.5712)	Prec@1 60.938 (58.227)
Epoch: [32][150/516]	LR 0.076791	Time 0.087 (0.085)	Data 0.000 (0.002)	Loss 1.5933 (1.5701)	Prec@1 56.250 (58.266)
Epoch: [32][200/516]	LR 0.076791	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 1.7242 (1.5720)	Prec@1 53.125 (58.172)
Epoch: [32][250/516]	LR 0.076791	Time 0.041 (0.083)	Data 0.000 (0.001)	Loss 1.5085 (1.5705)	Prec@1 63.281 (58.284)
Epoch: [32][300/516]	LR 0.076791	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.6951 (1.5681)	Prec@1 53.906 (58.411)
Epoch: [32][350/516]	LR 0.076791	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4448 (1.5647)	Prec@1 60.938 (58.527)
Epoch: [32][400/516]	LR 0.076791	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4824 (1.5649)	Prec@1 62.500 (58.533)
Epoch: [32][450/516]	LR 0.076791	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5712 (1.5637)	Prec@1 59.375 (58.573)
Epoch: [32][500/516]	LR 0.076791	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.6275 (1.5641)	Prec@1 54.688 (58.566)
Epoch: [32][516/516]	LR 0.076791	Time 0.021 (0.084)	Data 0.000 (0.001)	Loss 2.0210 (1.5644)	Prec@1 45.455 (58.546)
****************************************
clean_train:	 * Prec@1 88.257
noisy_train:	 * Prec@1 57.442
clean_val:	 * Prec@1 87.387
noisy_val:	 * Prec@1 56.402
****************************************
Epoch: [33][50/516]	LR 0.075452	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 1.4254 (1.5538)	Prec@1 64.844 (58.828)
Epoch: [33][100/516]	LR 0.075452	Time 0.083 (0.086)	Data 0.000 (0.003)	Loss 1.7095 (1.5576)	Prec@1 53.125 (58.656)
Epoch: [33][150/516]	LR 0.075452	Time 0.086 (0.085)	Data 0.000 (0.002)	Loss 1.4390 (1.5500)	Prec@1 63.281 (58.948)
Epoch: [33][200/516]	LR 0.075452	Time 0.076 (0.084)	Data 0.000 (0.001)	Loss 1.5792 (1.5578)	Prec@1 57.812 (58.621)
Epoch: [33][250/516]	LR 0.075452	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 1.5443 (1.5558)	Prec@1 59.375 (58.728)
Epoch: [33][300/516]	LR 0.075452	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.4270 (1.5579)	Prec@1 63.281 (58.734)
Epoch: [33][350/516]	LR 0.075452	Time 0.042 (0.084)	Data 0.000 (0.001)	Loss 1.5898 (1.5617)	Prec@1 58.594 (58.585)
Epoch: [33][400/516]	LR 0.075452	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.4689 (1.5610)	Prec@1 63.281 (58.604)
Epoch: [33][450/516]	LR 0.075452	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5983 (1.5644)	Prec@1 57.812 (58.521)
Epoch: [33][500/516]	LR 0.075452	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6487 (1.5632)	Prec@1 54.688 (58.616)
Epoch: [33][516/516]	LR 0.075452	Time 0.014 (0.084)	Data 0.000 (0.001)	Loss 1.5903 (1.5629)	Prec@1 45.455 (58.646)
****************************************
clean_train:	 * Prec@1 82.780
noisy_train:	 * Prec@1 54.085
clean_val:	 * Prec@1 82.241
noisy_val:	 * Prec@1 53.071
****************************************
Epoch: [34][50/516]	LR 0.074088	Time 0.085 (0.087)	Data 0.000 (0.004)	Loss 1.5086 (1.6144)	Prec@1 61.719 (56.453)
Epoch: [34][100/516]	LR 0.074088	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.5661 (1.5911)	Prec@1 58.594 (57.445)
Epoch: [34][150/516]	LR 0.074088	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.6465 (1.5886)	Prec@1 56.250 (57.599)
Epoch: [34][200/516]	LR 0.074088	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.5363 (1.5805)	Prec@1 58.594 (57.949)
Epoch: [34][250/516]	LR 0.074088	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.5099 (1.5808)	Prec@1 59.375 (57.894)
Epoch: [34][300/516]	LR 0.074088	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.4687 (1.5730)	Prec@1 62.500 (58.201)
Epoch: [34][350/516]	LR 0.074088	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 1.4387 (1.5699)	Prec@1 61.719 (58.317)
Epoch: [34][400/516]	LR 0.074088	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 1.6336 (1.5673)	Prec@1 57.031 (58.420)
Epoch: [34][450/516]	LR 0.074088	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.5735 (1.5673)	Prec@1 57.812 (58.434)
Epoch: [34][500/516]	LR 0.074088	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.3790 (1.5656)	Prec@1 64.844 (58.494)
Epoch: [34][516/516]	LR 0.074088	Time 0.020 (0.083)	Data 0.000 (0.001)	Loss 1.6998 (1.5667)	Prec@1 45.455 (58.458)
****************************************
clean_train:	 * Prec@1 88.125
noisy_train:	 * Prec@1 57.425
clean_val:	 * Prec@1 87.565
noisy_val:	 * Prec@1 56.375
****************************************
Epoch: [35][50/516]	LR 0.072700	Time 0.088 (0.088)	Data 0.000 (0.004)	Loss 1.6661 (1.6088)	Prec@1 56.250 (56.594)
Epoch: [35][100/516]	LR 0.072700	Time 0.073 (0.085)	Data 0.000 (0.002)	Loss 1.5994 (1.5792)	Prec@1 57.812 (57.953)
Epoch: [35][150/516]	LR 0.072700	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 1.4589 (1.5667)	Prec@1 60.938 (58.417)
Epoch: [35][200/516]	LR 0.072700	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.7088 (1.5667)	Prec@1 55.469 (58.461)
Epoch: [35][250/516]	LR 0.072700	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.4623 (1.5665)	Prec@1 62.500 (58.472)
Epoch: [35][300/516]	LR 0.072700	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.4536 (1.5610)	Prec@1 63.281 (58.659)
Epoch: [35][350/516]	LR 0.072700	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 1.6692 (1.5585)	Prec@1 58.594 (58.725)
Epoch: [35][400/516]	LR 0.072700	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.4501 (1.5590)	Prec@1 61.719 (58.730)
Epoch: [35][450/516]	LR 0.072700	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.5155 (1.5607)	Prec@1 61.719 (58.658)
Epoch: [35][500/516]	LR 0.072700	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 1.6689 (1.5600)	Prec@1 55.469 (58.686)
Epoch: [35][516/516]	LR 0.072700	Time 0.021 (0.084)	Data 0.000 (0.001)	Loss 2.1813 (1.5613)	Prec@1 36.364 (58.631)
****************************************
clean_train:	 * Prec@1 90.517
noisy_train:	 * Prec@1 58.745
clean_val:	 * Prec@1 90.186
noisy_val:	 * Prec@1 57.944
****************************************
Epoch: [36][50/516]	LR 0.071289	Time 0.041 (0.077)	Data 0.000 (0.004)	Loss 1.7296 (1.5486)	Prec@1 53.125 (59.203)
Epoch: [36][100/516]	LR 0.071289	Time 0.083 (0.075)	Data 0.000 (0.002)	Loss 1.4109 (1.5593)	Prec@1 63.281 (58.828)
Epoch: [36][150/516]	LR 0.071289	Time 0.089 (0.077)	Data 0.000 (0.001)	Loss 1.5503 (1.5595)	Prec@1 56.250 (58.734)
Epoch: [36][200/516]	LR 0.071289	Time 0.090 (0.079)	Data 0.000 (0.001)	Loss 1.7055 (1.5509)	Prec@1 52.344 (59.066)
Epoch: [36][250/516]	LR 0.071289	Time 0.081 (0.080)	Data 0.000 (0.001)	Loss 1.6653 (1.5574)	Prec@1 54.688 (58.803)
Epoch: [36][300/516]	LR 0.071289	Time 0.082 (0.080)	Data 0.000 (0.001)	Loss 1.5517 (1.5569)	Prec@1 57.812 (58.849)
Epoch: [36][350/516]	LR 0.071289	Time 0.088 (0.081)	Data 0.000 (0.001)	Loss 1.5497 (1.5559)	Prec@1 57.031 (58.848)
Epoch: [36][400/516]	LR 0.071289	Time 0.081 (0.081)	Data 0.000 (0.001)	Loss 1.2842 (1.5578)	Prec@1 71.875 (58.807)
Epoch: [36][450/516]	LR 0.071289	Time 0.080 (0.081)	Data 0.000 (0.001)	Loss 1.6864 (1.5591)	Prec@1 53.906 (58.778)
Epoch: [36][500/516]	LR 0.071289	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 1.6142 (1.5577)	Prec@1 57.031 (58.869)
Epoch: [36][516/516]	LR 0.071289	Time 0.021 (0.081)	Data 0.000 (0.001)	Loss 1.9682 (1.5582)	Prec@1 45.455 (58.852)
****************************************
clean_train:	 * Prec@1 90.925
noisy_train:	 * Prec@1 59.050
clean_val:	 * Prec@1 90.199
noisy_val:	 * Prec@1 57.862
****************************************
Epoch: [37][50/516]	LR 0.069857	Time 0.088 (0.091)	Data 0.000 (0.004)	Loss 1.5728 (1.5553)	Prec@1 57.812 (58.719)
Epoch: [37][100/516]	LR 0.069857	Time 0.074 (0.089)	Data 0.000 (0.002)	Loss 1.4253 (1.5457)	Prec@1 63.281 (59.172)
Epoch: [37][150/516]	LR 0.069857	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.3894 (1.5502)	Prec@1 62.500 (58.995)
Epoch: [37][200/516]	LR 0.069857	Time 0.082 (0.080)	Data 0.000 (0.001)	Loss 1.5176 (1.5562)	Prec@1 59.375 (58.789)
Epoch: [37][250/516]	LR 0.069857	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.6065 (1.5560)	Prec@1 56.250 (58.866)
Epoch: [37][300/516]	LR 0.069857	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.5439 (1.5589)	Prec@1 59.375 (58.758)
Epoch: [37][350/516]	LR 0.069857	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.6684 (1.5580)	Prec@1 57.031 (58.797)
Epoch: [37][400/516]	LR 0.069857	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.4338 (1.5574)	Prec@1 64.062 (58.850)
Epoch: [37][450/516]	LR 0.069857	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.6339 (1.5570)	Prec@1 54.688 (58.863)
Epoch: [37][500/516]	LR 0.069857	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 1.5627 (1.5569)	Prec@1 57.812 (58.831)
Epoch: [37][516/516]	LR 0.069857	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 2.1769 (1.5556)	Prec@1 36.364 (58.872)
****************************************
clean_train:	 * Prec@1 89.324
noisy_train:	 * Prec@1 57.977
clean_val:	 * Prec@1 88.930
noisy_val:	 * Prec@1 57.180
****************************************
Epoch: [38][50/516]	LR 0.068406	Time 0.087 (0.082)	Data 0.000 (0.004)	Loss 1.4828 (1.5608)	Prec@1 62.500 (59.453)
Epoch: [38][100/516]	LR 0.068406	Time 0.089 (0.085)	Data 0.001 (0.002)	Loss 1.5146 (1.5489)	Prec@1 61.719 (59.469)
Epoch: [38][150/516]	LR 0.068406	Time 0.088 (0.086)	Data 0.000 (0.002)	Loss 1.4626 (1.5553)	Prec@1 62.500 (59.068)
Epoch: [38][200/516]	LR 0.068406	Time 0.084 (0.087)	Data 0.000 (0.001)	Loss 1.7049 (1.5524)	Prec@1 51.562 (59.152)
Epoch: [38][250/516]	LR 0.068406	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 1.7784 (1.5566)	Prec@1 50.000 (58.966)
Epoch: [38][300/516]	LR 0.068406	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 1.6705 (1.5558)	Prec@1 53.906 (58.938)
Epoch: [38][350/516]	LR 0.068406	Time 0.078 (0.082)	Data 0.000 (0.001)	Loss 1.4946 (1.5543)	Prec@1 60.938 (59.018)
Epoch: [38][400/516]	LR 0.068406	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.6110 (1.5547)	Prec@1 56.250 (58.988)
Epoch: [38][450/516]	LR 0.068406	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 1.4261 (1.5560)	Prec@1 62.500 (58.915)
Epoch: [38][500/516]	LR 0.068406	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 1.5299 (1.5563)	Prec@1 58.594 (58.888)
Epoch: [38][516/516]	LR 0.068406	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 1.3825 (1.5564)	Prec@1 63.636 (58.883)
****************************************
clean_train:	 * Prec@1 90.443
noisy_train:	 * Prec@1 58.673
clean_val:	 * Prec@1 89.530
noisy_val:	 * Prec@1 57.890
****************************************
Epoch: [39][50/516]	LR 0.066937	Time 0.087 (0.091)	Data 0.000 (0.004)	Loss 1.5019 (1.5747)	Prec@1 60.156 (58.266)
Epoch: [39][100/516]	LR 0.066937	Time 0.088 (0.090)	Data 0.000 (0.002)	Loss 1.6127 (1.5638)	Prec@1 55.469 (58.617)
Epoch: [39][150/516]	LR 0.066937	Time 0.041 (0.088)	Data 0.000 (0.002)	Loss 1.5770 (1.5607)	Prec@1 55.469 (58.682)
Epoch: [39][200/516]	LR 0.066937	Time 0.088 (0.086)	Data 0.000 (0.001)	Loss 1.6659 (1.5515)	Prec@1 53.906 (59.055)
Epoch: [39][250/516]	LR 0.066937	Time 0.092 (0.086)	Data 0.000 (0.001)	Loss 1.4649 (1.5511)	Prec@1 60.156 (59.069)
Epoch: [39][300/516]	LR 0.066937	Time 0.088 (0.086)	Data 0.000 (0.001)	Loss 1.5353 (1.5545)	Prec@1 58.594 (58.909)
Epoch: [39][350/516]	LR 0.066937	Time 0.091 (0.085)	Data 0.000 (0.001)	Loss 1.5735 (1.5579)	Prec@1 57.812 (58.801)
Epoch: [39][400/516]	LR 0.066937	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.4761 (1.5566)	Prec@1 63.281 (58.869)
Epoch: [39][450/516]	LR 0.066937	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 1.6181 (1.5575)	Prec@1 57.031 (58.826)
Epoch: [39][500/516]	LR 0.066937	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.4867 (1.5546)	Prec@1 62.500 (58.961)
Epoch: [39][516/516]	LR 0.066937	Time 0.021 (0.083)	Data 0.000 (0.001)	Loss 1.3064 (1.5554)	Prec@1 72.727 (58.928)
****************************************
clean_train:	 * Prec@1 88.999
noisy_train:	 * Prec@1 57.862
clean_val:	 * Prec@1 88.165
noisy_val:	 * Prec@1 56.566
****************************************
Epoch: [40][50/516]	LR 0.065451	Time 0.081 (0.087)	Data 0.000 (0.004)	Loss 1.6223 (1.5652)	Prec@1 57.031 (58.562)
Epoch: [40][100/516]	LR 0.065451	Time 0.041 (0.082)	Data 0.000 (0.002)	Loss 1.3864 (1.5544)	Prec@1 64.844 (59.000)
Epoch: [40][150/516]	LR 0.065451	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.5258 (1.5610)	Prec@1 60.938 (58.823)
Epoch: [40][200/516]	LR 0.065451	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4358 (1.5596)	Prec@1 60.938 (58.727)
Epoch: [40][250/516]	LR 0.065451	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.4393 (1.5594)	Prec@1 64.844 (58.769)
Epoch: [40][300/516]	LR 0.065451	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6362 (1.5555)	Prec@1 54.688 (58.875)
Epoch: [40][350/516]	LR 0.065451	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.4353 (1.5565)	Prec@1 64.062 (58.830)
Epoch: [40][400/516]	LR 0.065451	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.4482 (1.5563)	Prec@1 64.062 (58.850)
Epoch: [40][450/516]	LR 0.065451	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.4476 (1.5551)	Prec@1 64.062 (58.885)
Epoch: [40][500/516]	LR 0.065451	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 1.8311 (1.5547)	Prec@1 48.438 (58.892)
Epoch: [40][516/516]	LR 0.065451	Time 0.021 (0.083)	Data 0.000 (0.001)	Loss 1.5720 (1.5555)	Prec@1 54.545 (58.859)
****************************************
clean_train:	 * Prec@1 89.930
noisy_train:	 * Prec@1 58.485
clean_val:	 * Prec@1 89.244
noisy_val:	 * Prec@1 57.412
****************************************
Epoch: [41][50/516]	LR 0.063950	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 1.3889 (1.5664)	Prec@1 65.625 (58.078)
Epoch: [41][100/516]	LR 0.063950	Time 0.088 (0.086)	Data 0.000 (0.002)	Loss 1.4554 (1.5637)	Prec@1 64.062 (58.414)
Epoch: [41][150/516]	LR 0.063950	Time 0.082 (0.085)	Data 0.000 (0.002)	Loss 1.6207 (1.5522)	Prec@1 57.031 (58.964)
Epoch: [41][200/516]	LR 0.063950	Time 0.048 (0.084)	Data 0.000 (0.001)	Loss 1.5962 (1.5625)	Prec@1 57.812 (58.625)
Epoch: [41][250/516]	LR 0.063950	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 1.3628 (1.5631)	Prec@1 67.969 (58.575)
Epoch: [41][300/516]	LR 0.063950	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.7485 (1.5651)	Prec@1 49.219 (58.568)
Epoch: [41][350/516]	LR 0.063950	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.4102 (1.5605)	Prec@1 62.500 (58.750)
Epoch: [41][400/516]	LR 0.063950	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6294 (1.5597)	Prec@1 55.469 (58.781)
Epoch: [41][450/516]	LR 0.063950	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4781 (1.5567)	Prec@1 62.500 (58.889)
Epoch: [41][500/516]	LR 0.063950	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5821 (1.5549)	Prec@1 57.812 (58.938)
Epoch: [41][516/516]	LR 0.063950	Time 0.020 (0.085)	Data 0.000 (0.001)	Loss 1.8502 (1.5536)	Prec@1 36.364 (58.960)
****************************************
clean_train:	 * Prec@1 90.351
noisy_train:	 * Prec@1 58.658
clean_val:	 * Prec@1 89.558
noisy_val:	 * Prec@1 57.740
****************************************
Epoch: [42][50/516]	LR 0.062434	Time 0.079 (0.088)	Data 0.000 (0.005)	Loss 1.2837 (1.5511)	Prec@1 67.188 (59.484)
Epoch: [42][100/516]	LR 0.062434	Time 0.088 (0.086)	Data 0.000 (0.002)	Loss 1.4460 (1.5433)	Prec@1 62.500 (59.641)
Epoch: [42][150/516]	LR 0.062434	Time 0.082 (0.085)	Data 0.000 (0.002)	Loss 1.5720 (1.5508)	Prec@1 57.031 (59.286)
Epoch: [42][200/516]	LR 0.062434	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.4550 (1.5477)	Prec@1 62.500 (59.297)
Epoch: [42][250/516]	LR 0.062434	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.5587 (1.5525)	Prec@1 57.812 (59.119)
Epoch: [42][300/516]	LR 0.062434	Time 0.080 (0.084)	Data 0.000 (0.001)	Loss 1.7268 (1.5524)	Prec@1 51.562 (59.164)
Epoch: [42][350/516]	LR 0.062434	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 1.6805 (1.5508)	Prec@1 53.906 (59.217)
Epoch: [42][400/516]	LR 0.062434	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4186 (1.5488)	Prec@1 64.844 (59.281)
Epoch: [42][450/516]	LR 0.062434	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.7327 (1.5518)	Prec@1 53.125 (59.168)
Epoch: [42][500/516]	LR 0.062434	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5790 (1.5497)	Prec@1 58.594 (59.237)
Epoch: [42][516/516]	LR 0.062434	Time 0.021 (0.084)	Data 0.000 (0.001)	Loss 1.0718 (1.5498)	Prec@1 81.818 (59.221)
****************************************
clean_train:	 * Prec@1 87.335
noisy_train:	 * Prec@1 56.873
clean_val:	 * Prec@1 86.637
noisy_val:	 * Prec@1 55.624
****************************************
Epoch: [43][50/516]	LR 0.060907	Time 0.082 (0.088)	Data 0.000 (0.004)	Loss 1.5484 (1.5581)	Prec@1 57.812 (58.594)
Epoch: [43][100/516]	LR 0.060907	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 1.5724 (1.5583)	Prec@1 57.031 (58.711)
Epoch: [43][150/516]	LR 0.060907	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.4448 (1.5544)	Prec@1 62.500 (58.911)
Epoch: [43][200/516]	LR 0.060907	Time 0.081 (0.084)	Data 0.000 (0.001)	Loss 1.5007 (1.5541)	Prec@1 60.938 (58.941)
Epoch: [43][250/516]	LR 0.060907	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 1.3551 (1.5533)	Prec@1 66.406 (58.938)
Epoch: [43][300/516]	LR 0.060907	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.5813 (1.5519)	Prec@1 57.812 (58.982)
Epoch: [43][350/516]	LR 0.060907	Time 0.089 (0.084)	Data 0.000 (0.001)	Loss 1.5944 (1.5506)	Prec@1 59.375 (59.074)
Epoch: [43][400/516]	LR 0.060907	Time 0.082 (0.084)	Data 0.001 (0.001)	Loss 1.5862 (1.5511)	Prec@1 59.375 (59.084)
Epoch: [43][450/516]	LR 0.060907	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 1.6755 (1.5528)	Prec@1 55.469 (59.024)
Epoch: [43][500/516]	LR 0.060907	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4651 (1.5510)	Prec@1 62.500 (59.114)
Epoch: [43][516/516]	LR 0.060907	Time 0.021 (0.084)	Data 0.000 (0.001)	Loss 1.5728 (1.5517)	Prec@1 63.636 (59.094)
****************************************
clean_train:	 * Prec@1 92.504
noisy_train:	 * Prec@1 60.101
clean_val:	 * Prec@1 91.919
noisy_val:	 * Prec@1 58.913
****************************************
Epoch: [44][50/516]	LR 0.059369	Time 0.082 (0.087)	Data 0.000 (0.004)	Loss 1.5743 (1.5593)	Prec@1 57.812 (58.625)
Epoch: [44][100/516]	LR 0.059369	Time 0.086 (0.085)	Data 0.000 (0.002)	Loss 1.6008 (1.5521)	Prec@1 57.031 (58.875)
Epoch: [44][150/516]	LR 0.059369	Time 0.081 (0.085)	Data 0.000 (0.002)	Loss 1.4592 (1.5491)	Prec@1 61.719 (59.016)
Epoch: [44][200/516]	LR 0.059369	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 1.6069 (1.5446)	Prec@1 58.594 (59.293)
Epoch: [44][250/516]	LR 0.059369	Time 0.089 (0.084)	Data 0.000 (0.001)	Loss 1.6034 (1.5453)	Prec@1 56.250 (59.278)
Epoch: [44][300/516]	LR 0.059369	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 1.5460 (1.5441)	Prec@1 59.375 (59.299)
Epoch: [44][350/516]	LR 0.059369	Time 0.075 (0.084)	Data 0.000 (0.001)	Loss 1.6459 (1.5434)	Prec@1 56.250 (59.350)
Epoch: [44][400/516]	LR 0.059369	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 1.6315 (1.5438)	Prec@1 56.250 (59.363)
Epoch: [44][450/516]	LR 0.059369	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 1.8740 (1.5484)	Prec@1 48.438 (59.207)
Epoch: [44][500/516]	LR 0.059369	Time 0.079 (0.084)	Data 0.000 (0.001)	Loss 1.6206 (1.5468)	Prec@1 58.594 (59.289)
Epoch: [44][516/516]	LR 0.059369	Time 0.018 (0.083)	Data 0.000 (0.001)	Loss 1.5391 (1.5469)	Prec@1 63.636 (59.300)
****************************************
clean_train:	 * Prec@1 89.418
noisy_train:	 * Prec@1 58.179
clean_val:	 * Prec@1 88.343
noisy_val:	 * Prec@1 57.139
****************************************
Epoch: [45][50/516]	LR 0.057822	Time 0.082 (0.073)	Data 0.000 (0.004)	Loss 1.4967 (1.5439)	Prec@1 61.719 (59.406)
Epoch: [45][100/516]	LR 0.057822	Time 0.083 (0.078)	Data 0.000 (0.002)	Loss 1.6017 (1.5554)	Prec@1 57.812 (58.914)
Epoch: [45][150/516]	LR 0.057822	Time 0.081 (0.080)	Data 0.000 (0.002)	Loss 1.4324 (1.5551)	Prec@1 62.500 (58.953)
Epoch: [45][200/516]	LR 0.057822	Time 0.081 (0.080)	Data 0.000 (0.001)	Loss 1.2856 (1.5489)	Prec@1 67.969 (59.203)
Epoch: [45][250/516]	LR 0.057822	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.4515 (1.5465)	Prec@1 64.062 (59.291)
Epoch: [45][300/516]	LR 0.057822	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.6672 (1.5477)	Prec@1 53.906 (59.245)
Epoch: [45][350/516]	LR 0.057822	Time 0.089 (0.082)	Data 0.000 (0.001)	Loss 1.4888 (1.5494)	Prec@1 60.156 (59.141)
Epoch: [45][400/516]	LR 0.057822	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 1.4884 (1.5492)	Prec@1 61.719 (59.146)
Epoch: [45][450/516]	LR 0.057822	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.3144 (1.5495)	Prec@1 67.188 (59.148)
Epoch: [45][500/516]	LR 0.057822	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.4123 (1.5470)	Prec@1 64.062 (59.230)
Epoch: [45][516/516]	LR 0.057822	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 1.1010 (1.5466)	Prec@1 81.818 (59.263)
****************************************
clean_train:	 * Prec@1 91.229
noisy_train:	 * Prec@1 59.274
clean_val:	 * Prec@1 90.336
noisy_val:	 * Prec@1 57.903
****************************************
Epoch: [46][50/516]	LR 0.056267	Time 0.088 (0.091)	Data 0.000 (0.004)	Loss 1.6715 (1.5406)	Prec@1 53.906 (59.406)
Epoch: [46][100/516]	LR 0.056267	Time 0.088 (0.081)	Data 0.000 (0.002)	Loss 1.2690 (1.5362)	Prec@1 69.531 (59.719)
Epoch: [46][150/516]	LR 0.056267	Time 0.083 (0.078)	Data 0.000 (0.002)	Loss 1.4231 (1.5368)	Prec@1 63.281 (59.536)
Epoch: [46][200/516]	LR 0.056267	Time 0.083 (0.079)	Data 0.000 (0.001)	Loss 1.5321 (1.5339)	Prec@1 59.375 (59.723)
Epoch: [46][250/516]	LR 0.056267	Time 0.089 (0.080)	Data 0.000 (0.001)	Loss 1.4983 (1.5403)	Prec@1 61.719 (59.528)
Epoch: [46][300/516]	LR 0.056267	Time 0.081 (0.080)	Data 0.000 (0.001)	Loss 1.5090 (1.5387)	Prec@1 60.156 (59.607)
Epoch: [46][350/516]	LR 0.056267	Time 0.093 (0.081)	Data 0.000 (0.001)	Loss 1.4863 (1.5379)	Prec@1 63.281 (59.632)
Epoch: [46][400/516]	LR 0.056267	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 1.4957 (1.5401)	Prec@1 60.938 (59.547)
Epoch: [46][450/516]	LR 0.056267	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 1.6886 (1.5439)	Prec@1 53.906 (59.396)
Epoch: [46][500/516]	LR 0.056267	Time 0.082 (0.082)	Data 0.000 (0.001)	Loss 1.6780 (1.5447)	Prec@1 56.250 (59.400)
Epoch: [46][516/516]	LR 0.056267	Time 0.021 (0.082)	Data 0.000 (0.001)	Loss 1.1495 (1.5439)	Prec@1 72.727 (59.447)
****************************************
clean_train:	 * Prec@1 89.207
noisy_train:	 * Prec@1 58.143
clean_val:	 * Prec@1 88.739
noisy_val:	 * Prec@1 56.934
****************************************
Epoch: [47][50/516]	LR 0.054705	Time 0.116 (0.104)	Data 0.000 (0.005)	Loss 1.4403 (1.5513)	Prec@1 64.062 (59.203)
Epoch: [47][100/516]	LR 0.054705	Time 0.133 (0.106)	Data 0.000 (0.003)	Loss 1.5285 (1.5520)	Prec@1 60.938 (59.188)
Epoch: [47][150/516]	LR 0.054705	Time 0.083 (0.104)	Data 0.000 (0.002)	Loss 1.4772 (1.5468)	Prec@1 63.281 (59.307)
Epoch: [47][200/516]	LR 0.054705	Time 0.126 (0.100)	Data 0.000 (0.001)	Loss 1.4581 (1.5420)	Prec@1 60.938 (59.555)
Epoch: [47][250/516]	LR 0.054705	Time 0.094 (0.097)	Data 0.000 (0.001)	Loss 1.5988 (1.5420)	Prec@1 58.594 (59.547)
Epoch: [47][300/516]	LR 0.054705	Time 0.079 (0.096)	Data 0.000 (0.001)	Loss 1.5115 (1.5364)	Prec@1 60.938 (59.732)
Epoch: [47][350/516]	LR 0.054705	Time 0.083 (0.097)	Data 0.000 (0.001)	Loss 1.5732 (1.5393)	Prec@1 57.812 (59.585)
Epoch: [47][400/516]	LR 0.054705	Time 0.081 (0.097)	Data 0.000 (0.001)	Loss 1.5972 (1.5410)	Prec@1 57.812 (59.555)
Epoch: [47][450/516]	LR 0.054705	Time 0.083 (0.097)	Data 0.000 (0.001)	Loss 1.2775 (1.5414)	Prec@1 67.188 (59.493)
Epoch: [47][500/516]	LR 0.054705	Time 0.083 (0.097)	Data 0.000 (0.001)	Loss 1.6285 (1.5412)	Prec@1 55.469 (59.487)
Epoch: [47][516/516]	LR 0.054705	Time 0.019 (0.096)	Data 0.000 (0.001)	Loss 1.7581 (1.5425)	Prec@1 45.455 (59.432)
****************************************
clean_train:	 * Prec@1 86.744
noisy_train:	 * Prec@1 56.641
clean_val:	 * Prec@1 86.063
noisy_val:	 * Prec@1 55.597
****************************************
Epoch: [48][50/516]	LR 0.053140	Time 0.088 (0.091)	Data 0.000 (0.004)	Loss 1.6859 (1.5739)	Prec@1 53.125 (58.000)
Epoch: [48][100/516]	LR 0.053140	Time 0.087 (0.089)	Data 0.000 (0.002)	Loss 1.4911 (1.5500)	Prec@1 61.719 (58.922)
Epoch: [48][150/516]	LR 0.053140	Time 0.088 (0.086)	Data 0.000 (0.002)	Loss 1.7036 (1.5509)	Prec@1 53.906 (58.922)
Epoch: [48][200/516]	LR 0.053140	Time 0.087 (0.087)	Data 0.000 (0.001)	Loss 1.4612 (1.5421)	Prec@1 61.719 (59.281)
Epoch: [48][250/516]	LR 0.053140	Time 0.088 (0.087)	Data 0.000 (0.001)	Loss 1.4876 (1.5446)	Prec@1 60.938 (59.153)
Epoch: [48][300/516]	LR 0.053140	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5957 (1.5433)	Prec@1 57.031 (59.190)
Epoch: [48][350/516]	LR 0.053140	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.5284 (1.5432)	Prec@1 59.375 (59.254)
Epoch: [48][400/516]	LR 0.053140	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 1.5715 (1.5440)	Prec@1 56.250 (59.242)
Epoch: [48][450/516]	LR 0.053140	Time 0.080 (0.083)	Data 0.000 (0.001)	Loss 1.3568 (1.5417)	Prec@1 64.062 (59.354)
Epoch: [48][500/516]	LR 0.053140	Time 0.083 (0.083)	Data 0.000 (0.001)	Loss 1.6949 (1.5434)	Prec@1 53.906 (59.339)
Epoch: [48][516/516]	LR 0.053140	Time 0.022 (0.083)	Data 0.000 (0.001)	Loss 1.8808 (1.5425)	Prec@1 45.455 (59.373)
****************************************
clean_train:	 * Prec@1 90.308
noisy_train:	 * Prec@1 58.808
clean_val:	 * Prec@1 89.626
noisy_val:	 * Prec@1 57.453
****************************************
Epoch: [49][50/516]	LR 0.051571	Time 0.041 (0.081)	Data 0.000 (0.004)	Loss 1.4937 (1.5377)	Prec@1 60.156 (59.547)
Epoch: [49][100/516]	LR 0.051571	Time 0.088 (0.083)	Data 0.000 (0.002)	Loss 1.6972 (1.5565)	Prec@1 53.125 (58.898)
Epoch: [49][150/516]	LR 0.051571	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 1.4674 (1.5510)	Prec@1 60.156 (59.000)
Epoch: [49][200/516]	LR 0.051571	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5730 (1.5487)	Prec@1 57.812 (59.160)
Epoch: [49][250/516]	LR 0.051571	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4122 (1.5399)	Prec@1 63.281 (59.513)
Epoch: [49][300/516]	LR 0.051571	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.3474 (1.5368)	Prec@1 67.188 (59.682)
Epoch: [49][350/516]	LR 0.051571	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.5915 (1.5377)	Prec@1 57.031 (59.656)
Epoch: [49][400/516]	LR 0.051571	Time 0.041 (0.084)	Data 0.000 (0.001)	Loss 1.6543 (1.5396)	Prec@1 56.250 (59.570)
Epoch: [49][450/516]	LR 0.051571	Time 0.081 (0.082)	Data 0.000 (0.001)	Loss 1.4533 (1.5422)	Prec@1 64.062 (59.460)
Epoch: [49][500/516]	LR 0.051571	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 1.5988 (1.5394)	Prec@1 56.250 (59.522)
Epoch: [49][516/516]	LR 0.051571	Time 0.020 (0.082)	Data 0.000 (0.001)	Loss 1.5796 (1.5394)	Prec@1 54.545 (59.538)
****************************************
clean_train:	 * Prec@1 90.604
noisy_train:	 * Prec@1 59.009
clean_val:	 * Prec@1 89.899
noisy_val:	 * Prec@1 57.617
****************************************
Epoch: [50][50/516]	LR 0.050000	Time 0.081 (0.087)	Data 0.000 (0.004)	Loss 1.4242 (1.5428)	Prec@1 64.062 (59.344)
Epoch: [50][100/516]	LR 0.050000	Time 0.083 (0.085)	Data 0.000 (0.002)	Loss 1.5049 (1.5291)	Prec@1 60.938 (59.984)
Epoch: [50][150/516]	LR 0.050000	Time 0.056 (0.084)	Data 0.000 (0.002)	Loss 1.4101 (1.5335)	Prec@1 64.062 (59.729)
Epoch: [50][200/516]	LR 0.050000	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 1.7291 (1.5404)	Prec@1 52.344 (59.551)
Epoch: [50][250/516]	LR 0.050000	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.5525 (1.5375)	Prec@1 59.375 (59.678)
Epoch: [50][300/516]	LR 0.050000	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.3598 (1.5339)	Prec@1 67.188 (59.823)
Epoch: [50][350/516]	LR 0.050000	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4431 (1.5359)	Prec@1 64.844 (59.795)
Epoch: [50][400/516]	LR 0.050000	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.6289 (1.5349)	Prec@1 56.250 (59.857)
Epoch: [50][450/516]	LR 0.050000	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 1.6359 (1.5346)	Prec@1 57.812 (59.845)
Epoch: [50][500/516]	LR 0.050000	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 1.4677 (1.5352)	Prec@1 60.938 (59.847)
Epoch: [50][516/516]	LR 0.050000	Time 0.023 (0.083)	Data 0.000 (0.001)	Loss 1.5349 (1.5364)	Prec@1 63.636 (59.794)
****************************************
clean_train:	 * Prec@1 90.595
noisy_train:	 * Prec@1 59.074
clean_val:	                                                                                                                                                                                                                                                                                                                           