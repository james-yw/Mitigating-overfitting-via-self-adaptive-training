Namespace(arch='resnet18', base_width=64, batch_size=128, data_root='../DATASETS/SVHN', dataset='SVHN', epochs=100, evaluate=False, loss='sat', lr=0.1, lr_gamma=0.1, lr_milestones=[40, 80], lr_schedule='cosine', momentum=0.9, noise_info=None, noise_rate=0.4, noise_type='corrupted_label', optimizer='sgd', print_freq=50, result_dir='./result/SVHN', resume='', sat_alpha=0.9, sat_es=0, save_dir='ckpts/SVHN/validation_resnet18_sat_corrupted_label_r0.4_cosine_', save_freq=0, seed=8426, start_epoch=0, train_sets='train', turn_off_aug=False, use_refined_label=False, val_sets=['clean_train', 'noisy_train', 'clean_val', 'noisy_val'], weight_decay=0.0005, workers=4)
Using downloaded and verified file: ../DATASETS/SVHN/train_32x32.mat
data shape: (73257, 3, 32, 32)
Using downloaded and verified file: ../DATASETS/SVHN/test_32x32.mat
data shape: (26032, 3, 32, 32)
Randomizing 40.0 percent of labels 
Noisy labels saved to ckpts/SVHN/validation_resnet18_sat_corrupted_label_r0.4_cosine_/noisy_idx_labels.npy
Size of dataset: 73257.
Label error rate: 0.36.
Using `SGD` optimizer
Using `cosine` schedule
****************************************
Epoch: [0][50/516]	LR 0.100000	Time 0.043 (0.109)	Data 0.000 (0.016)	Loss 2.2848 (2.8612)	Prec@1 17.969 (13.250)
Epoch: [0][100/516]	LR 0.100000	Time 0.098 (0.088)	Data 0.000 (0.008)	Loss 2.2736 (2.5752)	Prec@1 18.750 (14.539)
Epoch: [0][150/516]	LR 0.100000	Time 0.098 (0.091)	Data 0.000 (0.006)	Loss 2.2930 (2.4785)	Prec@1 14.844 (14.578)
Epoch: [0][200/516]	LR 0.100000	Time 0.102 (0.093)	Data 0.000 (0.004)	Loss 2.2870 (2.4278)	Prec@1 15.625 (14.695)
Epoch: [0][250/516]	LR 0.100000	Time 0.096 (0.094)	Data 0.000 (0.003)	Loss 2.2786 (2.3978)	Prec@1 19.531 (14.931)
Epoch: [0][300/516]	LR 0.100000	Time 0.090 (0.094)	Data 0.000 (0.003)	Loss 2.2640 (2.3773)	Prec@1 14.844 (15.096)
Epoch: [0][350/516]	LR 0.100000	Time 0.099 (0.095)	Data 0.000 (0.003)	Loss 2.2631 (2.3631)	Prec@1 19.531 (15.136)
Epoch: [0][400/516]	LR 0.100000	Time 0.099 (0.095)	Data 0.000 (0.002)	Loss 2.2426 (2.3522)	Prec@1 21.875 (15.193)
Epoch: [0][450/516]	LR 0.100000	Time 0.101 (0.095)	Data 0.000 (0.002)	Loss 2.2891 (2.3445)	Prec@1 16.406 (15.210)
Epoch: [0][500/516]	LR 0.100000	Time 0.099 (0.096)	Data 0.000 (0.002)	Loss 2.2821 (2.3380)	Prec@1 14.062 (15.092)
Epoch: [0][516/516]	LR 0.100000	Time 0.248 (0.096)	Data 0.000 (0.002)	Loss 2.3661 (2.3363)	Prec@1 0.000 (15.054)
****************************************
clean_train:	 * Prec@1 17.910
noisy_train:	 * Prec@1 14.855
clean_val:	 * Prec@1 17.390
noisy_val:	 * Prec@1 14.483
****************************************
Epoch: [1][50/516]	LR 0.099975	Time 0.102 (0.106)	Data 0.000 (0.008)	Loss 2.2608 (2.2752)	Prec@1 18.750 (15.453)
Epoch: [1][100/516]	LR 0.099975	Time 0.101 (0.103)	Data 0.001 (0.004)	Loss 2.2752 (2.2746)	Prec@1 14.062 (15.523)
Epoch: [1][150/516]	LR 0.099975	Time 0.099 (0.101)	Data 0.000 (0.003)	Loss 2.2684 (2.2754)	Prec@1 18.750 (15.406)
Epoch: [1][200/516]	LR 0.099975	Time 0.094 (0.100)	Data 0.000 (0.002)	Loss 2.3036 (2.2755)	Prec@1 13.281 (15.395)
Epoch: [1][250/516]	LR 0.099975	Time 0.096 (0.100)	Data 0.000 (0.002)	Loss 2.2877 (2.2758)	Prec@1 10.156 (15.369)
Epoch: [1][300/516]	LR 0.099975	Time 0.098 (0.100)	Data 0.000 (0.002)	Loss 2.2840 (2.2761)	Prec@1 10.938 (15.297)
Epoch: [1][350/516]	LR 0.099975	Time 0.103 (0.099)	Data 0.000 (0.001)	Loss 2.2817 (2.2757)	Prec@1 11.719 (15.426)
Epoch: [1][400/516]	LR 0.099975	Time 0.099 (0.099)	Data 0.000 (0.001)	Loss 2.2636 (2.2758)	Prec@1 21.875 (15.406)
Epoch: [1][450/516]	LR 0.099975	Time 0.094 (0.098)	Data 0.000 (0.001)	Loss 2.2873 (2.2763)	Prec@1 12.500 (15.316)
Epoch: [1][500/516]	LR 0.099975	Time 0.100 (0.098)	Data 0.000 (0.001)	Loss 2.2856 (2.2765)	Prec@1 9.375 (15.347)
Epoch: [1][516/516]	LR 0.099975	Time 0.034 (0.098)	Data 0.000 (0.001)	Loss 2.2765 (2.2764)	Prec@1 9.091 (15.340)
****************************************
clean_train:	 * Prec@1 18.956
noisy_train:	 * Prec@1 15.469
clean_val:	 * Prec@1 18.823
noisy_val:	 * Prec@1 14.810
****************************************
Epoch: [2][50/516]	LR 0.099901	Time 0.099 (0.105)	Data 0.000 (0.007)	Loss 2.2753 (2.2738)	Prec@1 14.062 (15.953)
Epoch: [2][100/516]	LR 0.099901	Time 0.097 (0.101)	Data 0.000 (0.004)	Loss 2.2892 (2.2753)	Prec@1 13.281 (15.586)
Epoch: [2][150/516]	LR 0.099901	Time 0.097 (0.100)	Data 0.000 (0.003)	Loss 2.2700 (2.2745)	Prec@1 14.844 (15.490)
Epoch: [2][200/516]	LR 0.099901	Time 0.102 (0.100)	Data 0.000 (0.002)	Loss 2.2861 (2.2728)	Prec@1 13.281 (15.754)
Epoch: [2][250/516]	LR 0.099901	Time 0.103 (0.100)	Data 0.000 (0.002)	Loss 2.2860 (2.2709)	Prec@1 14.844 (16.206)
Epoch: [2][300/516]	LR 0.099901	Time 0.099 (0.099)	Data 0.000 (0.001)	Loss 2.2320 (2.2678)	Prec@1 23.438 (16.646)
Epoch: [2][350/516]	LR 0.099901	Time 0.097 (0.098)	Data 0.000 (0.001)	Loss 2.1976 (2.2608)	Prec@1 24.219 (17.266)
Epoch: [2][400/516]	LR 0.099901	Time 0.095 (0.098)	Data 0.000 (0.001)	Loss 2.2228 (2.2543)	Prec@1 21.875 (17.791)
Epoch: [2][450/516]	LR 0.099901	Time 0.044 (0.097)	Data 0.000 (0.001)	Loss 2.1850 (2.2477)	Prec@1 26.562 (18.462)
Epoch: [2][500/516]	LR 0.099901	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 2.1646 (2.2386)	Prec@1 25.781 (19.319)
Epoch: [2][516/516]	LR 0.099901	Time 0.037 (0.097)	Data 0.000 (0.001)	Loss 2.1212 (2.2361)	Prec@1 27.273 (19.578)
****************************************
clean_train:	 * Prec@1 33.844
noisy_train:	 * Prec@1 24.650
clean_val:	 * Prec@1 33.265
noisy_val:	 * Prec@1 23.696
****************************************
Epoch: [3][50/516]	LR 0.099778	Time 0.095 (0.105)	Data 0.000 (0.007)	Loss 2.1227 (2.1585)	Prec@1 28.906 (27.984)
Epoch: [3][100/516]	LR 0.099778	Time 0.097 (0.101)	Data 0.000 (0.004)	Loss 2.1288 (2.1413)	Prec@1 33.594 (30.266)
Epoch: [3][150/516]	LR 0.099778	Time 0.096 (0.100)	Data 0.000 (0.002)	Loss 2.0585 (2.1270)	Prec@1 35.938 (31.714)
Epoch: [3][200/516]	LR 0.099778	Time 0.110 (0.100)	Data 0.000 (0.002)	Loss 2.0193 (2.1134)	Prec@1 39.062 (33.207)
Epoch: [3][250/516]	LR 0.099778	Time 0.097 (0.098)	Data 0.000 (0.002)	Loss 2.0136 (2.0996)	Prec@1 36.719 (34.697)
Epoch: [3][300/516]	LR 0.099778	Time 0.091 (0.098)	Data 0.000 (0.001)	Loss 2.0459 (2.0856)	Prec@1 42.969 (36.341)
Epoch: [3][350/516]	LR 0.099778	Time 0.044 (0.097)	Data 0.000 (0.001)	Loss 1.9080 (2.0729)	Prec@1 53.906 (37.757)
Epoch: [3][400/516]	LR 0.099778	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.9094 (2.0597)	Prec@1 53.906 (39.082)
Epoch: [3][450/516]	LR 0.099778	Time 0.100 (0.097)	Data 0.000 (0.001)	Loss 1.9594 (2.0483)	Prec@1 49.219 (40.253)
Epoch: [3][500/516]	LR 0.099778	Time 0.092 (0.096)	Data 0.000 (0.001)	Loss 2.0154 (2.0386)	Prec@1 46.094 (41.155)
Epoch: [3][516/516]	LR 0.099778	Time 0.029 (0.095)	Data 0.000 (0.001)	Loss 1.8989 (2.0363)	Prec@1 63.636 (41.389)
****************************************
clean_train:	 * Prec@1 77.393
noisy_train:	 * Prec@1 50.466
clean_val:	 * Prec@1 76.986
noisy_val:	 * Prec@1 50.532
****************************************
Epoch: [4][50/516]	LR 0.099606	Time 0.097 (0.105)	Data 0.000 (0.007)	Loss 2.0349 (1.9416)	Prec@1 42.969 (51.828)
Epoch: [4][100/516]	LR 0.099606	Time 0.099 (0.102)	Data 0.000 (0.004)	Loss 1.9157 (1.9373)	Prec@1 54.688 (52.109)
Epoch: [4][150/516]	LR 0.099606	Time 0.092 (0.098)	Data 0.000 (0.002)	Loss 1.9292 (1.9356)	Prec@1 55.469 (52.458)
Epoch: [4][200/516]	LR 0.099606	Time 0.097 (0.098)	Data 0.000 (0.002)	Loss 1.8866 (1.9340)	Prec@1 57.031 (52.551)
Epoch: [4][250/516]	LR 0.099606	Time 0.101 (0.097)	Data 0.000 (0.002)	Loss 1.9611 (1.9310)	Prec@1 46.875 (52.822)
Epoch: [4][300/516]	LR 0.099606	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.9017 (1.9322)	Prec@1 57.812 (52.667)
Epoch: [4][350/516]	LR 0.099606	Time 0.101 (0.096)	Data 0.000 (0.001)	Loss 1.8300 (1.9315)	Prec@1 59.375 (52.728)
Epoch: [4][400/516]	LR 0.099606	Time 0.092 (0.096)	Data 0.000 (0.001)	Loss 1.8841 (1.9316)	Prec@1 56.250 (52.752)
Epoch: [4][450/516]	LR 0.099606	Time 0.098 (0.094)	Data 0.000 (0.001)	Loss 1.9790 (1.9286)	Prec@1 49.219 (52.991)
Epoch: [4][500/516]	LR 0.099606	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8600 (1.9262)	Prec@1 56.250 (53.156)
Epoch: [4][516/516]	LR 0.099606	Time 0.033 (0.094)	Data 0.000 (0.001)	Loss 2.0910 (1.9263)	Prec@1 45.455 (53.140)
****************************************
clean_train:	 * Prec@1 84.990
noisy_train:	 * Prec@1 55.118
clean_val:	 * Prec@1 85.121
noisy_val:	 * Prec@1 55.405
****************************************
Epoch: [5][50/516]	LR 0.099384	Time 0.092 (0.098)	Data 0.000 (0.006)	Loss 1.8786 (1.9021)	Prec@1 57.031 (55.062)
Epoch: [5][100/516]	LR 0.099384	Time 0.095 (0.097)	Data 0.000 (0.003)	Loss 1.8846 (1.9005)	Prec@1 53.906 (55.117)
Epoch: [5][150/516]	LR 0.099384	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8715 (1.8976)	Prec@1 59.375 (55.151)
Epoch: [5][200/516]	LR 0.099384	Time 0.097 (0.095)	Data 0.000 (0.002)	Loss 1.8678 (1.8944)	Prec@1 59.375 (55.426)
Epoch: [5][250/516]	LR 0.099384	Time 0.094 (0.096)	Data 0.000 (0.002)	Loss 1.8848 (1.8933)	Prec@1 53.906 (55.497)
Epoch: [5][300/516]	LR 0.099384	Time 0.046 (0.095)	Data 0.000 (0.001)	Loss 1.9919 (1.8918)	Prec@1 46.094 (55.615)
Epoch: [5][350/516]	LR 0.099384	Time 0.044 (0.092)	Data 0.000 (0.001)	Loss 1.8310 (1.8924)	Prec@1 67.969 (55.670)
Epoch: [5][400/516]	LR 0.099384	Time 0.097 (0.093)	Data 0.000 (0.001)	Loss 1.8893 (1.8929)	Prec@1 56.250 (55.656)
Epoch: [5][450/516]	LR 0.099384	Time 0.099 (0.093)	Data 0.000 (0.001)	Loss 1.9161 (1.8940)	Prec@1 53.125 (55.542)
Epoch: [5][500/516]	LR 0.099384	Time 0.101 (0.094)	Data 0.000 (0.001)	Loss 1.8277 (1.8942)	Prec@1 63.281 (55.577)
Epoch: [5][516/516]	LR 0.099384	Time 0.023 (0.094)	Data 0.000 (0.001)	Loss 1.8795 (1.8938)	Prec@1 63.636 (55.608)
****************************************
clean_train:	 * Prec@1 86.152
noisy_train:	 * Prec@1 56.060
clean_val:	 * Prec@1 85.599
noisy_val:	 * Prec@1 55.501
****************************************
Epoch: [6][50/516]	LR 0.099114	Time 0.095 (0.103)	Data 0.000 (0.007)	Loss 1.8712 (1.8743)	Prec@1 55.469 (56.375)
Epoch: [6][100/516]	LR 0.099114	Time 0.092 (0.097)	Data 0.000 (0.004)	Loss 1.8960 (1.8793)	Prec@1 53.906 (56.086)
Epoch: [6][150/516]	LR 0.099114	Time 0.097 (0.097)	Data 0.000 (0.003)	Loss 1.8350 (1.8757)	Prec@1 57.812 (56.427)
Epoch: [6][200/516]	LR 0.099114	Time 0.105 (0.097)	Data 0.000 (0.002)	Loss 1.8914 (1.8776)	Prec@1 53.125 (56.406)
Epoch: [6][250/516]	LR 0.099114	Time 0.045 (0.094)	Data 0.000 (0.002)	Loss 1.8498 (1.8765)	Prec@1 58.594 (56.538)
Epoch: [6][300/516]	LR 0.099114	Time 0.097 (0.092)	Data 0.000 (0.001)	Loss 1.8441 (1.8757)	Prec@1 60.938 (56.599)
Epoch: [6][350/516]	LR 0.099114	Time 0.097 (0.093)	Data 0.000 (0.001)	Loss 1.9090 (1.8746)	Prec@1 53.125 (56.719)
Epoch: [6][400/516]	LR 0.099114	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8822 (1.8749)	Prec@1 53.906 (56.680)
Epoch: [6][450/516]	LR 0.099114	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.9104 (1.8748)	Prec@1 53.906 (56.646)
Epoch: [6][500/516]	LR 0.099114	Time 0.095 (0.095)	Data 0.000 (0.001)	Loss 1.8922 (1.8735)	Prec@1 57.031 (56.747)
Epoch: [6][516/516]	LR 0.099114	Time 0.031 (0.095)	Data 0.000 (0.001)	Loss 1.8919 (1.8738)	Prec@1 54.545 (56.720)
****************************************
clean_train:	 * Prec@1 84.278
noisy_train:	 * Prec@1 54.785
clean_val:	 * Prec@1 83.825
noisy_val:	 * Prec@1 54.641
****************************************
Epoch: [7][50/516]	LR 0.098796	Time 0.100 (0.104)	Data 0.000 (0.007)	Loss 1.8246 (1.8676)	Prec@1 63.281 (56.578)
Epoch: [7][100/516]	LR 0.098796	Time 0.097 (0.100)	Data 0.000 (0.004)	Loss 1.7931 (1.8610)	Prec@1 63.281 (57.109)
Epoch: [7][150/516]	LR 0.098796	Time 0.097 (0.095)	Data 0.000 (0.003)	Loss 1.8748 (1.8634)	Prec@1 53.906 (56.755)
Epoch: [7][200/516]	LR 0.098796	Time 0.098 (0.093)	Data 0.000 (0.002)	Loss 1.8227 (1.8633)	Prec@1 59.375 (56.742)
Epoch: [7][250/516]	LR 0.098796	Time 0.099 (0.094)	Data 0.000 (0.002)	Loss 1.8113 (1.8633)	Prec@1 62.500 (56.706)
Epoch: [7][300/516]	LR 0.098796	Time 0.100 (0.094)	Data 0.001 (0.001)	Loss 1.8815 (1.8613)	Prec@1 56.250 (56.964)
Epoch: [7][350/516]	LR 0.098796	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 1.8636 (1.8615)	Prec@1 57.031 (56.958)
Epoch: [7][400/516]	LR 0.098796	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8114 (1.8599)	Prec@1 64.062 (57.189)
Epoch: [7][450/516]	LR 0.098796	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8142 (1.8600)	Prec@1 60.156 (57.182)
Epoch: [7][500/516]	LR 0.098796	Time 0.102 (0.096)	Data 0.000 (0.001)	Loss 1.8175 (1.8593)	Prec@1 61.719 (57.211)
Epoch: [7][516/516]	LR 0.098796	Time 0.031 (0.095)	Data 0.000 (0.001)	Loss 2.2075 (1.8591)	Prec@1 27.273 (57.243)
****************************************
clean_train:	 * Prec@1 87.551
noisy_train:	 * Prec@1 56.899
clean_val:	 * Prec@1 86.828
noisy_val:	 * Prec@1 56.320
****************************************
Epoch: [8][50/516]	LR 0.098429	Time 0.043 (0.096)	Data 0.000 (0.009)	Loss 1.8447 (1.8516)	Prec@1 56.250 (57.297)
Epoch: [8][100/516]	LR 0.098429	Time 0.099 (0.090)	Data 0.000 (0.005)	Loss 1.8704 (1.8437)	Prec@1 53.125 (58.203)
Epoch: [8][150/516]	LR 0.098429	Time 0.092 (0.093)	Data 0.000 (0.003)	Loss 1.8475 (1.8465)	Prec@1 58.594 (57.896)
Epoch: [8][200/516]	LR 0.098429	Time 0.097 (0.094)	Data 0.000 (0.002)	Loss 1.8789 (1.8473)	Prec@1 53.906 (57.727)
Epoch: [8][250/516]	LR 0.098429	Time 0.097 (0.095)	Data 0.000 (0.002)	Loss 1.8367 (1.8493)	Prec@1 60.938 (57.547)
Epoch: [8][300/516]	LR 0.098429	Time 0.097 (0.095)	Data 0.000 (0.002)	Loss 1.8472 (1.8483)	Prec@1 55.469 (57.664)
Epoch: [8][350/516]	LR 0.098429	Time 0.100 (0.096)	Data 0.000 (0.002)	Loss 1.8328 (1.8475)	Prec@1 59.375 (57.739)
Epoch: [8][400/516]	LR 0.098429	Time 0.099 (0.096)	Data 0.000 (0.001)	Loss 1.8367 (1.8478)	Prec@1 57.812 (57.678)
Epoch: [8][450/516]	LR 0.098429	Time 0.104 (0.096)	Data 0.000 (0.001)	Loss 1.8744 (1.8473)	Prec@1 54.688 (57.707)
Epoch: [8][500/516]	LR 0.098429	Time 0.099 (0.096)	Data 0.000 (0.001)	Loss 1.8408 (1.8466)	Prec@1 58.594 (57.812)
Epoch: [8][516/516]	LR 0.098429	Time 0.030 (0.096)	Data 0.000 (0.001)	Loss 1.8912 (1.8462)	Prec@1 54.545 (57.839)
****************************************
clean_train:	 * Prec@1 88.124
noisy_train:	 * Prec@1 57.187
clean_val:	 * Prec@1 87.920
noisy_val:	 * Prec@1 56.989
****************************************
Epoch: [9][50/516]	LR 0.098015	Time 0.099 (0.105)	Data 0.000 (0.008)	Loss 1.8413 (1.8499)	Prec@1 55.469 (56.484)
Epoch: [9][100/516]	LR 0.098015	Time 0.099 (0.102)	Data 0.000 (0.004)	Loss 1.8068 (1.8369)	Prec@1 60.938 (57.797)
Epoch: [9][150/516]	LR 0.098015	Time 0.095 (0.100)	Data 0.000 (0.003)	Loss 1.8549 (1.8392)	Prec@1 53.906 (57.464)
Epoch: [9][200/516]	LR 0.098015	Time 0.099 (0.100)	Data 0.000 (0.002)	Loss 1.7596 (1.8384)	Prec@1 67.188 (57.566)
Epoch: [9][250/516]	LR 0.098015	Time 0.099 (0.099)	Data 0.000 (0.002)	Loss 1.7931 (1.8381)	Prec@1 64.062 (57.638)
Epoch: [9][300/516]	LR 0.098015	Time 0.098 (0.099)	Data 0.000 (0.001)	Loss 1.8144 (1.8383)	Prec@1 63.281 (57.685)
Epoch: [9][350/516]	LR 0.098015	Time 0.099 (0.099)	Data 0.000 (0.001)	Loss 1.8403 (1.8378)	Prec@1 56.250 (57.728)
Epoch: [9][400/516]	LR 0.098015	Time 0.099 (0.099)	Data 0.000 (0.001)	Loss 1.8406 (1.8386)	Prec@1 58.594 (57.648)
Epoch: [9][450/516]	LR 0.098015	Time 0.099 (0.098)	Data 0.000 (0.001)	Loss 1.7662 (1.8384)	Prec@1 71.875 (57.703)
Epoch: [9][500/516]	LR 0.098015	Time 0.095 (0.098)	Data 0.000 (0.001)	Loss 1.8531 (1.8380)	Prec@1 55.469 (57.766)
Epoch: [9][516/516]	LR 0.098015	Time 0.028 (0.098)	Data 0.000 (0.001)	Loss 1.7510 (1.8378)	Prec@1 63.636 (57.789)
****************************************
clean_train:	 * Prec@1 88.741
noisy_train:	 * Prec@1 57.606
clean_val:	 * Prec@1 88.630
noisy_val:	 * Prec@1 57.084
****************************************
Epoch: [10][50/516]	LR 0.097553	Time 0.098 (0.105)	Data 0.001 (0.007)	Loss 1.8777 (1.8353)	Prec@1 53.125 (57.234)
Epoch: [10][100/516]	LR 0.097553	Time 0.092 (0.101)	Data 0.000 (0.004)	Loss 1.8328 (1.8351)	Prec@1 58.594 (57.344)
Epoch: [10][150/516]	LR 0.097553	Time 0.095 (0.100)	Data 0.000 (0.003)	Loss 1.8375 (1.8332)	Prec@1 56.250 (57.568)
Epoch: [10][200/516]	LR 0.097553	Time 0.092 (0.100)	Data 0.000 (0.002)	Loss 1.8408 (1.8320)	Prec@1 55.469 (57.738)
Epoch: [10][250/516]	LR 0.097553	Time 0.113 (0.099)	Data 0.000 (0.002)	Loss 1.8818 (1.8298)	Prec@1 50.000 (58.059)
Epoch: [10][300/516]	LR 0.097553	Time 0.102 (0.099)	Data 0.000 (0.001)	Loss 1.7904 (1.8278)	Prec@1 61.719 (58.273)
Epoch: [10][350/516]	LR 0.097553	Time 0.097 (0.098)	Data 0.000 (0.001)	Loss 1.8104 (1.8278)	Prec@1 60.938 (58.237)
Epoch: [10][400/516]	LR 0.097553	Time 0.097 (0.098)	Data 0.000 (0.001)	Loss 1.8024 (1.8276)	Prec@1 64.062 (58.277)
Epoch: [10][450/516]	LR 0.097553	Time 0.102 (0.098)	Data 0.000 (0.001)	Loss 1.8397 (1.8269)	Prec@1 53.906 (58.342)
Epoch: [10][500/516]	LR 0.097553	Time 0.093 (0.097)	Data 0.000 (0.001)	Loss 1.8488 (1.8272)	Prec@1 53.906 (58.344)
Epoch: [10][516/516]	LR 0.097553	Time 0.029 (0.097)	Data 0.000 (0.001)	Loss 1.9376 (1.8272)	Prec@1 54.545 (58.341)
****************************************
clean_train:	 * Prec@1 87.969
noisy_train:	 * Prec@1 57.020
clean_val:	 * Prec@1 87.278
noisy_val:	 * Prec@1 56.689
****************************************
Epoch: [11][50/516]	LR 0.097044	Time 0.099 (0.104)	Data 0.000 (0.007)	Loss 1.8210 (1.8230)	Prec@1 57.812 (58.656)
Epoch: [11][100/516]	LR 0.097044	Time 0.098 (0.101)	Data 0.000 (0.004)	Loss 1.8401 (1.8213)	Prec@1 54.688 (58.648)
Epoch: [11][150/516]	LR 0.097044	Time 0.097 (0.100)	Data 0.000 (0.003)	Loss 1.8061 (1.8194)	Prec@1 61.719 (58.995)
Epoch: [11][200/516]	LR 0.097044	Time 0.098 (0.100)	Data 0.000 (0.002)	Loss 1.7949 (1.8201)	Prec@1 61.719 (58.867)
Epoch: [11][250/516]	LR 0.097044	Time 0.095 (0.098)	Data 0.000 (0.002)	Loss 1.7778 (1.8204)	Prec@1 71.094 (58.844)
Epoch: [11][300/516]	LR 0.097044	Time 0.100 (0.098)	Data 0.001 (0.001)	Loss 1.8266 (1.8205)	Prec@1 58.594 (58.737)
Epoch: [11][350/516]	LR 0.097044	Time 0.097 (0.098)	Data 0.000 (0.001)	Loss 1.8517 (1.8206)	Prec@1 52.344 (58.694)
Epoch: [11][400/516]	LR 0.097044	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.7823 (1.8209)	Prec@1 61.719 (58.676)
Epoch: [11][450/516]	LR 0.097044	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8044 (1.8204)	Prec@1 58.594 (58.712)
Epoch: [11][500/516]	LR 0.097044	Time 0.090 (0.097)	Data 0.000 (0.001)	Loss 1.8347 (1.8208)	Prec@1 57.031 (58.603)
Epoch: [11][516/516]	LR 0.097044	Time 0.032 (0.096)	Data 0.000 (0.001)	Loss 1.8545 (1.8210)	Prec@1 54.545 (58.587)
****************************************
clean_train:	 * Prec@1 87.839
noisy_train:	 * Prec@1 57.069
clean_val:	 * Prec@1 87.688
noisy_val:	 * Prec@1 56.880
****************************************
Epoch: [12][50/516]	LR 0.096489	Time 0.097 (0.105)	Data 0.000 (0.008)	Loss 1.8780 (1.8207)	Prec@1 49.219 (58.453)
Epoch: [12][100/516]	LR 0.096489	Time 0.099 (0.102)	Data 0.000 (0.004)	Loss 1.8074 (1.8176)	Prec@1 57.812 (58.844)
Epoch: [12][150/516]	LR 0.096489	Time 0.109 (0.098)	Data 0.000 (0.003)	Loss 1.8116 (1.8174)	Prec@1 57.812 (58.859)
Epoch: [12][200/516]	LR 0.096489	Time 0.097 (0.098)	Data 0.000 (0.002)	Loss 1.8142 (1.8186)	Prec@1 60.938 (58.754)
Epoch: [12][250/516]	LR 0.096489	Time 0.098 (0.098)	Data 0.000 (0.002)	Loss 1.8129 (1.8181)	Prec@1 56.250 (58.778)
Epoch: [12][300/516]	LR 0.096489	Time 0.097 (0.096)	Data 0.000 (0.002)	Loss 1.7953 (1.8178)	Prec@1 68.750 (58.870)
Epoch: [12][350/516]	LR 0.096489	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.7984 (1.8178)	Prec@1 64.062 (58.913)
Epoch: [12][400/516]	LR 0.096489	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8259 (1.8184)	Prec@1 59.375 (58.820)
Epoch: [12][450/516]	LR 0.096489	Time 0.043 (0.095)	Data 0.000 (0.001)	Loss 1.8409 (1.8193)	Prec@1 55.469 (58.686)
Epoch: [12][500/516]	LR 0.096489	Time 0.098 (0.094)	Data 0.000 (0.001)	Loss 1.8134 (1.8192)	Prec@1 63.281 (58.688)
Epoch: [12][516/516]	LR 0.096489	Time 0.034 (0.094)	Data 0.000 (0.001)	Loss 1.7151 (1.8194)	Prec@1 81.818 (58.652)
****************************************
clean_train:	 * Prec@1 90.539
noisy_train:	 * Prec@1 58.678
clean_val:	 * Prec@1 89.735
noisy_val:	 * Prec@1 57.944
****************************************
Epoch: [13][50/516]	LR 0.095888	Time 0.097 (0.097)	Data 0.000 (0.006)	Loss 1.8056 (1.8272)	Prec@1 60.938 (58.219)
Epoch: [13][100/516]	LR 0.095888	Time 0.109 (0.096)	Data 0.000 (0.003)	Loss 1.7602 (1.8224)	Prec@1 69.531 (58.602)
Epoch: [13][150/516]	LR 0.095888	Time 0.097 (0.096)	Data 0.000 (0.002)	Loss 1.8068 (1.8245)	Prec@1 59.375 (58.214)
Epoch: [13][200/516]	LR 0.095888	Time 0.094 (0.095)	Data 0.000 (0.002)	Loss 1.7902 (1.8244)	Prec@1 63.281 (58.227)
Epoch: [13][250/516]	LR 0.095888	Time 0.097 (0.095)	Data 0.000 (0.002)	Loss 1.8641 (1.8231)	Prec@1 55.469 (58.400)
Epoch: [13][300/516]	LR 0.095888	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 1.8062 (1.8222)	Prec@1 59.375 (58.578)
Epoch: [13][350/516]	LR 0.095888	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8354 (1.8221)	Prec@1 57.031 (58.692)
Epoch: [13][400/516]	LR 0.095888	Time 0.100 (0.093)	Data 0.000 (0.001)	Loss 1.8189 (1.8217)	Prec@1 57.031 (58.727)
Epoch: [13][450/516]	LR 0.095888	Time 0.101 (0.093)	Data 0.000 (0.001)	Loss 1.8272 (1.8213)	Prec@1 54.688 (58.767)
Epoch: [13][500/516]	LR 0.095888	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8042 (1.8210)	Prec@1 61.719 (58.830)
Epoch: [13][516/516]	LR 0.095888	Time 0.030 (0.094)	Data 0.000 (0.001)	Loss 1.8596 (1.8210)	Prec@1 54.545 (58.849)
****************************************
clean_train:	 * Prec@1 90.510
noisy_train:	 * Prec@1 58.631
clean_val:	 * Prec@1 90.158
noisy_val:	 * Prec@1 58.422
****************************************
Epoch: [14][50/516]	LR 0.095241	Time 0.094 (0.104)	Data 0.000 (0.008)	Loss 1.7786 (1.8275)	Prec@1 65.625 (58.469)
Epoch: [14][100/516]	LR 0.095241	Time 0.097 (0.097)	Data 0.000 (0.004)	Loss 1.8362 (1.8264)	Prec@1 54.688 (58.906)
Epoch: [14][150/516]	LR 0.095241	Time 0.097 (0.097)	Data 0.000 (0.003)	Loss 1.8252 (1.8250)	Prec@1 57.031 (58.948)
Epoch: [14][200/516]	LR 0.095241	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8302 (1.8252)	Prec@1 56.250 (58.945)
Epoch: [14][250/516]	LR 0.095241	Time 0.097 (0.094)	Data 0.000 (0.002)	Loss 1.8102 (1.8249)	Prec@1 60.938 (58.987)
Epoch: [14][300/516]	LR 0.095241	Time 0.101 (0.093)	Data 0.000 (0.002)	Loss 1.8181 (1.8243)	Prec@1 62.500 (58.992)
Epoch: [14][350/516]	LR 0.095241	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8343 (1.8246)	Prec@1 60.156 (58.879)
Epoch: [14][400/516]	LR 0.095241	Time 0.100 (0.094)	Data 0.000 (0.001)	Loss 1.8466 (1.8245)	Prec@1 53.906 (58.971)
Epoch: [14][450/516]	LR 0.095241	Time 0.095 (0.094)	Data 0.000 (0.001)	Loss 1.8386 (1.8245)	Prec@1 56.250 (58.927)
Epoch: [14][500/516]	LR 0.095241	Time 0.095 (0.095)	Data 0.000 (0.001)	Loss 1.8503 (1.8243)	Prec@1 56.250 (58.914)
Epoch: [14][516/516]	LR 0.095241	Time 0.027 (0.095)	Data 0.000 (0.001)	Loss 1.8303 (1.8244)	Prec@1 72.727 (58.936)
****************************************
clean_train:	 * Prec@1 89.833
noisy_train:	 * Prec@1 58.273
clean_val:	 * Prec@1 88.971
noisy_val:	 * Prec@1 57.494
****************************************
Epoch: [15][50/516]	LR 0.094550	Time 0.092 (0.103)	Data 0.000 (0.007)	Loss 1.8465 (1.8348)	Prec@1 55.469 (57.531)
Epoch: [15][100/516]	LR 0.094550	Time 0.097 (0.100)	Data 0.000 (0.004)	Loss 1.8364 (1.8317)	Prec@1 60.156 (58.352)
Epoch: [15][150/516]	LR 0.094550	Time 0.060 (0.096)	Data 0.000 (0.003)	Loss 1.8198 (1.8291)	Prec@1 61.719 (58.745)
Epoch: [15][200/516]	LR 0.094550	Time 0.096 (0.093)	Data 0.000 (0.002)	Loss 1.8429 (1.8287)	Prec@1 53.906 (58.664)
Epoch: [15][250/516]	LR 0.094550	Time 0.102 (0.094)	Data 0.000 (0.002)	Loss 1.8564 (1.8284)	Prec@1 58.594 (58.791)
Epoch: [15][300/516]	LR 0.094550	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8070 (1.8291)	Prec@1 63.281 (58.688)
Epoch: [15][350/516]	LR 0.094550	Time 0.089 (0.095)	Data 0.000 (0.001)	Loss 1.8335 (1.8289)	Prec@1 58.594 (58.701)
Epoch: [15][400/516]	LR 0.094550	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8112 (1.8281)	Prec@1 67.969 (58.943)
Epoch: [15][450/516]	LR 0.094550	Time 0.099 (0.096)	Data 0.000 (0.001)	Loss 1.8333 (1.8282)	Prec@1 57.031 (58.986)
Epoch: [15][500/516]	LR 0.094550	Time 0.096 (0.096)	Data 0.000 (0.001)	Loss 1.8087 (1.8277)	Prec@1 62.500 (59.073)
Epoch: [15][516/516]	LR 0.094550	Time 0.031 (0.096)	Data 0.000 (0.001)	Loss 1.7649 (1.8279)	Prec@1 72.727 (59.048)
****************************************
clean_train:	 * Prec@1 88.549
noisy_train:	 * Prec@1 57.418
clean_val:	 * Prec@1 88.329
noisy_val:	 * Prec@1 57.002
****************************************
Epoch: [16][50/516]	LR 0.093815	Time 0.095 (0.099)	Data 0.000 (0.007)	Loss 1.8359 (1.8305)	Prec@1 54.688 (59.234)
Epoch: [16][100/516]	LR 0.093815	Time 0.092 (0.089)	Data 0.000 (0.004)	Loss 1.8431 (1.8329)	Prec@1 56.250 (59.023)
Epoch: [16][150/516]	LR 0.093815	Time 0.096 (0.092)	Data 0.000 (0.003)	Loss 1.8400 (1.8313)	Prec@1 55.469 (59.281)
Epoch: [16][200/516]	LR 0.093815	Time 0.095 (0.093)	Data 0.000 (0.002)	Loss 1.8464 (1.8309)	Prec@1 50.781 (59.301)
Epoch: [16][250/516]	LR 0.093815	Time 0.095 (0.094)	Data 0.000 (0.002)	Loss 1.8232 (1.8311)	Prec@1 60.156 (59.250)
Epoch: [16][300/516]	LR 0.093815	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8488 (1.8320)	Prec@1 60.156 (59.083)
Epoch: [16][350/516]	LR 0.093815	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 1.8084 (1.8314)	Prec@1 63.281 (59.154)
Epoch: [16][400/516]	LR 0.093815	Time 0.095 (0.095)	Data 0.000 (0.001)	Loss 1.8620 (1.8311)	Prec@1 53.906 (59.109)
Epoch: [16][450/516]	LR 0.093815	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8108 (1.8311)	Prec@1 63.281 (59.186)
Epoch: [16][500/516]	LR 0.093815	Time 0.096 (0.096)	Data 0.000 (0.001)	Loss 1.8716 (1.8315)	Prec@1 49.219 (59.062)
Epoch: [16][516/516]	LR 0.093815	Time 0.031 (0.095)	Data 0.000 (0.001)	Loss 1.8644 (1.8316)	Prec@1 63.636 (59.088)
****************************************
clean_train:	 * Prec@1 91.681
noisy_train:	 * Prec@1 59.367
clean_val:	 * Prec@1 91.783
noisy_val:	 * Prec@1 59.282
****************************************
Epoch: [17][50/516]	LR 0.093037	Time 0.097 (0.103)	Data 0.000 (0.006)	Loss 1.8379 (1.8343)	Prec@1 53.906 (59.469)
Epoch: [17][100/516]	LR 0.093037	Time 0.099 (0.100)	Data 0.000 (0.003)	Loss 1.8508 (1.8346)	Prec@1 55.469 (59.531)
Epoch: [17][150/516]	LR 0.093037	Time 0.097 (0.099)	Data 0.000 (0.002)	Loss 1.8327 (1.8331)	Prec@1 61.719 (59.771)
Epoch: [17][200/516]	LR 0.093037	Time 0.096 (0.099)	Data 0.000 (0.002)	Loss 1.8686 (1.8340)	Prec@1 50.000 (59.496)
Epoch: [17][250/516]	LR 0.093037	Time 0.096 (0.098)	Data 0.001 (0.001)	Loss 1.8407 (1.8334)	Prec@1 60.156 (59.494)
Epoch: [17][300/516]	LR 0.093037	Time 0.093 (0.098)	Data 0.000 (0.001)	Loss 1.8491 (1.8332)	Prec@1 54.688 (59.508)
Epoch: [17][350/516]	LR 0.093037	Time 0.098 (0.098)	Data 0.000 (0.001)	Loss 1.8276 (1.8330)	Prec@1 60.156 (59.507)
Epoch: [17][400/516]	LR 0.093037	Time 0.099 (0.098)	Data 0.000 (0.001)	Loss 1.8378 (1.8337)	Prec@1 58.594 (59.381)
Epoch: [17][450/516]	LR 0.093037	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8475 (1.8343)	Prec@1 55.469 (59.250)
Epoch: [17][500/516]	LR 0.093037	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8290 (1.8344)	Prec@1 62.500 (59.247)
Epoch: [17][516/516]	LR 0.093037	Time 0.028 (0.097)	Data 0.000 (0.001)	Loss 1.8990 (1.8343)	Prec@1 54.545 (59.280)
****************************************
clean_train:	 * Prec@1 90.536
noisy_train:	 * Prec@1 58.693
clean_val:	 * Prec@1 90.418
noisy_val:	 * Prec@1 58.299
****************************************
Epoch: [18][50/516]	LR 0.092216	Time 0.099 (0.104)	Data 0.000 (0.007)	Loss 1.8357 (1.8372)	Prec@1 59.375 (60.297)
Epoch: [18][100/516]	LR 0.092216	Time 0.097 (0.101)	Data 0.000 (0.004)	Loss 1.8073 (1.8365)	Prec@1 63.281 (59.812)
Epoch: [18][150/516]	LR 0.092216	Time 0.099 (0.099)	Data 0.000 (0.003)	Loss 1.8504 (1.8365)	Prec@1 53.906 (59.667)
Epoch: [18][200/516]	LR 0.092216	Time 0.099 (0.099)	Data 0.000 (0.002)	Loss 1.8539 (1.8372)	Prec@1 54.688 (59.453)
Epoch: [18][250/516]	LR 0.092216	Time 0.094 (0.099)	Data 0.000 (0.002)	Loss 1.8581 (1.8369)	Prec@1 47.656 (59.550)
Epoch: [18][300/516]	LR 0.092216	Time 0.097 (0.099)	Data 0.000 (0.001)	Loss 1.8480 (1.8366)	Prec@1 55.469 (59.552)
Epoch: [18][350/516]	LR 0.092216	Time 0.096 (0.098)	Data 0.000 (0.001)	Loss 1.8461 (1.8367)	Prec@1 59.375 (59.531)
Epoch: [18][400/516]	LR 0.092216	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8197 (1.8372)	Prec@1 63.281 (59.354)
Epoch: [18][450/516]	LR 0.092216	Time 0.099 (0.097)	Data 0.000 (0.001)	Loss 1.8404 (1.8367)	Prec@1 58.594 (59.438)
Epoch: [18][500/516]	LR 0.092216	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8393 (1.8373)	Prec@1 54.688 (59.339)
Epoch: [18][516/516]	LR 0.092216	Time 0.028 (0.097)	Data 0.000 (0.001)	Loss 1.8727 (1.8372)	Prec@1 45.455 (59.344)
****************************************
clean_train:	 * Prec@1 91.878
noisy_train:	 * Prec@1 59.508
clean_val:	 * Prec@1 91.387
noisy_val:	 * Prec@1 58.900
****************************************
Epoch: [19][50/516]	LR 0.091354	Time 0.100 (0.104)	Data 0.000 (0.006)	Loss 1.8562 (1.8387)	Prec@1 54.688 (59.312)
Epoch: [19][100/516]	LR 0.091354	Time 0.099 (0.100)	Data 0.000 (0.003)	Loss 1.8741 (1.8366)	Prec@1 47.656 (59.891)
Epoch: [19][150/516]	LR 0.091354	Time 0.099 (0.099)	Data 0.000 (0.002)	Loss 1.8535 (1.8363)	Prec@1 53.906 (60.047)
Epoch: [19][200/516]	LR 0.091354	Time 0.096 (0.099)	Data 0.000 (0.002)	Loss 1.8358 (1.8374)	Prec@1 64.844 (59.934)
Epoch: [19][250/516]	LR 0.091354	Time 0.061 (0.099)	Data 0.000 (0.001)	Loss 1.8339 (1.8381)	Prec@1 58.594 (59.772)
Epoch: [19][300/516]	LR 0.091354	Time 0.101 (0.097)	Data 0.000 (0.001)	Loss 1.8475 (1.8386)	Prec@1 65.625 (59.677)
Epoch: [19][350/516]	LR 0.091354	Time 0.090 (0.097)	Data 0.000 (0.001)	Loss 1.8436 (1.8387)	Prec@1 59.375 (59.641)
Epoch: [19][400/516]	LR 0.091354	Time 0.095 (0.097)	Data 0.000 (0.001)	Loss 1.8242 (1.8389)	Prec@1 60.938 (59.625)
Epoch: [19][450/516]	LR 0.091354	Time 0.095 (0.097)	Data 0.000 (0.001)	Loss 1.8307 (1.8393)	Prec@1 59.375 (59.557)
Epoch: [19][500/516]	LR 0.091354	Time 0.094 (0.097)	Data 0.000 (0.001)	Loss 1.8485 (1.8397)	Prec@1 60.938 (59.453)
Epoch: [19][516/516]	LR 0.091354	Time 0.032 (0.096)	Data 0.000 (0.001)	Loss 1.8057 (1.8400)	Prec@1 63.636 (59.426)
****************************************
clean_train:	 * Prec@1 91.095
noisy_train:	 * Prec@1 58.936
clean_val:	 * Prec@1 90.609
noisy_val:	 * Prec@1 58.709
****************************************
Epoch: [20][50/516]	LR 0.090451	Time 0.102 (0.105)	Data 0.000 (0.007)	Loss 1.8300 (1.8437)	Prec@1 59.375 (59.031)
Epoch: [20][100/516]	LR 0.090451	Time 0.099 (0.101)	Data 0.000 (0.004)	Loss 1.8336 (1.8432)	Prec@1 55.469 (59.367)
Epoch: [20][150/516]	LR 0.090451	Time 0.099 (0.100)	Data 0.000 (0.003)	Loss 1.8252 (1.8412)	Prec@1 55.469 (59.781)
Epoch: [20][200/516]	LR 0.090451	Time 0.094 (0.097)	Data 0.000 (0.002)	Loss 1.8303 (1.8419)	Prec@1 58.594 (59.586)
Epoch: [20][250/516]	LR 0.090451	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8508 (1.8417)	Prec@1 57.812 (59.659)
Epoch: [20][300/516]	LR 0.090451	Time 0.043 (0.096)	Data 0.000 (0.001)	Loss 1.8549 (1.8417)	Prec@1 52.344 (59.635)
Epoch: [20][350/516]	LR 0.090451	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8323 (1.8412)	Prec@1 67.969 (59.701)
Epoch: [20][400/516]	LR 0.090451	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8506 (1.8420)	Prec@1 55.469 (59.516)
Epoch: [20][450/516]	LR 0.090451	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8461 (1.8423)	Prec@1 55.469 (59.439)
Epoch: [20][500/516]	LR 0.090451	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8216 (1.8426)	Prec@1 64.062 (59.392)
Epoch: [20][516/516]	LR 0.090451	Time 0.032 (0.094)	Data 0.000 (0.001)	Loss 1.9018 (1.8427)	Prec@1 54.545 (59.374)
****************************************
clean_train:	 * Prec@1 89.266
noisy_train:	 * Prec@1 57.948
clean_val:	 * Prec@1 88.780
noisy_val:	 * Prec@1 57.235
****************************************
Epoch: [21][50/516]	LR 0.089508	Time 0.096 (0.103)	Data 0.000 (0.006)	Loss 1.8528 (1.8444)	Prec@1 58.594 (59.891)
Epoch: [21][100/516]	LR 0.089508	Time 0.098 (0.097)	Data 0.000 (0.003)	Loss 1.8814 (1.8448)	Prec@1 52.344 (59.594)
Epoch: [21][150/516]	LR 0.089508	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8542 (1.8443)	Prec@1 60.938 (59.536)
Epoch: [21][200/516]	LR 0.089508	Time 0.099 (0.097)	Data 0.000 (0.002)	Loss 1.8583 (1.8440)	Prec@1 48.438 (59.500)
Epoch: [21][250/516]	LR 0.089508	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8390 (1.8441)	Prec@1 57.031 (59.434)
Epoch: [21][300/516]	LR 0.089508	Time 0.100 (0.096)	Data 0.000 (0.001)	Loss 1.8508 (1.8439)	Prec@1 58.594 (59.479)
Epoch: [21][350/516]	LR 0.089508	Time 0.092 (0.095)	Data 0.000 (0.001)	Loss 1.8449 (1.8445)	Prec@1 55.469 (59.355)
Epoch: [21][400/516]	LR 0.089508	Time 0.096 (0.093)	Data 0.000 (0.001)	Loss 1.8730 (1.8448)	Prec@1 51.562 (59.375)
Epoch: [21][450/516]	LR 0.089508	Time 0.099 (0.093)	Data 0.000 (0.001)	Loss 1.8388 (1.8449)	Prec@1 66.406 (59.438)
Epoch: [21][500/516]	LR 0.089508	Time 0.096 (0.093)	Data 0.000 (0.001)	Loss 1.8202 (1.8448)	Prec@1 68.750 (59.373)
Epoch: [21][516/516]	LR 0.089508	Time 0.029 (0.093)	Data 0.000 (0.001)	Loss 1.8821 (1.8447)	Prec@1 72.727 (59.420)
****************************************
clean_train:	 * Prec@1 89.680
noisy_train:	 * Prec@1 58.164
clean_val:	 * Prec@1 89.476
noisy_val:	 * Prec@1 57.808
****************************************
Epoch: [22][50/516]	LR 0.088526	Time 0.097 (0.103)	Data 0.000 (0.006)	Loss 1.8635 (1.8543)	Prec@1 57.031 (57.828)
Epoch: [22][100/516]	LR 0.088526	Time 0.094 (0.099)	Data 0.000 (0.003)	Loss 1.8325 (1.8509)	Prec@1 57.031 (58.102)
Epoch: [22][150/516]	LR 0.088526	Time 0.097 (0.096)	Data 0.000 (0.002)	Loss 1.8454 (1.8509)	Prec@1 56.250 (58.068)
Epoch: [22][200/516]	LR 0.088526	Time 0.095 (0.096)	Data 0.000 (0.002)	Loss 1.8661 (1.8500)	Prec@1 51.562 (58.523)
Epoch: [22][250/516]	LR 0.088526	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8499 (1.8496)	Prec@1 56.250 (58.584)
Epoch: [22][300/516]	LR 0.088526	Time 0.043 (0.094)	Data 0.000 (0.001)	Loss 1.8472 (1.8492)	Prec@1 57.031 (58.716)
Epoch: [22][350/516]	LR 0.088526	Time 0.095 (0.094)	Data 0.000 (0.001)	Loss 1.8412 (1.8484)	Prec@1 60.156 (58.917)
Epoch: [22][400/516]	LR 0.088526	Time 0.097 (0.094)	Data 0.000 (0.001)	Loss 1.8394 (1.8485)	Prec@1 59.375 (59.084)
Epoch: [22][450/516]	LR 0.088526	Time 0.100 (0.094)	Data 0.000 (0.001)	Loss 1.8487 (1.8483)	Prec@1 59.375 (59.123)
Epoch: [22][500/516]	LR 0.088526	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8333 (1.8480)	Prec@1 60.156 (59.150)
Epoch: [22][516/516]	LR 0.088526	Time 0.029 (0.095)	Data 0.000 (0.001)	Loss 2.0497 (1.8478)	Prec@1 54.545 (59.189)
****************************************
clean_train:	 * Prec@1 91.969
noisy_train:	 * Prec@1 59.430
clean_val:	 * Prec@1 91.387
noisy_val:	 * Prec@1 58.982
****************************************
Epoch: [23][50/516]	LR 0.087506	Time 0.095 (0.098)	Data 0.000 (0.007)	Loss 1.8534 (1.8586)	Prec@1 59.375 (58.141)
Epoch: [23][100/516]	LR 0.087506	Time 0.097 (0.097)	Data 0.000 (0.003)	Loss 1.8493 (1.8551)	Prec@1 63.281 (58.859)
Epoch: [23][150/516]	LR 0.087506	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8427 (1.8530)	Prec@1 57.031 (58.844)
Epoch: [23][200/516]	LR 0.087506	Time 0.097 (0.094)	Data 0.000 (0.002)	Loss 1.8640 (1.8521)	Prec@1 56.250 (59.035)
Epoch: [23][250/516]	LR 0.087506	Time 0.099 (0.093)	Data 0.000 (0.002)	Loss 1.8680 (1.8517)	Prec@1 52.344 (59.047)
Epoch: [23][300/516]	LR 0.087506	Time 0.097 (0.093)	Data 0.000 (0.001)	Loss 1.8309 (1.8510)	Prec@1 64.062 (59.216)
Epoch: [23][350/516]	LR 0.087506	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8452 (1.8504)	Prec@1 56.250 (59.254)
Epoch: [23][400/516]	LR 0.087506	Time 0.097 (0.094)	Data 0.000 (0.001)	Loss 1.8463 (1.8499)	Prec@1 67.188 (59.404)
Epoch: [23][450/516]	LR 0.087506	Time 0.095 (0.095)	Data 0.000 (0.001)	Loss 1.8316 (1.8495)	Prec@1 65.625 (59.455)
Epoch: [23][500/516]	LR 0.087506	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8648 (1.8495)	Prec@1 51.562 (59.462)
Epoch: [23][516/516]	LR 0.087506	Time 0.030 (0.095)	Data 0.000 (0.001)	Loss 1.8614 (1.8494)	Prec@1 72.727 (59.433)
****************************************
clean_train:	 * Prec@1 91.794
noisy_train:	 * Prec@1 59.335
clean_val:	 * Prec@1 91.250
noisy_val:	 * Prec@1 58.627
****************************************
Epoch: [24][50/516]	LR 0.086448	Time 0.097 (0.103)	Data 0.000 (0.006)	Loss 1.8614 (1.8558)	Prec@1 63.281 (58.922)
Epoch: [24][100/516]	LR 0.086448	Time 0.046 (0.096)	Data 0.000 (0.003)	Loss 1.8446 (1.8538)	Prec@1 63.281 (59.016)
Epoch: [24][150/516]	LR 0.086448	Time 0.096 (0.092)	Data 0.000 (0.002)	Loss 1.8493 (1.8529)	Prec@1 63.281 (59.135)
Epoch: [24][200/516]	LR 0.086448	Time 0.095 (0.093)	Data 0.000 (0.002)	Loss 1.8413 (1.8516)	Prec@1 63.281 (59.391)
Epoch: [24][250/516]	LR 0.086448	Time 0.097 (0.094)	Data 0.000 (0.001)	Loss 1.8589 (1.8513)	Prec@1 61.719 (59.491)
Epoch: [24][300/516]	LR 0.086448	Time 0.102 (0.095)	Data 0.000 (0.001)	Loss 1.8440 (1.8513)	Prec@1 60.938 (59.492)
Epoch: [24][350/516]	LR 0.086448	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8491 (1.8517)	Prec@1 54.688 (59.397)
Epoch: [24][400/516]	LR 0.086448	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 1.8599 (1.8514)	Prec@1 50.781 (59.447)
Epoch: [24][450/516]	LR 0.086448	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8296 (1.8515)	Prec@1 62.500 (59.359)
Epoch: [24][500/516]	LR 0.086448	Time 0.096 (0.096)	Data 0.000 (0.001)	Loss 1.8653 (1.8513)	Prec@1 54.688 (59.358)
Epoch: [24][516/516]	LR 0.086448	Time 0.027 (0.095)	Data 0.000 (0.001)	Loss 1.9169 (1.8512)	Prec@1 27.273 (59.406)
****************************************
clean_train:	 * Prec@1 92.786
noisy_train:	 * Prec@1 59.976
clean_val:	 * Prec@1 92.643
noisy_val:	 * Prec@1 59.651
****************************************
Epoch: [25][50/516]	LR 0.085355	Time 0.099 (0.087)	Data 0.000 (0.007)	Loss 1.8454 (1.8548)	Prec@1 59.375 (58.750)
Epoch: [25][100/516]	LR 0.085355	Time 0.096 (0.092)	Data 0.000 (0.003)	Loss 1.8653 (1.8561)	Prec@1 56.250 (58.945)
Epoch: [25][150/516]	LR 0.085355	Time 0.097 (0.094)	Data 0.000 (0.002)	Loss 1.8499 (1.8539)	Prec@1 61.719 (59.505)
Epoch: [25][200/516]	LR 0.085355	Time 0.097 (0.094)	Data 0.000 (0.002)	Loss 1.8624 (1.8529)	Prec@1 66.406 (59.688)
Epoch: [25][250/516]	LR 0.085355	Time 0.097 (0.095)	Data 0.000 (0.002)	Loss 1.8530 (1.8528)	Prec@1 56.250 (59.584)
Epoch: [25][300/516]	LR 0.085355	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 1.8509 (1.8527)	Prec@1 57.812 (59.625)
Epoch: [25][350/516]	LR 0.085355	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8559 (1.8529)	Prec@1 53.125 (59.484)
Epoch: [25][400/516]	LR 0.085355	Time 0.096 (0.096)	Data 0.000 (0.001)	Loss 1.8700 (1.8528)	Prec@1 60.938 (59.438)
Epoch: [25][450/516]	LR 0.085355	Time 0.096 (0.096)	Data 0.000 (0.001)	Loss 1.8614 (1.8525)	Prec@1 64.844 (59.415)
Epoch: [25][500/516]	LR 0.085355	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8492 (1.8526)	Prec@1 64.062 (59.470)
Epoch: [25][516/516]	LR 0.085355	Time 0.027 (0.095)	Data 0.000 (0.001)	Loss 1.8397 (1.8525)	Prec@1 54.545 (59.445)
****************************************
clean_train:	 * Prec@1 91.752
noisy_train:	 * Prec@1 59.335
clean_val:	 * Prec@1 91.387
noisy_val:	 * Prec@1 58.954
****************************************
Epoch: [26][50/516]	LR 0.084227	Time 0.097 (0.104)	Data 0.000 (0.006)	Loss 1.8530 (1.8546)	Prec@1 53.906 (59.203)
Epoch: [26][100/516]	LR 0.084227	Time 0.097 (0.101)	Data 0.000 (0.003)	Loss 1.8782 (1.8551)	Prec@1 58.594 (59.266)
Epoch: [26][150/516]	LR 0.084227	Time 0.099 (0.100)	Data 0.000 (0.002)	Loss 1.8931 (1.8546)	Prec@1 46.875 (59.292)
Epoch: [26][200/516]	LR 0.084227	Time 0.097 (0.099)	Data 0.000 (0.002)	Loss 1.8661 (1.8552)	Prec@1 55.469 (59.012)
Epoch: [26][250/516]	LR 0.084227	Time 0.096 (0.098)	Data 0.000 (0.001)	Loss 1.8393 (1.8549)	Prec@1 61.719 (59.331)
Epoch: [26][300/516]	LR 0.084227	Time 0.100 (0.098)	Data 0.000 (0.001)	Loss 1.8495 (1.8545)	Prec@1 60.938 (59.333)
Epoch: [26][350/516]	LR 0.084227	Time 0.096 (0.098)	Data 0.000 (0.001)	Loss 1.8681 (1.8546)	Prec@1 65.625 (59.368)
Epoch: [26][400/516]	LR 0.084227	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8488 (1.8545)	Prec@1 62.500 (59.420)
Epoch: [26][450/516]	LR 0.084227	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8720 (1.8545)	Prec@1 59.375 (59.479)
Epoch: [26][500/516]	LR 0.084227	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8509 (1.8543)	Prec@1 59.375 (59.514)
Epoch: [26][516/516]	LR 0.084227	Time 0.035 (0.097)	Data 0.000 (0.001)	Loss 1.8832 (1.8543)	Prec@1 54.545 (59.546)
****************************************
clean_train:	 * Prec@1 91.314
noisy_train:	 * Prec@1 59.081
clean_val:	 * Prec@1 91.087
noisy_val:	 * Prec@1 58.722
****************************************
Epoch: [27][50/516]	LR 0.083066	Time 0.097 (0.104)	Data 0.000 (0.007)	Loss 1.8611 (1.8571)	Prec@1 53.906 (59.984)
Epoch: [27][100/516]	LR 0.083066	Time 0.097 (0.100)	Data 0.000 (0.004)	Loss 1.8482 (1.8561)	Prec@1 57.812 (59.562)
Epoch: [27][150/516]	LR 0.083066	Time 0.103 (0.099)	Data 0.002 (0.002)	Loss 1.8685 (1.8564)	Prec@1 58.594 (59.641)
Epoch: [27][200/516]	LR 0.083066	Time 0.100 (0.099)	Data 0.000 (0.002)	Loss 1.8401 (1.8563)	Prec@1 66.406 (59.574)
Epoch: [27][250/516]	LR 0.083066	Time 0.097 (0.098)	Data 0.000 (0.002)	Loss 1.8627 (1.8557)	Prec@1 52.344 (59.456)
Epoch: [27][300/516]	LR 0.083066	Time 0.098 (0.098)	Data 0.000 (0.001)	Loss 1.8810 (1.8565)	Prec@1 54.688 (59.427)
Epoch: [27][350/516]	LR 0.083066	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8767 (1.8561)	Prec@1 55.469 (59.547)
Epoch: [27][400/516]	LR 0.083066	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8654 (1.8561)	Prec@1 60.938 (59.611)
Epoch: [27][450/516]	LR 0.083066	Time 0.099 (0.096)	Data 0.000 (0.001)	Loss 1.8544 (1.8559)	Prec@1 57.812 (59.549)
Epoch: [27][500/516]	LR 0.083066	Time 0.095 (0.096)	Data 0.000 (0.001)	Loss 1.8568 (1.8559)	Prec@1 57.031 (59.527)
Epoch: [27][516/516]	LR 0.083066	Time 0.032 (0.096)	Data 0.000 (0.001)	Loss 1.8563 (1.8559)	Prec@1 81.818 (59.540)
****************************************
clean_train:	 * Prec@1 91.697
noisy_train:	 * Prec@1 59.273
clean_val:	 * Prec@1 91.141
noisy_val:	 * Prec@1 58.832
****************************************
Epoch: [28][50/516]	LR 0.081871	Time 0.099 (0.104)	Data 0.000 (0.006)	Loss 1.8527 (1.8594)	Prec@1 55.469 (58.844)
Epoch: [28][100/516]	LR 0.081871	Time 0.093 (0.100)	Data 0.000 (0.003)	Loss 1.8466 (1.8580)	Prec@1 65.625 (59.000)
Epoch: [28][150/516]	LR 0.081871	Time 0.114 (0.099)	Data 0.000 (0.002)	Loss 1.8620 (1.8587)	Prec@1 53.125 (58.901)
Epoch: [28][200/516]	LR 0.081871	Time 0.095 (0.099)	Data 0.000 (0.002)	Loss 1.8608 (1.8589)	Prec@1 65.625 (58.891)
Epoch: [28][250/516]	LR 0.081871	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8706 (1.8589)	Prec@1 55.469 (58.900)
Epoch: [28][300/516]	LR 0.081871	Time 0.095 (0.097)	Data 0.000 (0.001)	Loss 1.8575 (1.8586)	Prec@1 64.062 (59.174)
Epoch: [28][350/516]	LR 0.081871	Time 0.048 (0.097)	Data 0.000 (0.001)	Loss 1.8665 (1.8584)	Prec@1 50.000 (59.221)
Epoch: [28][400/516]	LR 0.081871	Time 0.095 (0.097)	Data 0.000 (0.001)	Loss 1.8482 (1.8579)	Prec@1 60.938 (59.305)
Epoch: [28][450/516]	LR 0.081871	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8504 (1.8576)	Prec@1 67.188 (59.337)
Epoch: [28][500/516]	LR 0.081871	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8390 (1.8576)	Prec@1 60.938 (59.383)
Epoch: [28][516/516]	LR 0.081871	Time 0.028 (0.095)	Data 0.000 (0.001)	Loss 1.8249 (1.8574)	Prec@1 72.727 (59.433)
****************************************
clean_train:	 * Prec@1 92.092
noisy_train:	 * Prec@1 59.430
clean_val:	 * Prec@1 91.810
noisy_val:	 * Prec@1 59.241
****************************************
Epoch: [29][50/516]	LR 0.080645	Time 0.096 (0.104)	Data 0.000 (0.007)	Loss 1.8440 (1.8597)	Prec@1 60.938 (58.516)
Epoch: [29][100/516]	LR 0.080645	Time 0.099 (0.101)	Data 0.000 (0.004)	Loss 1.8491 (1.8590)	Prec@1 61.719 (59.438)
Epoch: [29][150/516]	LR 0.080645	Time 0.096 (0.098)	Data 0.000 (0.002)	Loss 1.8566 (1.8591)	Prec@1 60.156 (59.615)
Epoch: [29][200/516]	LR 0.080645	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8660 (1.8593)	Prec@1 59.375 (59.484)
Epoch: [29][250/516]	LR 0.080645	Time 0.095 (0.097)	Data 0.000 (0.002)	Loss 1.8760 (1.8596)	Prec@1 57.812 (59.591)
Epoch: [29][300/516]	LR 0.080645	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8619 (1.8595)	Prec@1 51.562 (59.503)
Epoch: [29][350/516]	LR 0.080645	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8695 (1.8594)	Prec@1 60.156 (59.489)
Epoch: [29][400/516]	LR 0.080645	Time 0.094 (0.096)	Data 0.000 (0.001)	Loss 1.8371 (1.8591)	Prec@1 64.844 (59.475)
Epoch: [29][450/516]	LR 0.080645	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8718 (1.8591)	Prec@1 57.812 (59.556)
Epoch: [29][500/516]	LR 0.080645	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8411 (1.8589)	Prec@1 57.812 (59.514)
Epoch: [29][516/516]	LR 0.080645	Time 0.033 (0.094)	Data 0.000 (0.001)	Loss 1.8641 (1.8588)	Prec@1 36.364 (59.530)
****************************************
clean_train:	 * Prec@1 91.523
noisy_train:	 * Prec@1 59.107
clean_val:	 * Prec@1 91.264
noisy_val:	 * Prec@1 58.763
****************************************
Epoch: [30][50/516]	LR 0.079389	Time 0.097 (0.097)	Data 0.000 (0.006)	Loss 1.8640 (1.8597)	Prec@1 57.812 (59.516)
Epoch: [30][100/516]	LR 0.079389	Time 0.095 (0.097)	Data 0.000 (0.003)	Loss 1.8623 (1.8601)	Prec@1 59.375 (59.375)
Epoch: [30][150/516]	LR 0.079389	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8559 (1.8592)	Prec@1 67.188 (59.750)
Epoch: [30][200/516]	LR 0.079389	Time 0.100 (0.095)	Data 0.000 (0.002)	Loss 1.8435 (1.8593)	Prec@1 63.281 (59.801)
Epoch: [30][250/516]	LR 0.079389	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8586 (1.8601)	Prec@1 55.469 (59.612)
Epoch: [30][300/516]	LR 0.079389	Time 0.043 (0.095)	Data 0.000 (0.001)	Loss 1.8571 (1.8602)	Prec@1 60.156 (59.641)
Epoch: [30][350/516]	LR 0.079389	Time 0.095 (0.093)	Data 0.000 (0.001)	Loss 1.8640 (1.8599)	Prec@1 61.719 (59.618)
Epoch: [30][400/516]	LR 0.079389	Time 0.099 (0.093)	Data 0.000 (0.001)	Loss 1.8703 (1.8601)	Prec@1 51.562 (59.508)
Epoch: [30][450/516]	LR 0.079389	Time 0.094 (0.094)	Data 0.000 (0.001)	Loss 1.8615 (1.8601)	Prec@1 65.625 (59.505)
Epoch: [30][500/516]	LR 0.079389	Time 0.096 (0.094)	Data 0.000 (0.001)	Loss 1.8489 (1.8602)	Prec@1 57.031 (59.442)
Epoch: [30][516/516]	LR 0.079389	Time 0.043 (0.094)	Data 0.000 (0.001)	Loss 1.9291 (1.8602)	Prec@1 36.364 (59.470)
****************************************
clean_train:	 * Prec@1 90.317
noisy_train:	 * Prec@1 58.478
clean_val:	 * Prec@1 90.213
noisy_val:	 * Prec@1 58.422
****************************************
Epoch: [31][50/516]	LR 0.078104	Time 0.097 (0.105)	Data 0.000 (0.008)	Loss 1.8619 (1.8645)	Prec@1 63.281 (58.766)
Epoch: [31][100/516]	LR 0.078104	Time 0.097 (0.098)	Data 0.000 (0.004)	Loss 1.8569 (1.8644)	Prec@1 61.719 (58.812)
Epoch: [31][150/516]	LR 0.078104	Time 0.097 (0.097)	Data 0.000 (0.003)	Loss 1.8539 (1.8625)	Prec@1 66.406 (59.365)
Epoch: [31][200/516]	LR 0.078104	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8459 (1.8622)	Prec@1 57.031 (59.363)
Epoch: [31][250/516]	LR 0.078104	Time 0.044 (0.093)	Data 0.000 (0.002)	Loss 1.8788 (1.8618)	Prec@1 49.219 (59.372)
Epoch: [31][300/516]	LR 0.078104	Time 0.095 (0.093)	Data 0.000 (0.002)	Loss 1.8692 (1.8618)	Prec@1 58.594 (59.393)
Epoch: [31][350/516]	LR 0.078104	Time 0.094 (0.094)	Data 0.000 (0.001)	Loss 1.8686 (1.8619)	Prec@1 57.031 (59.458)
Epoch: [31][400/516]	LR 0.078104	Time 0.096 (0.094)	Data 0.000 (0.001)	Loss 1.8595 (1.8619)	Prec@1 57.031 (59.332)
Epoch: [31][450/516]	LR 0.078104	Time 0.100 (0.095)	Data 0.000 (0.001)	Loss 1.8618 (1.8617)	Prec@1 70.312 (59.358)
Epoch: [31][500/516]	LR 0.078104	Time 0.098 (0.095)	Data 0.000 (0.001)	Loss 1.8643 (1.8617)	Prec@1 60.938 (59.514)
Epoch: [31][516/516]	LR 0.078104	Time 0.027 (0.095)	Data 0.000 (0.001)	Loss 1.8973 (1.8617)	Prec@1 45.455 (59.465)
****************************************
clean_train:	 * Prec@1 92.239
noisy_train:	 * Prec@1 59.564
clean_val:	 * Prec@1 91.919
noisy_val:	 * Prec@1 59.337
****************************************
Epoch: [32][50/516]	LR 0.076791	Time 0.097 (0.103)	Data 0.000 (0.007)	Loss 1.8840 (1.8660)	Prec@1 60.156 (59.188)
Epoch: [32][100/516]	LR 0.076791	Time 0.098 (0.100)	Data 0.000 (0.003)	Loss 1.8576 (1.8645)	Prec@1 53.906 (59.562)
Epoch: [32][150/516]	LR 0.076791	Time 0.113 (0.095)	Data 0.000 (0.002)	Loss 1.8578 (1.8636)	Prec@1 59.375 (59.250)
Epoch: [32][200/516]	LR 0.076791	Time 0.099 (0.093)	Data 0.000 (0.002)	Loss 1.8691 (1.8633)	Prec@1 58.594 (59.211)
Epoch: [32][250/516]	LR 0.076791	Time 0.097 (0.094)	Data 0.000 (0.001)	Loss 1.8690 (1.8636)	Prec@1 57.031 (59.397)
Epoch: [32][300/516]	LR 0.076791	Time 0.097 (0.094)	Data 0.000 (0.001)	Loss 1.8737 (1.8634)	Prec@1 55.469 (59.430)
Epoch: [32][350/516]	LR 0.076791	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8486 (1.8633)	Prec@1 66.406 (59.484)
Epoch: [32][400/516]	LR 0.076791	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8769 (1.8633)	Prec@1 62.500 (59.469)
Epoch: [32][450/516]	LR 0.076791	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8551 (1.8633)	Prec@1 61.719 (59.488)
Epoch: [32][500/516]	LR 0.076791	Time 0.096 (0.096)	Data 0.000 (0.001)	Loss 1.8597 (1.8631)	Prec@1 61.719 (59.553)
Epoch: [32][516/516]	LR 0.076791	Time 0.033 (0.096)	Data 0.000 (0.001)	Loss 1.8843 (1.8630)	Prec@1 54.545 (59.508)
****************************************
clean_train:	 * Prec@1 91.505
noisy_train:	 * Prec@1 59.098
clean_val:	 * Prec@1 90.854
noisy_val:	 * Prec@1 58.531
****************************************
Epoch: [33][50/516]	LR 0.075452	Time 0.094 (0.093)	Data 0.000 (0.006)	Loss 1.8520 (1.8648)	Prec@1 64.844 (58.953)
Epoch: [33][100/516]	LR 0.075452	Time 0.098 (0.087)	Data 0.000 (0.003)	Loss 1.8673 (1.8652)	Prec@1 56.250 (59.344)
Epoch: [33][150/516]	LR 0.075452	Time 0.097 (0.090)	Data 0.000 (0.002)	Loss 1.8606 (1.8653)	Prec@1 54.688 (59.286)
Epoch: [33][200/516]	LR 0.075452	Time 0.097 (0.092)	Data 0.000 (0.002)	Loss 1.8615 (1.8644)	Prec@1 53.125 (59.289)
Epoch: [33][250/516]	LR 0.075452	Time 0.096 (0.093)	Data 0.000 (0.001)	Loss 1.8785 (1.8646)	Prec@1 52.344 (59.256)
Epoch: [33][300/516]	LR 0.075452	Time 0.099 (0.094)	Data 0.000 (0.001)	Loss 1.8626 (1.8640)	Prec@1 62.500 (59.242)
Epoch: [33][350/516]	LR 0.075452	Time 0.096 (0.095)	Data 0.000 (0.001)	Loss 1.8679 (1.8637)	Prec@1 60.938 (59.453)
Epoch: [33][400/516]	LR 0.075452	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 1.8491 (1.8639)	Prec@1 57.031 (59.385)
Epoch: [33][450/516]	LR 0.075452	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 1.8625 (1.8641)	Prec@1 61.719 (59.365)
Epoch: [33][500/516]	LR 0.075452	Time 0.099 (0.095)	Data 0.000 (0.001)	Loss 1.8568 (1.8641)	Prec@1 59.375 (59.478)
Epoch: [33][516/516]	LR 0.075452	Time 0.036 (0.095)	Data 0.000 (0.001)	Loss 1.9072 (1.8641)	Prec@1 72.727 (59.523)
****************************************
clean_train:	 * Prec@1 92.841
noisy_train:	 * Prec@1 59.952
clean_val:	 * Prec@1 92.820
noisy_val:	 * Prec@1 59.965
****************************************
Epoch: [34][50/516]	LR 0.074088	Time 0.099 (0.104)	Data 0.000 (0.007)	Loss 1.8535 (1.8668)	Prec@1 61.719 (59.812)
Epoch: [34][100/516]	LR 0.074088	Time 0.094 (0.101)	Data 0.000 (0.003)	Loss 1.8652 (1.8662)	Prec@1 59.375 (59.680)
Epoch: [34][150/516]	LR 0.074088	Time 0.099 (0.100)	Data 0.000 (0.002)	Loss 1.8542 (1.8649)	Prec@1 59.375 (59.932)
Epoch: [34][200/516]	LR 0.074088	Time 0.097 (0.099)	Data 0.000 (0.002)	Loss 1.8722 (1.8647)	Prec@1 63.281 (60.066)
Epoch: [34][250/516]	LR 0.074088	Time 0.096 (0.099)	Data 0.000 (0.002)	Loss 1.8546 (1.8651)	Prec@1 70.312 (59.747)
Epoch: [34][300/516]	LR 0.074088	Time 0.095 (0.098)	Data 0.000 (0.001)	Loss 1.8712 (1.8650)	Prec@1 54.688 (59.711)
Epoch: [34][350/516]	LR 0.074088	Time 0.099 (0.098)	Data 0.000 (0.001)	Loss 1.8639 (1.8649)	Prec@1 58.594 (59.725)
Epoch: [34][400/516]	LR 0.074088	Time 0.099 (0.098)	Data 0.000 (0.001)	Loss 1.8514 (1.8651)	Prec@1 64.062 (59.613)
Epoch: [34][450/516]	LR 0.074088	Time 0.096 (0.097)	Data 0.000 (0.001)	Loss 1.8622 (1.8651)	Prec@1 59.375 (59.632)
Epoch: [34][500/516]	LR 0.074088	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8606 (1.8653)	Prec@1 67.969 (59.541)
Epoch: [34][516/516]	LR 0.074088	Time 0.026 (0.097)	Data 0.000 (0.001)	Loss 1.9286 (1.8652)	Prec@1 81.818 (59.540)
****************************************
clean_train:	 * Prec@1 92.451
noisy_train:	 * Prec@1 59.653
clean_val:	 * Prec@1 92.028
noisy_val:	 * Prec@1 59.255
****************************************
Epoch: [35][50/516]	LR 0.072700	Time 0.096 (0.104)	Data 0.000 (0.007)	Loss 1.8609 (1.8693)	Prec@1 62.500 (58.812)
Epoch: [35][100/516]	LR 0.072700	Time 0.097 (0.101)	Data 0.000 (0.003)	Loss 1.8584 (1.8686)	Prec@1 53.125 (58.820)
Epoch: [35][150/516]	LR 0.072700	Time 0.094 (0.100)	Data 0.000 (0.002)	Loss 1.8709 (1.8685)	Prec@1 58.594 (58.958)
Epoch: [35][200/516]	LR 0.072700	Time 0.097 (0.099)	Data 0.000 (0.002)	Loss 1.8750 (1.8680)	Prec@1 57.031 (59.270)
Epoch: [35][250/516]	LR 0.072700	Time 0.099 (0.098)	Data 0.000 (0.001)	Loss 1.8650 (1.8679)	Prec@1 52.344 (59.316)
Epoch: [35][300/516]	LR 0.072700	Time 0.099 (0.098)	Data 0.000 (0.001)	Loss 1.8878 (1.8676)	Prec@1 56.250 (59.214)
Epoch: [35][350/516]	LR 0.072700	Time 0.095 (0.097)	Data 0.000 (0.001)	Loss 1.8661 (1.8673)	Prec@1 57.031 (59.214)
Epoch: [35][400/516]	LR 0.072700	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8685 (1.8671)	Prec@1 60.938 (59.252)
Epoch: [35][450/516]	LR 0.072700	Time 0.095 (0.097)	Data 0.000 (0.001)	Loss 1.8970 (1.8670)	Prec@1 55.469 (59.394)
Epoch: [35][500/516]	LR 0.072700	Time 0.099 (0.097)	Data 0.000 (0.001)	Loss 1.8825 (1.8670)	Prec@1 53.125 (59.392)
Epoch: [35][516/516]	LR 0.072700	Time 0.032 (0.097)	Data 0.000 (0.001)	Loss 1.9021 (1.8670)	Prec@1 72.727 (59.371)
****************************************
clean_train:	 * Prec@1 92.697
noisy_train:	 * Prec@1 59.784
clean_val:	 * Prec@1 92.711
noisy_val:	 * Prec@1 59.773
****************************************
Epoch: [36][50/516]	LR 0.071289	Time 0.099 (0.120)	Data 0.000 (0.008)	Loss 1.8529 (1.8669)	Prec@1 60.938 (60.188)
Epoch: [36][100/516]	LR 0.071289	Time 0.095 (0.116)	Data 0.000 (0.004)	Loss 1.8521 (1.8687)	Prec@1 59.375 (59.719)
Epoch: [36][150/516]	LR 0.071289	Time 0.147 (0.116)	Data 0.000 (0.003)	Loss 1.8816 (1.8691)	Prec@1 64.062 (59.609)
Epoch: [36][200/516]	LR 0.071289	Time 0.145 (0.117)	Data 0.000 (0.002)	Loss 1.8559 (1.8690)	Prec@1 62.500 (59.684)
Epoch: [36][250/516]	LR 0.071289	Time 0.099 (0.114)	Data 0.000 (0.002)	Loss 1.8587 (1.8689)	Prec@1 57.812 (59.678)
Epoch: [36][300/516]	LR 0.071289	Time 0.097 (0.110)	Data 0.000 (0.002)	Loss 1.8650 (1.8685)	Prec@1 60.156 (59.781)
Epoch: [36][350/516]	LR 0.071289	Time 0.097 (0.108)	Data 0.000 (0.001)	Loss 1.8762 (1.8683)	Prec@1 62.500 (59.750)
Epoch: [36][400/516]	LR 0.071289	Time 0.097 (0.106)	Data 0.000 (0.001)	Loss 1.8766 (1.8678)	Prec@1 58.594 (59.646)
Epoch: [36][450/516]	LR 0.071289	Time 0.095 (0.105)	Data 0.000 (0.001)	Loss 1.8692 (1.8677)	Prec@1 55.469 (59.602)
Epoch: [36][500/516]	LR 0.071289	Time 0.094 (0.104)	Data 0.000 (0.001)	Loss 1.8492 (1.8673)	Prec@1 53.906 (59.592)
Epoch: [36][516/516]	LR 0.071289	Time 0.030 (0.103)	Data 0.000 (0.001)	Loss 1.9161 (1.8674)	Prec@1 63.636 (59.564)
****************************************
clean_train:	 * Prec@1 93.052
noisy_train:	 * Prec@1 60.026
clean_val:	 * Prec@1 92.957
noisy_val:	 * Prec@1 59.924
****************************************
Epoch: [37][50/516]	LR 0.069857	Time 0.099 (0.103)	Data 0.000 (0.006)	Loss 1.8579 (1.8693)	Prec@1 51.562 (58.734)
Epoch: [37][100/516]	LR 0.069857	Time 0.099 (0.100)	Data 0.000 (0.003)	Loss 1.8589 (1.8681)	Prec@1 58.594 (59.594)
Epoch: [37][150/516]	LR 0.069857	Time 0.101 (0.099)	Data 0.000 (0.002)	Loss 1.8697 (1.8682)	Prec@1 65.625 (59.823)
Epoch: [37][200/516]	LR 0.069857	Time 0.094 (0.097)	Data 0.000 (0.002)	Loss 1.8825 (1.8684)	Prec@1 62.500 (59.664)
Epoch: [37][250/516]	LR 0.069857	Time 0.097 (0.097)	Data 0.000 (0.001)	Loss 1.8542 (1.8686)	Prec@1 61.719 (59.737)
Epoch: [37][300/516]	LR 0.069857	Time 0.050 (0.096)	Data 0.000 (0.001)	Loss 1.8626 (1.8687)	Prec@1 59.375 (59.549)
Epoch: [37][350/516]	LR 0.069857	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8527 (1.8683)	Prec@1 56.250 (59.643)
Epoch: [37][400/516]	LR 0.069857	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8729 (1.8683)	Prec@1 59.375 (59.527)
Epoch: [37][450/516]	LR 0.069857	Time 0.057 (0.096)	Data 0.000 (0.001)	Loss 1.8737 (1.8683)	Prec@1 52.344 (59.510)
Epoch: [37][500/516]	LR 0.069857	Time 0.098 (0.094)	Data 0.000 (0.001)	Loss 1.8529 (1.8685)	Prec@1 59.375 (59.478)
Epoch: [37][516/516]	LR 0.069857	Time 0.029 (0.094)	Data 0.000 (0.001)	Loss 1.8695 (1.8686)	Prec@1 72.727 (59.505)
****************************************
clean_train:	 * Prec@1 92.459
noisy_train:	 * Prec@1 59.629
clean_val:	 * Prec@1 92.097
noisy_val:	 * Prec@1 59.255
****************************************
Epoch: [38][50/516]	LR 0.068406	Time 0.095 (0.102)	Data 0.000 (0.006)	Loss 1.8744 (1.8718)	Prec@1 59.375 (57.562)
Epoch: [38][100/516]	LR 0.068406	Time 0.097 (0.096)	Data 0.000 (0.003)	Loss 1.8629 (1.8707)	Prec@1 60.156 (58.758)
Epoch: [38][150/516]	LR 0.068406	Time 0.095 (0.096)	Data 0.000 (0.002)	Loss 1.8653 (1.8699)	Prec@1 64.062 (59.443)
Epoch: [38][200/516]	LR 0.068406	Time 0.093 (0.096)	Data 0.000 (0.002)	Loss 1.8653 (1.8696)	Prec@1 57.812 (59.426)
Epoch: [38][250/516]	LR 0.068406	Time 0.101 (0.095)	Data 0.000 (0.001)	Loss 1.8585 (1.8692)	Prec@1 55.469 (59.372)
Epoch: [38][300/516]	LR 0.068406	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 1.8617 (1.8694)	Prec@1 63.281 (59.513)
Epoch: [38][350/516]	LR 0.068406	Time 0.099 (0.095)	Data 0.001 (0.001)	Loss 1.8667 (1.8693)	Prec@1 64.062 (59.475)
Epoch: [38][400/516]	LR 0.068406	Time 0.097 (0.093)	Data 0.000 (0.001)	Loss 1.8902 (1.8697)	Prec@1 50.781 (59.436)
Epoch: [38][450/516]	LR 0.068406	Time 0.105 (0.094)	Data 0.002 (0.001)	Loss 1.8909 (1.8700)	Prec@1 59.375 (59.413)
Epoch: [38][500/516]	LR 0.068406	Time 0.102 (0.094)	Data 0.000 (0.001)	Loss 1.9010 (1.8700)	Prec@1 55.469 (59.419)
Epoch: [38][516/516]	LR 0.068406	Time 0.034 (0.094)	Data 0.000 (0.001)	Loss 1.8936 (1.8700)	Prec@1 81.818 (59.442)
****************************************
clean_train:	 * Prec@1 91.432
noisy_train:	 * Prec@1 59.034
clean_val:	 * Prec@1 91.441
noisy_val:	 * Prec@1 59.036
****************************************
Epoch: [39][50/516]	LR 0.066937	Time 0.097 (0.102)	Data 0.000 (0.006)	Loss 1.8857 (1.8724)	Prec@1 59.375 (58.641)
Epoch: [39][100/516]	LR 0.066937	Time 0.097 (0.100)	Data 0.000 (0.003)	Loss 1.8678 (1.8730)	Prec@1 67.188 (58.734)
Epoch: [39][150/516]	LR 0.066937	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8723 (1.8715)	Prec@1 57.031 (58.854)
Epoch: [39][200/516]	LR 0.066937	Time 0.097 (0.097)	Data 0.000 (0.002)	Loss 1.8728 (1.8712)	Prec@1 60.156 (58.906)
Epoch: [39][250/516]	LR 0.066937	Time 0.042 (0.096)	Data 0.000 (0.001)	Loss 1.8708 (1.8713)	Prec@1 54.688 (59.047)
                                                                                                                                                                                                                                      